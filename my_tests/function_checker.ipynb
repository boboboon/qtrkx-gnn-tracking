{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "#internal\n",
    "import os, sys, glob, yaml, datetime, argparse\n",
    "import csv\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph = namedtuple('Graph', ['X', 'Ri', 'Ro', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_to_graph(X, Ri_rows, Ri_cols, Ro_rows, Ro_cols, y, dtype=np.float32):\n",
    "    n_nodes, n_edges = X.shape[0], Ri_rows.shape[0]\n",
    "    Ri = np.zeros((n_nodes, n_edges), dtype=dtype)\n",
    "    Ro = np.zeros((n_nodes, n_edges), dtype=dtype)\n",
    "    Ri[Ri_rows, Ri_cols] = 1\n",
    "    Ro[Ro_rows, Ro_cols] = 1\n",
    "    return Graph(X, Ri, Ro, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(filename):\n",
    "    \"\"\"Reade a single graph NPZ\"\"\"\n",
    "    with np.load(filename) as f:\n",
    "        return sparse_to_graph(**dict(f.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset():\n",
    "    def __init__(self, input_dir, n_samples=None):\n",
    "        input_dir = os.path.expandvars(input_dir)\n",
    "        filenames = [os.path.join(input_dir, f) for f in os.listdir(input_dir)\n",
    "                     if f.startswith('event') and f.endswith('.npz')]\n",
    "        self.filenames = (\n",
    "            filenames[:n_samples] if n_samples is not None else filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return load_graph(self.filenames[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(input_dir,n_files):\n",
    "    return GraphDataset(input_dir, n_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map2angle(arr0):\n",
    "    # Mapping the cylindrical coordinates to [0,1]\n",
    "    arr = np.zeros(arr0.shape, dtype=np.float32)\n",
    "    r_min     = 0.\n",
    "    r_max     = 1.1\n",
    "    arr[:,0] = (arr0[:,0]-r_min)/(r_max-r_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now we will see how these functions above are used piecewise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We grab our dataset that can be found in data/train and use 50 files of it (all in config)\n",
    "train_data = get_dataset('/Users/lucascurtin/Desktop/qtrkx-gnn-tracking/data/train', 50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(X=array([[ 0.03249963, -0.45238492,  0.12183899],\n",
       "       [ 0.0717338 , -0.44740212,  0.266498  ],\n",
       "       [ 0.11588637, -0.4448925 ,  0.427269  ],\n",
       "       ...,\n",
       "       [ 0.2606789 , -0.98216856, -0.44779998],\n",
       "       [ 0.3633492 , -0.9724082 , -0.6242    ],\n",
       "       [ 0.5020463 , -0.9593005 , -0.8642    ]], dtype=float32), Ri=array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), Ro=array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), y=array([1., 0., 0., ..., 0., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data is a GraphDataset object, and is made by diving into our data file and grabbing the files up to the 50th one\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we've got lots of arrays i.e. X, Ri, Ro and y. We will now dive into seeing how they got these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2de66aacfb5533ba02da6f4420ea2eaa19c5caca09d87e43bc0380df315872a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
