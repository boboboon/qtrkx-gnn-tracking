Printing configs: 
train_dir: /home/xzcaplcu/repo/qtrkx-gnn-tracking/data_personal/train_graphs
valid_dir: /home/xzcaplcu/repo/qtrkx-gnn-tracking/data_personal/valid_graphs
dataset: TuysuzPaper
log_dir: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/
run_type: new_run
gpu: -1
n_files: 100
n_valid: 20
n_train: 80
lr_c: 0.01
batch_size: 1
n_iters: 3
n_epoch: 30
TEST_every: 50
hid_dim: 4
network: CGNN
optimizer: Adam
loss_func: BinaryCrossentropy
n_thread: 4
log_verbosity: 2
Log dir: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/
Training data input dir: /home/xzcaplcu/repo/qtrkx-gnn-tracking/data_personal/train_graphs
Validation data input dir: /home/xzcaplcu/repo/qtrkx-gnn-tracking/data_personal/train_graphs
2023-03-06 16:35:31.204673 Deleted old log: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/log_validation.csv
2023-03-06 16:35:31.204848 Deleted old log: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/log_training.csv
2023-03-06 16:35:31.204995 Deleted old log: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/summary.csv
2023-03-06 16:35:31.205188 Deleted old log: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/log_parameters_0.csv
2023-03-06 16:35:31.205340 Deleted old log: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/log_parameters_1.csv
2023-03-06 16:35:31.205705 Deleted old log: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/log_parameters_2.csv
2023-03-06 16:35:31.205877 Deleted old log: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/log_parameters_3.csv
2023-03-06 16:35:31.206030 Deleted old log: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/log_parameters_4.csv
2023-03-06 16:35:31.206176 Deleted old log: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/log_parameters_5.csv
2023-03-06 16:35:31.206504 Deleted old log: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/log_parameters_6.csv
2023-03-06 16:35:31.206662 Deleted old log: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/log_parameters_7.csv
2023-03-06 16:35:31.206875 Deleted old log: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/log_parameters_8.csv
2023-03-06 16:35:31.207037 Deleted old log: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/log_parameters_9.csv
2023-03-06 16:35:31.207251 Deleted old log: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/log_gradients_0.csv
2023-03-06 16:35:31.207399 Deleted old log: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/log_gradients_1.csv
2023-03-06 16:35:31.207757 Deleted old log: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/log_gradients_2.csv
2023-03-06 16:35:31.207908 Deleted old log: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/log_gradients_3.csv
2023-03-06 16:35:31.208054 Deleted old log: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/log_gradients_4.csv
2023-03-06 16:35:31.208198 Deleted old log: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/log_gradients_5.csv
2023-03-06 16:35:31.208539 Deleted old log: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/log_gradients_6.csv
2023-03-06 16:35:31.208706 Deleted old log: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/log_gradients_7.csv
2023-03-06 16:35:31.208925 Deleted old log: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/log_gradients_8.csv
2023-03-06 16:35:31.209073 Deleted old log: /home/xzcaplcu/repo/qtrkx-gnn-tracking/logs/test_QGNN/run 1/log_gradients_9.csv
Model: "GNN"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 InputNet (Sequential)       (None, 4)                 16        
                                                                 
 EdgeNet (EdgeNet)           multiple                  65        
                                                                 
 NodeNet (NodeNet)           multiple                  108       
                                                                 
=================================================================
Total params: 189
Trainable params: 189
Non-trainable params: 0
_________________________________________________________________
None
2023-03-06 16:35:33.676647 Starting testing the valid set with 20 subgraphs!
2023-03-06 16:36:39.558350: validation Test:  Loss: 0.7131,  AUC: 0.2421, Acc: 48.6822,  Precision: nan -- Elapsed: 1m5s
2023-03-06 16:36:39.559918 Starting testing the train set with 20 subgraphs!
2023-03-06 16:41:05.861683: training Test:  Loss: 0.7129,  AUC: 0.2397, Acc: 48.7956,  Precision: 0.1111 -- Elapsed: 4m26s
2023-03-06 16:41:05.869093: Training is starting!
2023-03-06 16:41:08.945766: Epoch: 1, Batch: 1, Loss: 0.7127, Elapsed: 0m3s
2023-03-06 16:41:12.431490: Epoch: 1, Batch: 2, Loss: 0.6971, Elapsed: 0m3s
2023-03-06 16:41:16.488427: Epoch: 1, Batch: 3, Loss: 0.6915, Elapsed: 0m4s
2023-03-06 16:41:18.183785: Epoch: 1, Batch: 4, Loss: 0.6866, Elapsed: 0m1s
2023-03-06 16:41:20.729804: Epoch: 1, Batch: 5, Loss: 0.6796, Elapsed: 0m2s
2023-03-06 16:41:24.015758: Epoch: 1, Batch: 6, Loss: 0.6806, Elapsed: 0m3s
2023-03-06 16:41:26.202297: Epoch: 1, Batch: 7, Loss: 0.6734, Elapsed: 0m2s
2023-03-06 16:41:28.636632: Epoch: 1, Batch: 8, Loss: 0.6748, Elapsed: 0m2s
2023-03-06 16:41:31.204169: Epoch: 1, Batch: 9, Loss: 0.6791, Elapsed: 0m2s
2023-03-06 16:41:33.686849: Epoch: 1, Batch: 10, Loss: 0.6691, Elapsed: 0m2s
2023-03-06 16:41:36.325229: Epoch: 1, Batch: 11, Loss: 0.6672, Elapsed: 0m2s
2023-03-06 16:41:38.265881: Epoch: 1, Batch: 12, Loss: 0.6612, Elapsed: 0m1s
2023-03-06 16:41:42.907537: Epoch: 1, Batch: 13, Loss: 0.6636, Elapsed: 0m4s
2023-03-06 16:41:45.407833: Epoch: 1, Batch: 14, Loss: 0.6580, Elapsed: 0m2s
2023-03-06 16:41:48.223510: Epoch: 1, Batch: 15, Loss: 0.6553, Elapsed: 0m2s
2023-03-06 16:41:51.260683: Epoch: 1, Batch: 16, Loss: 0.6564, Elapsed: 0m3s
2023-03-06 16:41:54.438062: Epoch: 1, Batch: 17, Loss: 0.6494, Elapsed: 0m3s
2023-03-06 16:41:58.102433: Epoch: 1, Batch: 18, Loss: 0.6467, Elapsed: 0m3s
2023-03-06 16:42:00.017211: Epoch: 1, Batch: 19, Loss: 0.6431, Elapsed: 0m1s
2023-03-06 16:42:04.087436: Epoch: 1, Batch: 20, Loss: 0.6453, Elapsed: 0m4s
2023-03-06 16:42:06.597257: Epoch: 1, Batch: 21, Loss: 0.6344, Elapsed: 0m2s
2023-03-06 16:42:09.601906: Epoch: 1, Batch: 22, Loss: 0.6347, Elapsed: 0m2s
2023-03-06 16:42:13.819252: Epoch: 1, Batch: 23, Loss: 0.6366, Elapsed: 0m4s
2023-03-06 16:42:16.143004: Epoch: 1, Batch: 24, Loss: 0.6202, Elapsed: 0m2s
2023-03-06 16:42:20.827747: Epoch: 1, Batch: 25, Loss: 0.6230, Elapsed: 0m4s
2023-03-06 16:42:22.911056: Epoch: 1, Batch: 26, Loss: 0.6140, Elapsed: 0m2s
2023-03-06 16:42:25.893755: Epoch: 1, Batch: 27, Loss: 0.6278, Elapsed: 0m2s
2023-03-06 16:42:27.916799: Epoch: 1, Batch: 28, Loss: 0.6146, Elapsed: 0m2s
2023-03-06 16:42:31.276887: Epoch: 1, Batch: 29, Loss: 0.6117, Elapsed: 0m3s
2023-03-06 16:42:32.574031: Epoch: 1, Batch: 30, Loss: 0.5836, Elapsed: 0m1s
2023-03-06 16:42:34.780217: Epoch: 1, Batch: 31, Loss: 0.5938, Elapsed: 0m2s
2023-03-06 16:42:37.278650: Epoch: 1, Batch: 32, Loss: 0.6166, Elapsed: 0m2s
2023-03-06 16:42:39.999490: Epoch: 1, Batch: 33, Loss: 0.6095, Elapsed: 0m2s
2023-03-06 16:42:42.574711: Epoch: 1, Batch: 34, Loss: 0.5916, Elapsed: 0m2s
2023-03-06 16:42:49.033049: Epoch: 1, Batch: 35, Loss: 0.6056, Elapsed: 0m6s
2023-03-06 16:42:50.059055: Epoch: 1, Batch: 36, Loss: 0.6092, Elapsed: 0m1s
2023-03-06 16:42:53.492880: Epoch: 1, Batch: 37, Loss: 0.5940, Elapsed: 0m3s
2023-03-06 16:42:55.323267: Epoch: 1, Batch: 38, Loss: 0.5819, Elapsed: 0m1s
2023-03-06 16:42:57.571861: Epoch: 1, Batch: 39, Loss: 0.5768, Elapsed: 0m2s
2023-03-06 16:43:00.151696: Epoch: 1, Batch: 40, Loss: 0.5792, Elapsed: 0m2s
2023-03-06 16:43:04.239308: Epoch: 1, Batch: 41, Loss: 0.5861, Elapsed: 0m4s
2023-03-06 16:43:08.422857: Epoch: 1, Batch: 42, Loss: 0.5804, Elapsed: 0m4s
2023-03-06 16:43:12.610954: Epoch: 1, Batch: 43, Loss: 0.5756, Elapsed: 0m4s
2023-03-06 16:43:14.541415: Epoch: 1, Batch: 44, Loss: 0.5577, Elapsed: 0m1s
2023-03-06 16:43:19.252421: Epoch: 1, Batch: 45, Loss: 0.5646, Elapsed: 0m4s
2023-03-06 16:43:20.905730: Epoch: 1, Batch: 46, Loss: 0.5445, Elapsed: 0m1s
2023-03-06 16:43:24.487689: Epoch: 1, Batch: 47, Loss: 0.5504, Elapsed: 0m3s
2023-03-06 16:43:27.422077: Epoch: 1, Batch: 48, Loss: 0.5404, Elapsed: 0m2s
2023-03-06 16:43:33.032485: Epoch: 1, Batch: 49, Loss: 0.5500, Elapsed: 0m5s
2023-03-06 16:43:34.898545: Epoch: 1, Batch: 50, Loss: 0.5275, Elapsed: 0m1s
2023-03-06 16:43:34.908482 Starting testing the valid set with 20 subgraphs!
2023-03-06 16:44:42.028769: validation Test:  Loss: 0.5343,  AUC: 0.8131, Acc: 72.8746,  Precision: 0.7286 -- Elapsed: 1m7s
2023-03-06 16:44:42.030261 Starting testing the train set with 20 subgraphs!
2023-03-06 16:49:04.701592: training Test:  Loss: 0.5340,  AUC: 0.8134, Acc: 72.9226,  Precision: 0.7276 -- Elapsed: 4m22s
2023-03-06 16:49:06.239191: Epoch: 1, Batch: 51, Loss: 0.5129, Elapsed: 0m1s
2023-03-06 16:49:09.656022: Epoch: 1, Batch: 52, Loss: 0.5311, Elapsed: 0m3s
2023-03-06 16:49:13.167294: Epoch: 1, Batch: 53, Loss: 0.5406, Elapsed: 0m3s
2023-03-06 16:49:16.025144: Epoch: 1, Batch: 54, Loss: 0.5158, Elapsed: 0m2s
2023-03-06 16:49:18.308640: Epoch: 1, Batch: 55, Loss: 0.5084, Elapsed: 0m2s
2023-03-06 16:49:22.771503: Epoch: 1, Batch: 56, Loss: 0.5176, Elapsed: 0m4s
2023-03-06 16:49:25.740578: Epoch: 1, Batch: 57, Loss: 0.5095, Elapsed: 0m2s
2023-03-06 16:49:28.697958: Epoch: 1, Batch: 58, Loss: 0.4941, Elapsed: 0m2s
2023-03-06 16:49:33.572787: Epoch: 1, Batch: 59, Loss: 0.5039, Elapsed: 0m4s
2023-03-06 16:49:36.144068: Epoch: 1, Batch: 60, Loss: 0.4915, Elapsed: 0m2s
2023-03-06 16:49:39.148635: Epoch: 1, Batch: 61, Loss: 0.4973, Elapsed: 0m2s
2023-03-06 16:49:41.137196: Epoch: 1, Batch: 62, Loss: 0.4864, Elapsed: 0m1s
2023-03-06 16:49:45.439546: Epoch: 1, Batch: 63, Loss: 0.4996, Elapsed: 0m4s
2023-03-06 16:49:48.301360: Epoch: 1, Batch: 64, Loss: 0.4792, Elapsed: 0m2s
2023-03-06 16:49:51.317093: Epoch: 1, Batch: 65, Loss: 0.4754, Elapsed: 0m3s
2023-03-06 16:49:53.617646: Epoch: 1, Batch: 66, Loss: 0.4650, Elapsed: 0m2s
2023-03-06 16:49:57.008192: Epoch: 1, Batch: 67, Loss: 0.4864, Elapsed: 0m3s
2023-03-06 16:50:01.819188: Epoch: 1, Batch: 68, Loss: 0.4932, Elapsed: 0m4s
2023-03-06 16:50:04.605483: Epoch: 1, Batch: 69, Loss: 0.4516, Elapsed: 0m2s
2023-03-06 16:50:09.023732: Epoch: 1, Batch: 70, Loss: 0.4934, Elapsed: 0m4s
2023-03-06 16:50:10.727504: Epoch: 1, Batch: 71, Loss: 0.4641, Elapsed: 0m1s
2023-03-06 16:50:13.242581: Epoch: 1, Batch: 72, Loss: 0.4698, Elapsed: 0m2s
2023-03-06 16:50:16.809337: Epoch: 1, Batch: 73, Loss: 0.4807, Elapsed: 0m3s
2023-03-06 16:50:19.628713: Epoch: 1, Batch: 74, Loss: 0.4786, Elapsed: 0m2s
2023-03-06 16:50:22.349362: Epoch: 1, Batch: 75, Loss: 0.4739, Elapsed: 0m2s
2023-03-06 16:50:27.696879: Epoch: 1, Batch: 76, Loss: 0.4897, Elapsed: 0m5s
2023-03-06 16:50:30.071218: Epoch: 1, Batch: 77, Loss: 0.4703, Elapsed: 0m2s
2023-03-06 16:50:35.146293: Epoch: 1, Batch: 78, Loss: 0.4878, Elapsed: 0m5s
2023-03-06 16:50:38.991429: Epoch: 1, Batch: 79, Loss: 0.4795, Elapsed: 0m3s
2023-03-06 16:50:44.047251: Epoch: 1, Batch: 80, Loss: 0.4597, Elapsed: 0m5s
2023-03-06 16:50:48.232328: Epoch: 2, Batch: 1, Loss: 0.4794, Elapsed: 0m4s
2023-03-06 16:50:51.252196: Epoch: 2, Batch: 2, Loss: 0.4717, Elapsed: 0m3s
2023-03-06 16:50:55.674126: Epoch: 2, Batch: 3, Loss: 0.4766, Elapsed: 0m4s
2023-03-06 16:51:00.349886: Epoch: 2, Batch: 4, Loss: 0.4805, Elapsed: 0m4s
2023-03-06 16:51:03.205414: Epoch: 2, Batch: 5, Loss: 0.4602, Elapsed: 0m2s
2023-03-06 16:51:07.357942: Epoch: 2, Batch: 6, Loss: 0.4786, Elapsed: 0m4s
2023-03-06 16:51:11.461470: Epoch: 2, Batch: 7, Loss: 0.4801, Elapsed: 0m4s
2023-03-06 16:51:14.412968: Epoch: 2, Batch: 8, Loss: 0.4608, Elapsed: 0m2s
2023-03-06 16:51:19.608202: Epoch: 2, Batch: 9, Loss: 0.4805, Elapsed: 0m5s
2023-03-06 16:51:23.832703: Epoch: 2, Batch: 10, Loss: 0.4787, Elapsed: 0m4s
2023-03-06 16:51:26.449304: Epoch: 2, Batch: 11, Loss: 0.4592, Elapsed: 0m2s
2023-03-06 16:51:29.449531: Epoch: 2, Batch: 12, Loss: 0.4672, Elapsed: 0m2s
2023-03-06 16:51:31.958270: Epoch: 2, Batch: 13, Loss: 0.4516, Elapsed: 0m2s
2023-03-06 16:51:34.790679: Epoch: 2, Batch: 14, Loss: 0.4548, Elapsed: 0m2s
2023-03-06 16:51:37.588198: Epoch: 2, Batch: 15, Loss: 0.4646, Elapsed: 0m2s
2023-03-06 16:51:40.519435: Epoch: 2, Batch: 16, Loss: 0.4531, Elapsed: 0m2s
2023-03-06 16:51:43.313206: Epoch: 2, Batch: 17, Loss: 0.4517, Elapsed: 0m2s
2023-03-06 16:51:46.956514: Epoch: 2, Batch: 18, Loss: 0.4687, Elapsed: 0m3s
2023-03-06 16:51:52.297264: Epoch: 2, Batch: 19, Loss: 0.4767, Elapsed: 0m5s
2023-03-06 16:51:54.864035: Epoch: 2, Batch: 20, Loss: 0.4535, Elapsed: 0m2s
2023-03-06 16:51:59.482385: Epoch: 2, Batch: 21, Loss: 0.4723, Elapsed: 0m4s
2023-03-06 16:52:01.217509: Epoch: 2, Batch: 22, Loss: 0.4244, Elapsed: 0m1s
2023-03-06 16:52:03.746108: Epoch: 2, Batch: 23, Loss: 0.4513, Elapsed: 0m2s
2023-03-06 16:52:06.377163: Epoch: 2, Batch: 24, Loss: 0.4576, Elapsed: 0m2s
2023-03-06 16:52:07.716035: Epoch: 2, Batch: 25, Loss: 0.4065, Elapsed: 0m1s
2023-03-06 16:52:10.097138: Epoch: 2, Batch: 26, Loss: 0.4535, Elapsed: 0m2s
2023-03-06 16:52:11.993596: Epoch: 2, Batch: 27, Loss: 0.4409, Elapsed: 0m1s
2023-03-06 16:52:15.406314: Epoch: 2, Batch: 28, Loss: 0.4575, Elapsed: 0m3s
2023-03-06 16:52:18.972529: Epoch: 2, Batch: 29, Loss: 0.4611, Elapsed: 0m3s
2023-03-06 16:52:20.633167: Epoch: 2, Batch: 30, Loss: 0.4194, Elapsed: 0m1s
2023-03-06 16:52:21.649765: Epoch: 2, Batch: 31, Loss: 0.3961, Elapsed: 0m1s
2023-03-06 16:52:24.146304: Epoch: 2, Batch: 32, Loss: 0.4424, Elapsed: 0m2s
2023-03-06 16:52:27.507273: Epoch: 2, Batch: 33, Loss: 0.4553, Elapsed: 0m3s
2023-03-06 16:52:29.041394: Epoch: 2, Batch: 34, Loss: 0.4190, Elapsed: 0m1s
2023-03-06 16:52:34.112509: Epoch: 2, Batch: 35, Loss: 0.4340, Elapsed: 0m5s
2023-03-06 16:52:36.830382: Epoch: 2, Batch: 36, Loss: 0.4520, Elapsed: 0m2s
2023-03-06 16:52:39.785757: Epoch: 2, Batch: 37, Loss: 0.4578, Elapsed: 0m2s
2023-03-06 16:52:43.210744: Epoch: 2, Batch: 38, Loss: 0.4669, Elapsed: 0m3s
2023-03-06 16:52:46.703761: Epoch: 2, Batch: 39, Loss: 0.4650, Elapsed: 0m3s
2023-03-06 16:52:49.693755: Epoch: 2, Batch: 40, Loss: 0.4569, Elapsed: 0m2s
2023-03-06 16:52:52.243184: Epoch: 2, Batch: 41, Loss: 0.4484, Elapsed: 0m2s
2023-03-06 16:52:54.072690: Epoch: 2, Batch: 42, Loss: 0.4299, Elapsed: 0m1s
2023-03-06 16:52:56.042126: Epoch: 2, Batch: 43, Loss: 0.4382, Elapsed: 0m1s
2023-03-06 16:52:59.280071: Epoch: 2, Batch: 44, Loss: 0.4471, Elapsed: 0m3s
2023-03-06 16:53:03.057543: Epoch: 2, Batch: 45, Loss: 0.4554, Elapsed: 0m3s
2023-03-06 16:53:05.586942: Epoch: 2, Batch: 46, Loss: 0.4304, Elapsed: 0m2s
2023-03-06 16:53:08.723652: Epoch: 2, Batch: 47, Loss: 0.4616, Elapsed: 0m3s
2023-03-06 16:53:11.853999: Epoch: 2, Batch: 48, Loss: 0.4394, Elapsed: 0m3s
2023-03-06 16:53:15.236845: Epoch: 2, Batch: 49, Loss: 0.4534, Elapsed: 0m3s
2023-03-06 16:53:17.491014: Epoch: 2, Batch: 50, Loss: 0.4339, Elapsed: 0m2s
2023-03-06 16:53:17.502300 Starting testing the valid set with 20 subgraphs!
2023-03-06 16:54:23.308322: validation Test:  Loss: 0.4496,  AUC: 0.8458, Acc: 77.1595,  Precision: 0.8632 -- Elapsed: 1m5s
2023-03-06 16:54:23.309465 Starting testing the train set with 20 subgraphs!
2023-03-06 16:58:46.107984: training Test:  Loss: 0.4482,  AUC: 0.8466, Acc: 77.3327,  Precision: 0.8651 -- Elapsed: 4m22s
2023-03-06 16:58:48.331434: Epoch: 2, Batch: 51, Loss: 0.4337, Elapsed: 0m2s
2023-03-06 16:58:51.806622: Epoch: 2, Batch: 52, Loss: 0.4546, Elapsed: 0m3s
2023-03-06 16:58:54.986621: Epoch: 2, Batch: 53, Loss: 0.4444, Elapsed: 0m3s
2023-03-06 16:58:57.524292: Epoch: 2, Batch: 54, Loss: 0.4389, Elapsed: 0m2s
2023-03-06 16:59:01.726979: Epoch: 2, Batch: 55, Loss: 0.4590, Elapsed: 0m4s
2023-03-06 16:59:07.752249: Epoch: 2, Batch: 56, Loss: 0.4697, Elapsed: 0m6s
2023-03-06 16:59:10.298801: Epoch: 2, Batch: 57, Loss: 0.4412, Elapsed: 0m2s
2023-03-06 16:59:13.424936: Epoch: 2, Batch: 58, Loss: 0.4535, Elapsed: 0m3s
2023-03-06 16:59:15.728730: Epoch: 2, Batch: 59, Loss: 0.4357, Elapsed: 0m2s
2023-03-06 16:59:19.814939: Epoch: 2, Batch: 60, Loss: 0.4636, Elapsed: 0m4s
2023-03-06 16:59:23.875397: Epoch: 2, Batch: 61, Loss: 0.4581, Elapsed: 0m4s
2023-03-06 16:59:25.799334: Epoch: 2, Batch: 62, Loss: 0.4250, Elapsed: 0m1s
2023-03-06 16:59:28.300532: Epoch: 2, Batch: 63, Loss: 0.4439, Elapsed: 0m2s
2023-03-06 16:59:32.006798: Epoch: 2, Batch: 64, Loss: 0.4548, Elapsed: 0m3s
2023-03-06 16:59:35.196754: Epoch: 2, Batch: 65, Loss: 0.4533, Elapsed: 0m3s
2023-03-06 16:59:37.313152: Epoch: 2, Batch: 66, Loss: 0.4351, Elapsed: 0m2s
2023-03-06 16:59:39.679532: Epoch: 2, Batch: 67, Loss: 0.4351, Elapsed: 0m2s
2023-03-06 16:59:43.979165: Epoch: 2, Batch: 68, Loss: 0.4594, Elapsed: 0m4s
2023-03-06 16:59:45.893574: Epoch: 2, Batch: 69, Loss: 0.4104, Elapsed: 0m1s
2023-03-06 16:59:52.135210: Epoch: 2, Batch: 70, Loss: 0.4670, Elapsed: 0m6s
2023-03-06 16:59:57.079279: Epoch: 2, Batch: 71, Loss: 0.4551, Elapsed: 0m4s
2023-03-06 17:00:01.632814: Epoch: 2, Batch: 72, Loss: 0.4612, Elapsed: 0m4s
2023-03-06 17:00:05.713350: Epoch: 2, Batch: 73, Loss: 0.4679, Elapsed: 0m4s
2023-03-06 17:00:08.211142: Epoch: 2, Batch: 74, Loss: 0.4396, Elapsed: 0m2s
2023-03-06 17:00:10.386013: Epoch: 2, Batch: 75, Loss: 0.4216, Elapsed: 0m2s
2023-03-06 17:00:12.374944: Epoch: 2, Batch: 76, Loss: 0.4245, Elapsed: 0m1s
2023-03-06 17:00:14.887592: Epoch: 2, Batch: 77, Loss: 0.4263, Elapsed: 0m2s
2023-03-06 17:00:16.885709: Epoch: 2, Batch: 78, Loss: 0.4357, Elapsed: 0m1s
2023-03-06 17:00:18.578093: Epoch: 2, Batch: 79, Loss: 0.4233, Elapsed: 0m1s
2023-03-06 17:00:20.966359: Epoch: 2, Batch: 80, Loss: 0.4122, Elapsed: 0m2s
2023-03-06 17:00:23.900214: Epoch: 3, Batch: 1, Loss: 0.4309, Elapsed: 0m2s
2023-03-06 17:00:26.401233: Epoch: 3, Batch: 2, Loss: 0.4381, Elapsed: 0m2s
2023-03-06 17:00:27.443840: Epoch: 3, Batch: 3, Loss: 0.3810, Elapsed: 0m1s
2023-03-06 17:00:29.890658: Epoch: 3, Batch: 4, Loss: 0.4369, Elapsed: 0m2s
2023-03-06 17:00:32.796549: Epoch: 3, Batch: 5, Loss: 0.4326, Elapsed: 0m2s
2023-03-06 17:00:35.372526: Epoch: 3, Batch: 6, Loss: 0.4364, Elapsed: 0m2s
2023-03-06 17:00:38.834374: Epoch: 3, Batch: 7, Loss: 0.4451, Elapsed: 0m3s
2023-03-06 17:00:41.469597: Epoch: 3, Batch: 8, Loss: 0.4242, Elapsed: 0m2s
2023-03-06 17:00:44.929278: Epoch: 3, Batch: 9, Loss: 0.4420, Elapsed: 0m3s
2023-03-06 17:00:47.206357: Epoch: 3, Batch: 10, Loss: 0.4261, Elapsed: 0m2s
2023-03-06 17:00:50.157036: Epoch: 3, Batch: 11, Loss: 0.4342, Elapsed: 0m2s
2023-03-06 17:00:54.266896: Epoch: 3, Batch: 12, Loss: 0.4536, Elapsed: 0m4s
2023-03-06 17:00:58.867785: Epoch: 3, Batch: 13, Loss: 0.4535, Elapsed: 0m4s
2023-03-06 17:01:01.252440: Epoch: 3, Batch: 14, Loss: 0.4093, Elapsed: 0m2s
2023-03-06 17:01:03.788688: Epoch: 3, Batch: 15, Loss: 0.4299, Elapsed: 0m2s
2023-03-06 17:01:07.442414: Epoch: 3, Batch: 16, Loss: 0.4461, Elapsed: 0m3s
2023-03-06 17:01:10.896929: Epoch: 3, Batch: 17, Loss: 0.4464, Elapsed: 0m3s
2023-03-06 17:01:13.915896: Epoch: 3, Batch: 18, Loss: 0.4413, Elapsed: 0m3s
2023-03-06 17:01:18.044963: Epoch: 3, Batch: 19, Loss: 0.4557, Elapsed: 0m4s
2023-03-06 17:01:20.544685: Epoch: 3, Batch: 20, Loss: 0.4329, Elapsed: 0m2s
2023-03-06 17:01:22.962370: Epoch: 3, Batch: 21, Loss: 0.4299, Elapsed: 0m2s
2023-03-06 17:01:25.464793: Epoch: 3, Batch: 22, Loss: 0.4253, Elapsed: 0m2s
2023-03-06 17:01:27.009603: Epoch: 3, Batch: 23, Loss: 0.4011, Elapsed: 0m1s
2023-03-06 17:01:29.876356: Epoch: 3, Batch: 24, Loss: 0.4340, Elapsed: 0m2s
2023-03-06 17:01:31.503375: Epoch: 3, Batch: 25, Loss: 0.4031, Elapsed: 0m1s
2023-03-06 17:01:34.306151: Epoch: 3, Batch: 26, Loss: 0.4287, Elapsed: 0m2s
2023-03-06 17:01:36.328426: Epoch: 3, Batch: 27, Loss: 0.4270, Elapsed: 0m2s
2023-03-06 17:01:38.819758: Epoch: 3, Batch: 28, Loss: 0.4348, Elapsed: 0m2s
2023-03-06 17:01:41.976831: Epoch: 3, Batch: 29, Loss: 0.4410, Elapsed: 0m3s
2023-03-06 17:01:44.696409: Epoch: 3, Batch: 30, Loss: 0.4325, Elapsed: 0m2s
2023-03-06 17:01:47.520204: Epoch: 3, Batch: 31, Loss: 0.4323, Elapsed: 0m2s
2023-03-06 17:01:49.457018: Epoch: 3, Batch: 32, Loss: 0.4009, Elapsed: 0m1s
2023-03-06 17:01:51.648820: Epoch: 3, Batch: 33, Loss: 0.4135, Elapsed: 0m2s
2023-03-06 17:01:53.479819: Epoch: 3, Batch: 34, Loss: 0.4122, Elapsed: 0m1s
2023-03-06 17:01:57.839517: Epoch: 3, Batch: 35, Loss: 0.4454, Elapsed: 0m4s
2023-03-06 17:02:03.228559: Epoch: 3, Batch: 36, Loss: 0.4188, Elapsed: 0m5s
2023-03-06 17:02:06.660513: Epoch: 3, Batch: 37, Loss: 0.4288, Elapsed: 0m3s
2023-03-06 17:02:09.910741: Epoch: 3, Batch: 38, Loss: 0.4416, Elapsed: 0m3s
2023-03-06 17:02:13.348425: Epoch: 3, Batch: 39, Loss: 0.4359, Elapsed: 0m3s
2023-03-06 17:02:16.931786: Epoch: 3, Batch: 40, Loss: 0.4486, Elapsed: 0m3s
2023-03-06 17:02:22.226064: Epoch: 3, Batch: 41, Loss: 0.4519, Elapsed: 0m5s
2023-03-06 17:02:25.853883: Epoch: 3, Batch: 42, Loss: 0.4478, Elapsed: 0m3s
2023-03-06 17:02:27.163537: Epoch: 3, Batch: 43, Loss: 0.3791, Elapsed: 0m1s
2023-03-06 17:02:29.844700: Epoch: 3, Batch: 44, Loss: 0.4453, Elapsed: 0m2s
2023-03-06 17:02:33.406531: Epoch: 3, Batch: 45, Loss: 0.4408, Elapsed: 0m3s
2023-03-06 17:02:36.377266: Epoch: 3, Batch: 46, Loss: 0.4428, Elapsed: 0m2s
2023-03-06 17:02:42.658405: Epoch: 3, Batch: 47, Loss: 0.4578, Elapsed: 0m6s
2023-03-06 17:02:46.189145: Epoch: 3, Batch: 48, Loss: 0.4372, Elapsed: 0m3s
2023-03-06 17:02:48.775390: Epoch: 3, Batch: 49, Loss: 0.4193, Elapsed: 0m2s
2023-03-06 17:02:52.727764: Epoch: 3, Batch: 50, Loss: 0.4506, Elapsed: 0m3s
2023-03-06 17:02:52.736681 Starting testing the valid set with 20 subgraphs!
2023-03-06 17:03:59.570022: validation Test:  Loss: 0.4337,  AUC: 0.8575, Acc: 78.1652,  Precision: 0.8480 -- Elapsed: 1m6s
2023-03-06 17:03:59.571199 Starting testing the train set with 20 subgraphs!
2023-03-06 17:08:23.558773: training Test:  Loss: 0.4322,  AUC: 0.8584, Acc: 78.2799,  Precision: 0.8501 -- Elapsed: 4m23s
2023-03-06 17:08:25.727294: Epoch: 3, Batch: 51, Loss: 0.4220, Elapsed: 0m2s
2023-03-06 17:08:29.783918: Epoch: 3, Batch: 52, Loss: 0.4440, Elapsed: 0m4s
2023-03-06 17:08:32.277643: Epoch: 3, Batch: 53, Loss: 0.4351, Elapsed: 0m2s
2023-03-06 17:08:35.941946: Epoch: 3, Batch: 54, Loss: 0.4412, Elapsed: 0m3s
2023-03-06 17:08:37.937817: Epoch: 3, Batch: 55, Loss: 0.4262, Elapsed: 0m1s
2023-03-06 17:08:41.752972: Epoch: 3, Batch: 56, Loss: 0.4441, Elapsed: 0m3s
2023-03-06 17:08:46.266527: Epoch: 3, Batch: 57, Loss: 0.4502, Elapsed: 0m4s
2023-03-06 17:08:47.929094: Epoch: 3, Batch: 58, Loss: 0.3950, Elapsed: 0m1s
2023-03-06 17:08:49.636132: Epoch: 3, Batch: 59, Loss: 0.4125, Elapsed: 0m1s
2023-03-06 17:08:53.783827: Epoch: 3, Batch: 60, Loss: 0.4417, Elapsed: 0m4s
2023-03-06 17:08:57.996401: Epoch: 3, Batch: 61, Loss: 0.4432, Elapsed: 0m4s
2023-03-06 17:09:02.459256: Epoch: 3, Batch: 62, Loss: 0.4438, Elapsed: 0m4s
2023-03-06 17:09:07.813066: Epoch: 3, Batch: 63, Loss: 0.4505, Elapsed: 0m5s
2023-03-06 17:09:12.163737: Epoch: 3, Batch: 64, Loss: 0.4448, Elapsed: 0m4s
2023-03-06 17:09:15.260463: Epoch: 3, Batch: 65, Loss: 0.4335, Elapsed: 0m3s
2023-03-06 17:09:17.148389: Epoch: 3, Batch: 66, Loss: 0.4121, Elapsed: 0m1s
2023-03-06 17:09:19.077998: Epoch: 3, Batch: 67, Loss: 0.4146, Elapsed: 0m1s
2023-03-06 17:09:23.949892: Epoch: 3, Batch: 68, Loss: 0.4421, Elapsed: 0m4s
2023-03-06 17:09:25.894713: Epoch: 3, Batch: 69, Loss: 0.4077, Elapsed: 0m1s
2023-03-06 17:09:31.544213: Epoch: 3, Batch: 70, Loss: 0.4518, Elapsed: 0m5s
2023-03-06 17:09:34.108120: Epoch: 3, Batch: 71, Loss: 0.4227, Elapsed: 0m2s
2023-03-06 17:09:36.309586: Epoch: 3, Batch: 72, Loss: 0.4142, Elapsed: 0m2s
2023-03-06 17:09:39.290420: Epoch: 3, Batch: 73, Loss: 0.4333, Elapsed: 0m2s
2023-03-06 17:09:42.040113: Epoch: 3, Batch: 74, Loss: 0.4263, Elapsed: 0m2s
2023-03-06 17:09:44.022332: Epoch: 3, Batch: 75, Loss: 0.4113, Elapsed: 0m1s
2023-03-06 17:09:46.969609: Epoch: 3, Batch: 76, Loss: 0.4196, Elapsed: 0m2s
2023-03-06 17:09:49.250933: Epoch: 3, Batch: 77, Loss: 0.4213, Elapsed: 0m2s
2023-03-06 17:09:53.312934: Epoch: 3, Batch: 78, Loss: 0.4548, Elapsed: 0m4s
2023-03-06 17:09:55.462998: Epoch: 3, Batch: 79, Loss: 0.4062, Elapsed: 0m2s
2023-03-06 17:09:58.275979: Epoch: 3, Batch: 80, Loss: 0.4297, Elapsed: 0m2s
2023-03-06 17:09:59.935846: Epoch: 4, Batch: 1, Loss: 0.3911, Elapsed: 0m1s
2023-03-06 17:10:02.437230: Epoch: 4, Batch: 2, Loss: 0.4248, Elapsed: 0m2s
2023-03-06 17:10:07.412582: Epoch: 4, Batch: 3, Loss: 0.4395, Elapsed: 0m4s
2023-03-06 17:10:09.924817: Epoch: 4, Batch: 4, Loss: 0.4106, Elapsed: 0m2s
2023-03-06 17:10:12.800533: Epoch: 4, Batch: 5, Loss: 0.4249, Elapsed: 0m2s
2023-03-06 17:10:15.746364: Epoch: 4, Batch: 6, Loss: 0.4180, Elapsed: 0m2s
2023-03-06 17:10:18.320494: Epoch: 4, Batch: 7, Loss: 0.4303, Elapsed: 0m2s
2023-03-06 17:10:23.139178: Epoch: 4, Batch: 8, Loss: 0.4414, Elapsed: 0m4s
2023-03-06 17:10:25.076999: Epoch: 4, Batch: 9, Loss: 0.4045, Elapsed: 0m1s
2023-03-06 17:10:28.658739: Epoch: 4, Batch: 10, Loss: 0.4336, Elapsed: 0m3s
2023-03-06 17:10:31.036542: Epoch: 4, Batch: 11, Loss: 0.4220, Elapsed: 0m2s
2023-03-06 17:10:33.028489: Epoch: 4, Batch: 12, Loss: 0.4189, Elapsed: 0m1s
2023-03-06 17:10:35.992142: Epoch: 4, Batch: 13, Loss: 0.4199, Elapsed: 0m2s
2023-03-06 17:10:38.842661: Epoch: 4, Batch: 14, Loss: 0.4175, Elapsed: 0m2s
2023-03-06 17:10:43.072036: Epoch: 4, Batch: 15, Loss: 0.4442, Elapsed: 0m4s
2023-03-06 17:10:46.479669: Epoch: 4, Batch: 16, Loss: 0.4257, Elapsed: 0m3s
2023-03-06 17:10:49.490707: Epoch: 4, Batch: 17, Loss: 0.4279, Elapsed: 0m3s
2023-03-06 17:10:52.292943: Epoch: 4, Batch: 18, Loss: 0.4265, Elapsed: 0m2s
2023-03-06 17:10:54.501007: Epoch: 4, Batch: 19, Loss: 0.4101, Elapsed: 0m2s
2023-03-06 17:10:57.495361: Epoch: 4, Batch: 20, Loss: 0.4280, Elapsed: 0m2s
2023-03-06 17:10:59.109889: Epoch: 4, Batch: 21, Loss: 0.3904, Elapsed: 0m1s
2023-03-06 17:11:03.621057: Epoch: 4, Batch: 22, Loss: 0.4437, Elapsed: 0m4s
2023-03-06 17:11:06.378428: Epoch: 4, Batch: 23, Loss: 0.4215, Elapsed: 0m2s
2023-03-06 17:11:10.926291: Epoch: 4, Batch: 24, Loss: 0.4348, Elapsed: 0m4s
2023-03-06 17:11:16.791875: Epoch: 4, Batch: 25, Loss: 0.4033, Elapsed: 0m5s
2023-03-06 17:11:19.587249: Epoch: 4, Batch: 26, Loss: 0.4192, Elapsed: 0m2s
2023-03-06 17:11:22.497799: Epoch: 4, Batch: 27, Loss: 0.4353, Elapsed: 0m2s
2023-03-06 17:11:26.049088: Epoch: 4, Batch: 28, Loss: 0.4261, Elapsed: 0m3s
2023-03-06 17:11:28.384011: Epoch: 4, Batch: 29, Loss: 0.4112, Elapsed: 0m2s
2023-03-06 17:11:32.530697: Epoch: 4, Batch: 30, Loss: 0.4358, Elapsed: 0m4s
2023-03-06 17:11:37.615444: Epoch: 4, Batch: 31, Loss: 0.4407, Elapsed: 0m5s
2023-03-06 17:11:39.541731: Epoch: 4, Batch: 32, Loss: 0.4069, Elapsed: 0m1s
2023-03-06 17:11:41.929353: Epoch: 4, Batch: 33, Loss: 0.3925, Elapsed: 0m2s
2023-03-06 17:11:45.352599: Epoch: 4, Batch: 34, Loss: 0.4270, Elapsed: 0m3s
2023-03-06 17:11:48.843478: Epoch: 4, Batch: 35, Loss: 0.4374, Elapsed: 0m3s
2023-03-06 17:11:51.007738: Epoch: 4, Batch: 36, Loss: 0.4112, Elapsed: 0m2s
2023-03-06 17:11:53.572858: Epoch: 4, Batch: 37, Loss: 0.4156, Elapsed: 0m2s
2023-03-06 17:11:57.784080: Epoch: 4, Batch: 38, Loss: 0.4367, Elapsed: 0m4s
2023-03-06 17:12:00.981482: Epoch: 4, Batch: 39, Loss: 0.4140, Elapsed: 0m3s
2023-03-06 17:12:07.224991: Epoch: 4, Batch: 40, Loss: 0.4480, Elapsed: 0m6s
2023-03-06 17:12:11.639142: Epoch: 4, Batch: 41, Loss: 0.4363, Elapsed: 0m4s
2023-03-06 17:12:12.655471: Epoch: 4, Batch: 42, Loss: 0.3555, Elapsed: 0m1s
2023-03-06 17:12:16.337406: Epoch: 4, Batch: 43, Loss: 0.4304, Elapsed: 0m3s
2023-03-06 17:12:18.353559: Epoch: 4, Batch: 44, Loss: 0.4113, Elapsed: 0m2s
2023-03-06 17:12:20.186771: Epoch: 4, Batch: 45, Loss: 0.3963, Elapsed: 0m1s
2023-03-06 17:12:22.668078: Epoch: 4, Batch: 46, Loss: 0.4168, Elapsed: 0m2s
2023-03-06 17:12:27.104052: Epoch: 4, Batch: 47, Loss: 0.4346, Elapsed: 0m4s
2023-03-06 17:12:29.198529: Epoch: 4, Batch: 48, Loss: 0.4034, Elapsed: 0m2s
2023-03-06 17:12:32.262626: Epoch: 4, Batch: 49, Loss: 0.4295, Elapsed: 0m3s
2023-03-06 17:12:34.721298: Epoch: 4, Batch: 50, Loss: 0.4058, Elapsed: 0m2s
2023-03-06 17:12:34.731874 Starting testing the valid set with 20 subgraphs!
2023-03-06 17:13:40.671022: validation Test:  Loss: 0.4210,  AUC: 0.8675, Acc: 78.6283,  Precision: 0.8499 -- Elapsed: 1m5s
2023-03-06 17:13:40.672235 Starting testing the train set with 20 subgraphs!
2023-03-06 17:18:05.576838: training Test:  Loss: 0.4197,  AUC: 0.8682, Acc: 78.6991,  Precision: 0.8497 -- Elapsed: 4m24s
2023-03-06 17:18:07.747994: Epoch: 4, Batch: 51, Loss: 0.3981, Elapsed: 0m2s
2023-03-06 17:18:10.257216: Epoch: 4, Batch: 52, Loss: 0.4157, Elapsed: 0m2s
2023-03-06 17:18:13.725757: Epoch: 4, Batch: 53, Loss: 0.4316, Elapsed: 0m3s
2023-03-06 17:18:19.183083: Epoch: 4, Batch: 54, Loss: 0.4413, Elapsed: 0m5s
2023-03-06 17:18:21.717072: Epoch: 4, Batch: 55, Loss: 0.4084, Elapsed: 0m2s
2023-03-06 17:18:24.548715: Epoch: 4, Batch: 56, Loss: 0.4161, Elapsed: 0m2s
2023-03-06 17:18:27.601280: Epoch: 4, Batch: 57, Loss: 0.4251, Elapsed: 0m3s
2023-03-06 17:18:29.299549: Epoch: 4, Batch: 58, Loss: 0.4001, Elapsed: 0m1s
2023-03-06 17:18:31.172881: Epoch: 4, Batch: 59, Loss: 0.4010, Elapsed: 0m1s
2023-03-06 17:18:34.429600: Epoch: 4, Batch: 60, Loss: 0.4210, Elapsed: 0m3s
2023-03-06 17:18:36.352957: Epoch: 4, Batch: 61, Loss: 0.3818, Elapsed: 0m1s
2023-03-06 17:18:37.663926: Epoch: 4, Batch: 62, Loss: 0.3610, Elapsed: 0m1s
2023-03-06 17:18:41.467364: Epoch: 4, Batch: 63, Loss: 0.4312, Elapsed: 0m3s
2023-03-06 17:18:43.914042: Epoch: 4, Batch: 64, Loss: 0.4078, Elapsed: 0m2s
2023-03-06 17:18:49.537701: Epoch: 4, Batch: 65, Loss: 0.4414, Elapsed: 0m5s
2023-03-06 17:18:53.383056: Epoch: 4, Batch: 66, Loss: 0.4363, Elapsed: 0m3s
2023-03-06 17:18:55.036821: Epoch: 4, Batch: 67, Loss: 0.3805, Elapsed: 0m1s
2023-03-06 17:18:59.227145: Epoch: 4, Batch: 68, Loss: 0.4311, Elapsed: 0m4s
2023-03-06 17:19:03.587524: Epoch: 4, Batch: 69, Loss: 0.4286, Elapsed: 0m4s
2023-03-06 17:19:06.404686: Epoch: 4, Batch: 70, Loss: 0.4099, Elapsed: 0m2s
2023-03-06 17:19:09.131458: Epoch: 4, Batch: 71, Loss: 0.4139, Elapsed: 0m2s
2023-03-06 17:19:13.265535: Epoch: 4, Batch: 72, Loss: 0.4452, Elapsed: 0m4s
2023-03-06 17:19:15.822318: Epoch: 4, Batch: 73, Loss: 0.4070, Elapsed: 0m2s
2023-03-06 17:19:19.278974: Epoch: 4, Batch: 74, Loss: 0.4266, Elapsed: 0m3s
2023-03-06 17:19:22.318538: Epoch: 4, Batch: 75, Loss: 0.4226, Elapsed: 0m3s
2023-03-06 17:19:24.529152: Epoch: 4, Batch: 76, Loss: 0.3924, Elapsed: 0m2s
2023-03-06 17:19:27.596551: Epoch: 4, Batch: 77, Loss: 0.4232, Elapsed: 0m3s
2023-03-06 17:19:29.888821: Epoch: 4, Batch: 78, Loss: 0.4105, Elapsed: 0m2s
2023-03-06 17:19:33.553690: Epoch: 4, Batch: 79, Loss: 0.4253, Elapsed: 0m3s
2023-03-06 17:19:36.487858: Epoch: 4, Batch: 80, Loss: 0.4037, Elapsed: 0m2s
2023-03-06 17:19:39.863627: Epoch: 5, Batch: 1, Loss: 0.4192, Elapsed: 0m3s
2023-03-06 17:19:42.845747: Epoch: 5, Batch: 2, Loss: 0.4080, Elapsed: 0m2s
2023-03-06 17:19:47.157631: Epoch: 5, Batch: 3, Loss: 0.4307, Elapsed: 0m4s
2023-03-06 17:19:49.093197: Epoch: 5, Batch: 4, Loss: 0.3989, Elapsed: 0m1s
2023-03-06 17:19:51.988250: Epoch: 5, Batch: 5, Loss: 0.4149, Elapsed: 0m2s
2023-03-06 17:19:56.409726: Epoch: 5, Batch: 6, Loss: 0.4300, Elapsed: 0m4s
2023-03-06 17:19:58.968123: Epoch: 5, Batch: 7, Loss: 0.4098, Elapsed: 0m2s
2023-03-06 17:20:01.635767: Epoch: 5, Batch: 8, Loss: 0.4050, Elapsed: 0m2s
2023-03-06 17:20:04.101822: Epoch: 5, Batch: 9, Loss: 0.3855, Elapsed: 0m2s
2023-03-06 17:20:08.507828: Epoch: 5, Batch: 10, Loss: 0.4260, Elapsed: 0m4s
2023-03-06 17:20:14.196155: Epoch: 5, Batch: 11, Loss: 0.4376, Elapsed: 0m5s
2023-03-06 17:20:20.635646: Epoch: 5, Batch: 12, Loss: 0.4384, Elapsed: 0m6s
2023-03-06 17:20:23.409818: Epoch: 5, Batch: 13, Loss: 0.3974, Elapsed: 0m2s
2023-03-06 17:20:28.790719: Epoch: 5, Batch: 14, Loss: 0.3912, Elapsed: 0m5s
2023-03-06 17:20:32.950222: Epoch: 5, Batch: 15, Loss: 0.4281, Elapsed: 0m4s
2023-03-06 17:20:35.829701: Epoch: 5, Batch: 16, Loss: 0.4073, Elapsed: 0m2s
2023-03-06 17:20:37.129514: Epoch: 5, Batch: 17, Loss: 0.3561, Elapsed: 0m1s
2023-03-06 17:20:40.084181: Epoch: 5, Batch: 18, Loss: 0.4207, Elapsed: 0m2s
2023-03-06 17:20:43.210775: Epoch: 5, Batch: 19, Loss: 0.4215, Elapsed: 0m3s
2023-03-06 17:20:47.369853: Epoch: 5, Batch: 20, Loss: 0.4249, Elapsed: 0m4s
2023-03-06 17:20:50.880385: Epoch: 5, Batch: 21, Loss: 0.4304, Elapsed: 0m3s
2023-03-06 17:20:53.136094: Epoch: 5, Batch: 22, Loss: 0.3987, Elapsed: 0m2s
2023-03-06 17:20:56.610350: Epoch: 5, Batch: 23, Loss: 0.4135, Elapsed: 0m3s
2023-03-06 17:20:59.564485: Epoch: 5, Batch: 24, Loss: 0.4046, Elapsed: 0m2s
2023-03-06 17:21:02.047201: Epoch: 5, Batch: 25, Loss: 0.4196, Elapsed: 0m2s
2023-03-06 17:21:05.029830: Epoch: 5, Batch: 26, Loss: 0.4063, Elapsed: 0m2s
2023-03-06 17:21:08.597716: Epoch: 5, Batch: 27, Loss: 0.4237, Elapsed: 0m3s
2023-03-06 17:21:13.208313: Epoch: 5, Batch: 28, Loss: 0.4292, Elapsed: 0m4s
2023-03-06 17:21:16.461378: Epoch: 5, Batch: 29, Loss: 0.4150, Elapsed: 0m3s
2023-03-06 17:21:18.959304: Epoch: 5, Batch: 30, Loss: 0.4090, Elapsed: 0m2s
2023-03-06 17:21:21.339994: Epoch: 5, Batch: 31, Loss: 0.4092, Elapsed: 0m2s
2023-03-06 17:21:23.973508: Epoch: 5, Batch: 32, Loss: 0.4117, Elapsed: 0m2s
2023-03-06 17:21:25.667310: Epoch: 5, Batch: 33, Loss: 0.3936, Elapsed: 0m1s
2023-03-06 17:21:27.582478: Epoch: 5, Batch: 34, Loss: 0.3950, Elapsed: 0m1s
2023-03-06 17:21:29.603128: Epoch: 5, Batch: 35, Loss: 0.3971, Elapsed: 0m2s
2023-03-06 17:21:31.787947: Epoch: 5, Batch: 36, Loss: 0.3879, Elapsed: 0m2s
2023-03-06 17:21:34.060376: Epoch: 5, Batch: 37, Loss: 0.4008, Elapsed: 0m2s
2023-03-06 17:21:36.598084: Epoch: 5, Batch: 38, Loss: 0.4093, Elapsed: 0m2s
2023-03-06 17:21:39.434391: Epoch: 5, Batch: 39, Loss: 0.4130, Elapsed: 0m2s
2023-03-06 17:21:41.589427: Epoch: 5, Batch: 40, Loss: 0.3911, Elapsed: 0m2s
2023-03-06 17:21:43.139241: Epoch: 5, Batch: 41, Loss: 0.3747, Elapsed: 0m1s
2023-03-06 17:21:48.026108: Epoch: 5, Batch: 42, Loss: 0.4272, Elapsed: 0m4s
2023-03-06 17:21:49.639764: Epoch: 5, Batch: 43, Loss: 0.3785, Elapsed: 0m1s
2023-03-06 17:21:53.048752: Epoch: 5, Batch: 44, Loss: 0.4175, Elapsed: 0m3s
2023-03-06 17:21:55.522203: Epoch: 5, Batch: 45, Loss: 0.3983, Elapsed: 0m2s
2023-03-06 17:21:58.551142: Epoch: 5, Batch: 46, Loss: 0.4145, Elapsed: 0m3s
2023-03-06 17:22:02.567469: Epoch: 5, Batch: 47, Loss: 0.4265, Elapsed: 0m4s
2023-03-06 17:22:05.599793: Epoch: 5, Batch: 48, Loss: 0.4189, Elapsed: 0m3s
2023-03-06 17:22:10.262515: Epoch: 5, Batch: 49, Loss: 0.4324, Elapsed: 0m4s
2023-03-06 17:22:13.348000: Epoch: 5, Batch: 50, Loss: 0.4159, Elapsed: 0m3s
2023-03-06 17:22:13.357192 Starting testing the valid set with 20 subgraphs!
2023-03-06 17:23:20.543876: validation Test:  Loss: 0.4135,  AUC: 0.8721, Acc: 78.9240,  Precision: 0.8497 -- Elapsed: 1m7s
2023-03-06 17:23:20.545176 Starting testing the train set with 20 subgraphs!
2023-03-06 17:27:43.347484: training Test:  Loss: 0.4122,  AUC: 0.8730, Acc: 79.0463,  Precision: 0.8506 -- Elapsed: 4m22s
2023-03-06 17:27:46.056816: Epoch: 5, Batch: 51, Loss: 0.4225, Elapsed: 0m2s
2023-03-06 17:27:49.012237: Epoch: 5, Batch: 52, Loss: 0.3993, Elapsed: 0m2s
2023-03-06 17:27:51.842119: Epoch: 5, Batch: 53, Loss: 0.4085, Elapsed: 0m2s
2023-03-06 17:27:53.522873: Epoch: 5, Batch: 54, Loss: 0.3754, Elapsed: 0m1s
2023-03-06 17:27:54.542178: Epoch: 5, Batch: 55, Loss: 0.3458, Elapsed: 0m1s
2023-03-06 17:27:57.146242: Epoch: 5, Batch: 56, Loss: 0.4056, Elapsed: 0m2s
2023-03-06 17:28:00.812896: Epoch: 5, Batch: 57, Loss: 0.4211, Elapsed: 0m3s
2023-03-06 17:28:02.700364: Epoch: 5, Batch: 58, Loss: 0.3863, Elapsed: 0m1s
2023-03-06 17:28:06.558407: Epoch: 5, Batch: 59, Loss: 0.4251, Elapsed: 0m3s
2023-03-06 17:28:10.022400: Epoch: 5, Batch: 60, Loss: 0.4232, Elapsed: 0m3s
2023-03-06 17:28:15.149754: Epoch: 5, Batch: 61, Loss: 0.4311, Elapsed: 0m5s
2023-03-06 17:28:17.940464: Epoch: 5, Batch: 62, Loss: 0.4081, Elapsed: 0m2s
2023-03-06 17:28:20.168618: Epoch: 5, Batch: 63, Loss: 0.4001, Elapsed: 0m2s
2023-03-06 17:28:24.331783: Epoch: 5, Batch: 64, Loss: 0.4407, Elapsed: 0m4s
2023-03-06 17:28:27.991978: Epoch: 5, Batch: 65, Loss: 0.4213, Elapsed: 0m3s
2023-03-06 17:28:29.921088: Epoch: 5, Batch: 66, Loss: 0.3893, Elapsed: 0m1s
2023-03-06 17:28:33.756558: Epoch: 5, Batch: 67, Loss: 0.4303, Elapsed: 0m3s
2023-03-06 17:28:37.044261: Epoch: 5, Batch: 68, Loss: 0.4017, Elapsed: 0m3s
2023-03-06 17:28:41.265960: Epoch: 5, Batch: 69, Loss: 0.4277, Elapsed: 0m4s
2023-03-06 17:28:43.278905: Epoch: 5, Batch: 70, Loss: 0.4019, Elapsed: 0m2s
2023-03-06 17:28:45.778298: Epoch: 5, Batch: 71, Loss: 0.4074, Elapsed: 0m2s
2023-03-06 17:28:49.941948: Epoch: 5, Batch: 72, Loss: 0.4309, Elapsed: 0m4s
2023-03-06 17:28:52.365695: Epoch: 5, Batch: 73, Loss: 0.4002, Elapsed: 0m2s
2023-03-06 17:28:56.033120: Epoch: 5, Batch: 74, Loss: 0.4204, Elapsed: 0m3s
2023-03-06 17:28:58.323042: Epoch: 5, Batch: 75, Loss: 0.4064, Elapsed: 0m2s
2023-03-06 17:29:00.327052: Epoch: 5, Batch: 76, Loss: 0.4032, Elapsed: 0m1s
2023-03-06 17:29:02.839378: Epoch: 5, Batch: 77, Loss: 0.4004, Elapsed: 0m2s
2023-03-06 17:29:05.817226: Epoch: 5, Batch: 78, Loss: 0.4199, Elapsed: 0m2s
2023-03-06 17:29:07.823728: Epoch: 5, Batch: 79, Loss: 0.3736, Elapsed: 0m1s
2023-03-06 17:29:14.355047: Epoch: 5, Batch: 80, Loss: 0.4404, Elapsed: 0m6s
2023-03-06 17:29:17.068757: Epoch: 6, Batch: 1, Loss: 0.3939, Elapsed: 0m2s
2023-03-06 17:29:23.881554: Epoch: 6, Batch: 2, Loss: 0.4406, Elapsed: 0m6s
2023-03-06 17:29:26.222942: Epoch: 6, Batch: 3, Loss: 0.4015, Elapsed: 0m2s
2023-03-06 17:29:32.751116: Epoch: 6, Batch: 4, Loss: 0.4350, Elapsed: 0m6s
2023-03-06 17:29:36.703647: Epoch: 6, Batch: 5, Loss: 0.4281, Elapsed: 0m3s
2023-03-06 17:29:39.604366: Epoch: 6, Batch: 6, Loss: 0.3969, Elapsed: 0m2s
2023-03-06 17:29:44.683122: Epoch: 6, Batch: 7, Loss: 0.4263, Elapsed: 0m5s
2023-03-06 17:29:47.635580: Epoch: 6, Batch: 8, Loss: 0.4010, Elapsed: 0m2s
2023-03-06 17:29:52.111391: Epoch: 6, Batch: 9, Loss: 0.4221, Elapsed: 0m4s
2023-03-06 17:29:54.728841: Epoch: 6, Batch: 10, Loss: 0.4077, Elapsed: 0m2s
2023-03-06 17:29:58.797261: Epoch: 6, Batch: 11, Loss: 0.4240, Elapsed: 0m4s
2023-03-06 17:30:00.580298: Epoch: 6, Batch: 12, Loss: 0.3741, Elapsed: 0m1s
2023-03-06 17:30:02.621849: Epoch: 6, Batch: 13, Loss: 0.4026, Elapsed: 0m2s
2023-03-06 17:30:05.696875: Epoch: 6, Batch: 14, Loss: 0.4184, Elapsed: 0m3s
2023-03-06 17:30:09.106901: Epoch: 6, Batch: 15, Loss: 0.4109, Elapsed: 0m3s
2023-03-06 17:30:12.282483: Epoch: 6, Batch: 16, Loss: 0.4007, Elapsed: 0m3s
2023-03-06 17:30:16.762768: Epoch: 6, Batch: 17, Loss: 0.4260, Elapsed: 0m4s
2023-03-06 17:30:19.212412: Epoch: 6, Batch: 18, Loss: 0.4061, Elapsed: 0m2s
2023-03-06 17:30:21.553965: Epoch: 6, Batch: 19, Loss: 0.4060, Elapsed: 0m2s
2023-03-06 17:30:25.747230: Epoch: 6, Batch: 20, Loss: 0.4248, Elapsed: 0m4s
2023-03-06 17:30:27.677500: Epoch: 6, Batch: 21, Loss: 0.3883, Elapsed: 0m1s
2023-03-06 17:30:30.619843: Epoch: 6, Batch: 22, Loss: 0.4019, Elapsed: 0m2s
2023-03-06 17:30:33.033121: Epoch: 6, Batch: 23, Loss: 0.3995, Elapsed: 0m2s
2023-03-06 17:30:35.901041: Epoch: 6, Batch: 24, Loss: 0.4109, Elapsed: 0m2s
2023-03-06 17:30:37.895157: Epoch: 6, Batch: 25, Loss: 0.3949, Elapsed: 0m1s
2023-03-06 17:30:40.882039: Epoch: 6, Batch: 26, Loss: 0.4147, Elapsed: 0m2s
2023-03-06 17:30:43.910220: Epoch: 6, Batch: 27, Loss: 0.4193, Elapsed: 0m3s
2023-03-06 17:30:46.356534: Epoch: 6, Batch: 28, Loss: 0.3992, Elapsed: 0m2s
2023-03-06 17:30:49.015351: Epoch: 6, Batch: 29, Loss: 0.4175, Elapsed: 0m2s
2023-03-06 17:30:51.923452: Epoch: 6, Batch: 30, Loss: 0.4075, Elapsed: 0m2s
2023-03-06 17:30:57.272406: Epoch: 6, Batch: 31, Loss: 0.4335, Elapsed: 0m5s
2023-03-06 17:30:58.816372: Epoch: 6, Batch: 32, Loss: 0.3734, Elapsed: 0m1s
2023-03-06 17:31:03.717254: Epoch: 6, Batch: 33, Loss: 0.4257, Elapsed: 0m4s
2023-03-06 17:31:08.817807: Epoch: 6, Batch: 34, Loss: 0.4306, Elapsed: 0m5s
2023-03-06 17:31:11.201202: Epoch: 6, Batch: 35, Loss: 0.3816, Elapsed: 0m2s
2023-03-06 17:31:13.118423: Epoch: 6, Batch: 36, Loss: 0.3731, Elapsed: 0m1s
2023-03-06 17:31:16.776720: Epoch: 6, Batch: 37, Loss: 0.4194, Elapsed: 0m3s
2023-03-06 17:31:18.647344: Epoch: 6, Batch: 38, Loss: 0.3921, Elapsed: 0m1s
2023-03-06 17:31:21.503081: Epoch: 6, Batch: 39, Loss: 0.4037, Elapsed: 0m2s
2023-03-06 17:31:24.493256: Epoch: 6, Batch: 40, Loss: 0.4026, Elapsed: 0m2s
2023-03-06 17:31:28.326558: Epoch: 6, Batch: 41, Loss: 0.4294, Elapsed: 0m3s
2023-03-06 17:31:32.685819: Epoch: 6, Batch: 42, Loss: 0.4219, Elapsed: 0m4s
2023-03-06 17:31:37.184137: Epoch: 6, Batch: 43, Loss: 0.4309, Elapsed: 0m4s
2023-03-06 17:31:39.980262: Epoch: 6, Batch: 44, Loss: 0.4035, Elapsed: 0m2s
2023-03-06 17:31:43.437732: Epoch: 6, Batch: 45, Loss: 0.4210, Elapsed: 0m3s
2023-03-06 17:31:46.879815: Epoch: 6, Batch: 46, Loss: 0.4212, Elapsed: 0m3s
2023-03-06 17:31:49.715727: Epoch: 6, Batch: 47, Loss: 0.4203, Elapsed: 0m2s
2023-03-06 17:31:52.635502: Epoch: 6, Batch: 48, Loss: 0.4066, Elapsed: 0m2s
2023-03-06 17:31:55.296439: Epoch: 6, Batch: 49, Loss: 0.4058, Elapsed: 0m2s
2023-03-06 17:31:59.433969: Epoch: 6, Batch: 50, Loss: 0.4261, Elapsed: 0m4s
2023-03-06 17:31:59.444171 Starting testing the valid set with 20 subgraphs!
2023-03-06 17:33:08.001412: validation Test:  Loss: 0.4116,  AUC: 0.8728, Acc: 79.0210,  Precision: 0.8682 -- Elapsed: 1m8s
2023-03-06 17:33:08.002586 Starting testing the train set with 20 subgraphs!
2023-03-06 17:37:29.360000: training Test:  Loss: 0.4103,  AUC: 0.8737, Acc: 79.1373,  Precision: 0.8683 -- Elapsed: 4m21s
2023-03-06 17:37:34.527679: Epoch: 6, Batch: 51, Loss: 0.3874, Elapsed: 0m5s
2023-03-06 17:37:36.189140: Epoch: 6, Batch: 52, Loss: 0.3760, Elapsed: 0m1s
2023-03-06 17:37:39.196991: Epoch: 6, Batch: 53, Loss: 0.3975, Elapsed: 0m2s
2023-03-06 17:37:42.616297: Epoch: 6, Batch: 54, Loss: 0.4152, Elapsed: 0m3s
2023-03-06 17:37:44.802370: Epoch: 6, Batch: 55, Loss: 0.3849, Elapsed: 0m2s
2023-03-06 17:37:46.962707: Epoch: 6, Batch: 56, Loss: 0.3881, Elapsed: 0m2s
2023-03-06 17:37:49.137475: Epoch: 6, Batch: 57, Loss: 0.3983, Elapsed: 0m2s
2023-03-06 17:37:51.674131: Epoch: 6, Batch: 58, Loss: 0.3991, Elapsed: 0m2s
2023-03-06 17:37:54.722963: Epoch: 6, Batch: 59, Loss: 0.4170, Elapsed: 0m3s
2023-03-06 17:37:58.088304: Epoch: 6, Batch: 60, Loss: 0.4146, Elapsed: 0m3s
2023-03-06 17:38:02.094815: Epoch: 6, Batch: 61, Loss: 0.4246, Elapsed: 0m3s
2023-03-06 17:38:04.726414: Epoch: 6, Batch: 62, Loss: 0.4087, Elapsed: 0m2s
2023-03-06 17:38:09.333920: Epoch: 6, Batch: 63, Loss: 0.4261, Elapsed: 0m4s
2023-03-06 17:38:12.151830: Epoch: 6, Batch: 64, Loss: 0.4099, Elapsed: 0m2s
2023-03-06 17:38:16.306563: Epoch: 6, Batch: 65, Loss: 0.4391, Elapsed: 0m4s
2023-03-06 17:38:18.238875: Epoch: 6, Batch: 66, Loss: 0.3835, Elapsed: 0m1s
2023-03-06 17:38:22.575912: Epoch: 6, Batch: 67, Loss: 0.4294, Elapsed: 0m4s
2023-03-06 17:38:25.614608: Epoch: 6, Batch: 68, Loss: 0.4124, Elapsed: 0m3s
2023-03-06 17:38:28.217041: Epoch: 6, Batch: 69, Loss: 0.4034, Elapsed: 0m2s
2023-03-06 17:38:29.910664: Epoch: 6, Batch: 70, Loss: 0.3907, Elapsed: 0m1s
2023-03-06 17:38:30.930506: Epoch: 6, Batch: 71, Loss: 0.3433, Elapsed: 0m1s
2023-03-06 17:38:34.746633: Epoch: 6, Batch: 72, Loss: 0.4189, Elapsed: 0m3s
2023-03-06 17:38:37.951595: Epoch: 6, Batch: 73, Loss: 0.4164, Elapsed: 0m3s
2023-03-06 17:38:40.675866: Epoch: 6, Batch: 74, Loss: 0.4044, Elapsed: 0m2s
2023-03-06 17:38:43.313076: Epoch: 6, Batch: 75, Loss: 0.4057, Elapsed: 0m2s
2023-03-06 17:38:44.617521: Epoch: 6, Batch: 76, Loss: 0.3501, Elapsed: 0m1s
2023-03-06 17:38:47.870730: Epoch: 6, Batch: 77, Loss: 0.4108, Elapsed: 0m3s
2023-03-06 17:38:51.539076: Epoch: 6, Batch: 78, Loss: 0.4190, Elapsed: 0m3s
2023-03-06 17:38:53.475426: Epoch: 6, Batch: 79, Loss: 0.3930, Elapsed: 0m1s
2023-03-06 17:38:55.688340: Epoch: 6, Batch: 80, Loss: 0.3940, Elapsed: 0m2s
2023-03-06 17:38:59.877571: Epoch: 7, Batch: 1, Loss: 0.4210, Elapsed: 0m4s
2023-03-06 17:39:02.505772: Epoch: 7, Batch: 2, Loss: 0.3951, Elapsed: 0m2s
2023-03-06 17:39:05.261228: Epoch: 7, Batch: 3, Loss: 0.3993, Elapsed: 0m2s
2023-03-06 17:39:07.348249: Epoch: 7, Batch: 4, Loss: 0.3864, Elapsed: 0m2s
2023-03-06 17:39:11.731766: Epoch: 7, Batch: 5, Loss: 0.4234, Elapsed: 0m4s
2023-03-06 17:39:13.921869: Epoch: 7, Batch: 6, Loss: 0.3843, Elapsed: 0m2s
2023-03-06 17:39:18.362618: Epoch: 7, Batch: 7, Loss: 0.4247, Elapsed: 0m4s
2023-03-06 17:39:23.711912: Epoch: 7, Batch: 8, Loss: 0.3865, Elapsed: 0m5s
2023-03-06 17:39:25.829004: Epoch: 7, Batch: 9, Loss: 0.3997, Elapsed: 0m2s
2023-03-06 17:39:29.102081: Epoch: 7, Batch: 10, Loss: 0.3985, Elapsed: 0m3s
2023-03-06 17:39:32.771959: Epoch: 7, Batch: 11, Loss: 0.4184, Elapsed: 0m3s
2023-03-06 17:39:35.278184: Epoch: 7, Batch: 12, Loss: 0.4052, Elapsed: 0m2s
2023-03-06 17:39:38.346339: Epoch: 7, Batch: 13, Loss: 0.4164, Elapsed: 0m3s
2023-03-06 17:39:40.863044: Epoch: 7, Batch: 14, Loss: 0.3914, Elapsed: 0m2s
2023-03-06 17:39:43.449220: Epoch: 7, Batch: 15, Loss: 0.4030, Elapsed: 0m2s
2023-03-06 17:39:45.376442: Epoch: 7, Batch: 16, Loss: 0.3916, Elapsed: 0m1s
2023-03-06 17:39:48.412621: Epoch: 7, Batch: 17, Loss: 0.4160, Elapsed: 0m3s
2023-03-06 17:39:51.296586: Epoch: 7, Batch: 18, Loss: 0.4049, Elapsed: 0m2s
2023-03-06 17:39:52.908967: Epoch: 7, Batch: 19, Loss: 0.3747, Elapsed: 0m1s
2023-03-06 17:39:55.857364: Epoch: 7, Batch: 20, Loss: 0.4004, Elapsed: 0m2s
2023-03-06 17:39:59.998020: Epoch: 7, Batch: 21, Loss: 0.4284, Elapsed: 0m4s
2023-03-06 17:40:03.378378: Epoch: 7, Batch: 22, Loss: 0.4137, Elapsed: 0m3s
2023-03-06 17:40:07.204949: Epoch: 7, Batch: 23, Loss: 0.4216, Elapsed: 0m3s
2023-03-06 17:40:10.775741: Epoch: 7, Batch: 24, Loss: 0.4180, Elapsed: 0m3s
2023-03-06 17:40:15.290847: Epoch: 7, Batch: 25, Loss: 0.4292, Elapsed: 0m4s
2023-03-06 17:40:20.953683: Epoch: 7, Batch: 26, Loss: 0.4320, Elapsed: 0m5s
2023-03-06 17:40:23.343501: Epoch: 7, Batch: 27, Loss: 0.4035, Elapsed: 0m2s
2023-03-06 17:40:25.266662: Epoch: 7, Batch: 28, Loss: 0.3707, Elapsed: 0m1s
2023-03-06 17:40:28.275578: Epoch: 7, Batch: 29, Loss: 0.4088, Elapsed: 0m2s
2023-03-06 17:40:32.261968: Epoch: 7, Batch: 30, Loss: 0.4275, Elapsed: 0m3s
2023-03-06 17:40:36.876361: Epoch: 7, Batch: 31, Loss: 0.4246, Elapsed: 0m4s
2023-03-06 17:40:39.897582: Epoch: 7, Batch: 32, Loss: 0.4112, Elapsed: 0m3s
2023-03-06 17:40:42.387679: Epoch: 7, Batch: 33, Loss: 0.4151, Elapsed: 0m2s
2023-03-06 17:40:47.499178: Epoch: 7, Batch: 34, Loss: 0.4275, Elapsed: 0m5s
2023-03-06 17:40:50.008160: Epoch: 7, Batch: 35, Loss: 0.4032, Elapsed: 0m2s
2023-03-06 17:40:53.420743: Epoch: 7, Batch: 36, Loss: 0.4085, Elapsed: 0m3s
2023-03-06 17:40:56.361801: Epoch: 7, Batch: 37, Loss: 0.3954, Elapsed: 0m2s
2023-03-06 17:40:59.099056: Epoch: 7, Batch: 38, Loss: 0.4048, Elapsed: 0m2s
2023-03-06 17:41:02.004459: Epoch: 7, Batch: 39, Loss: 0.4010, Elapsed: 0m2s
2023-03-06 17:41:04.250175: Epoch: 7, Batch: 40, Loss: 0.3930, Elapsed: 0m2s
2023-03-06 17:41:06.553353: Epoch: 7, Batch: 41, Loss: 0.4023, Elapsed: 0m2s
2023-03-06 17:41:08.252332: Epoch: 7, Batch: 42, Loss: 0.3886, Elapsed: 0m1s
2023-03-06 17:41:11.146072: Epoch: 7, Batch: 43, Loss: 0.4090, Elapsed: 0m2s
2023-03-06 17:41:18.526359: Epoch: 7, Batch: 44, Loss: 0.4370, Elapsed: 0m7s
2023-03-06 17:41:24.072288: Epoch: 7, Batch: 45, Loss: 0.4312, Elapsed: 0m5s
2023-03-06 17:41:27.872596: Epoch: 7, Batch: 46, Loss: 0.4168, Elapsed: 0m3s
2023-03-06 17:41:31.844120: Epoch: 7, Batch: 47, Loss: 0.4248, Elapsed: 0m3s
2023-03-06 17:41:35.475605: Epoch: 7, Batch: 48, Loss: 0.4091, Elapsed: 0m3s
2023-03-06 17:41:38.849168: Epoch: 7, Batch: 49, Loss: 0.4146, Elapsed: 0m3s
2023-03-06 17:41:41.673601: Epoch: 7, Batch: 50, Loss: 0.4180, Elapsed: 0m2s
2023-03-06 17:41:41.683849 Starting testing the valid set with 20 subgraphs!
2023-03-06 17:42:48.418337: validation Test:  Loss: 0.4094,  AUC: 0.8730, Acc: 79.0397,  Precision: 0.8193 -- Elapsed: 1m6s
2023-03-06 17:42:48.419491 Starting testing the train set with 20 subgraphs!
2023-03-06 17:47:10.718140: training Test:  Loss: 0.4081,  AUC: 0.8739, Acc: 79.1355,  Precision: 0.8203 -- Elapsed: 4m22s
2023-03-06 17:47:12.716725: Epoch: 7, Batch: 51, Loss: 0.3989, Elapsed: 0m1s
2023-03-06 17:47:15.537415: Epoch: 7, Batch: 52, Loss: 0.4014, Elapsed: 0m2s
2023-03-06 17:47:19.962331: Epoch: 7, Batch: 53, Loss: 0.4198, Elapsed: 0m4s
2023-03-06 17:47:21.603789: Epoch: 7, Batch: 54, Loss: 0.3695, Elapsed: 0m1s
2023-03-06 17:47:23.915303: Epoch: 7, Batch: 55, Loss: 0.3861, Elapsed: 0m2s
2023-03-06 17:47:27.123748: Epoch: 7, Batch: 56, Loss: 0.4110, Elapsed: 0m3s
2023-03-06 17:47:31.456430: Epoch: 7, Batch: 57, Loss: 0.4235, Elapsed: 0m4s
2023-03-06 17:47:33.964927: Epoch: 7, Batch: 58, Loss: 0.4045, Elapsed: 0m2s
2023-03-06 17:47:36.395344: Epoch: 7, Batch: 59, Loss: 0.3966, Elapsed: 0m2s
2023-03-06 17:47:40.735664: Epoch: 7, Batch: 60, Loss: 0.4226, Elapsed: 0m4s
2023-03-06 17:47:44.156091: Epoch: 7, Batch: 61, Loss: 0.4135, Elapsed: 0m3s
2023-03-06 17:47:45.995002: Epoch: 7, Batch: 62, Loss: 0.3804, Elapsed: 0m1s
2023-03-06 17:47:48.529331: Epoch: 7, Batch: 63, Loss: 0.3963, Elapsed: 0m2s
2023-03-06 17:47:49.830060: Epoch: 7, Batch: 64, Loss: 0.3476, Elapsed: 0m1s
2023-03-06 17:47:51.820568: Epoch: 7, Batch: 65, Loss: 0.3908, Elapsed: 0m1s
2023-03-06 17:47:53.502104: Epoch: 7, Batch: 66, Loss: 0.3708, Elapsed: 0m1s
2023-03-06 17:47:55.776549: Epoch: 7, Batch: 67, Loss: 0.3960, Elapsed: 0m2s
2023-03-06 17:48:00.048816: Epoch: 7, Batch: 68, Loss: 0.4219, Elapsed: 0m4s
2023-03-06 17:48:03.665575: Epoch: 7, Batch: 69, Loss: 0.4182, Elapsed: 0m3s
2023-03-06 17:48:06.614884: Epoch: 7, Batch: 70, Loss: 0.3993, Elapsed: 0m2s
2023-03-06 17:48:10.838299: Epoch: 7, Batch: 71, Loss: 0.4362, Elapsed: 0m4s
2023-03-06 17:48:12.844497: Epoch: 7, Batch: 72, Loss: 0.3889, Elapsed: 0m1s
2023-03-06 17:48:13.943457: Epoch: 7, Batch: 73, Loss: 0.3410, Elapsed: 0m1s
2023-03-06 17:48:17.142823: Epoch: 7, Batch: 74, Loss: 0.4161, Elapsed: 0m3s
2023-03-06 17:48:19.626240: Epoch: 7, Batch: 75, Loss: 0.3792, Elapsed: 0m2s
2023-03-06 17:48:22.241685: Epoch: 7, Batch: 76, Loss: 0.4068, Elapsed: 0m2s
2023-03-06 17:48:24.405383: Epoch: 7, Batch: 77, Loss: 0.3974, Elapsed: 0m2s
2023-03-06 17:48:29.275038: Epoch: 7, Batch: 78, Loss: 0.4223, Elapsed: 0m4s
2023-03-06 17:48:31.760685: Epoch: 7, Batch: 79, Loss: 0.4037, Elapsed: 0m2s
2023-03-06 17:48:35.204439: Epoch: 7, Batch: 80, Loss: 0.4181, Elapsed: 0m3s
2023-03-06 17:48:39.405023: Epoch: 8, Batch: 1, Loss: 0.4212, Elapsed: 0m4s
2023-03-06 17:48:42.565413: Epoch: 8, Batch: 2, Loss: 0.3964, Elapsed: 0m3s
2023-03-06 17:48:44.952674: Epoch: 8, Batch: 3, Loss: 0.3782, Elapsed: 0m2s
2023-03-06 17:48:48.441676: Epoch: 8, Batch: 4, Loss: 0.4239, Elapsed: 0m3s
2023-03-06 17:48:52.638016: Epoch: 8, Batch: 5, Loss: 0.4273, Elapsed: 0m4s
2023-03-06 17:48:55.498999: Epoch: 8, Batch: 6, Loss: 0.4076, Elapsed: 0m2s
2023-03-06 17:48:58.425525: Epoch: 8, Batch: 7, Loss: 0.3941, Elapsed: 0m2s
2023-03-06 17:49:02.584828: Epoch: 8, Batch: 8, Loss: 0.4215, Elapsed: 0m4s
2023-03-06 17:49:03.675502: Epoch: 8, Batch: 9, Loss: 0.3400, Elapsed: 0m1s
2023-03-06 17:49:05.762472: Epoch: 8, Batch: 10, Loss: 0.3899, Elapsed: 0m2s
2023-03-06 17:49:11.459132: Epoch: 8, Batch: 11, Loss: 0.4300, Elapsed: 0m5s
2023-03-06 17:49:13.441575: Epoch: 8, Batch: 12, Loss: 0.3971, Elapsed: 0m1s
2023-03-06 17:49:15.929914: Epoch: 8, Batch: 13, Loss: 0.4133, Elapsed: 0m2s
2023-03-06 17:49:19.368387: Epoch: 8, Batch: 14, Loss: 0.4170, Elapsed: 0m3s
2023-03-06 17:49:24.235712: Epoch: 8, Batch: 15, Loss: 0.4216, Elapsed: 0m4s
2023-03-06 17:49:27.224094: Epoch: 8, Batch: 16, Loss: 0.4092, Elapsed: 0m2s
2023-03-06 17:49:29.867133: Epoch: 8, Batch: 17, Loss: 0.4008, Elapsed: 0m2s
2023-03-06 17:49:32.404573: Epoch: 8, Batch: 18, Loss: 0.4022, Elapsed: 0m2s
2023-03-06 17:49:35.760731: Epoch: 8, Batch: 19, Loss: 0.4111, Elapsed: 0m3s
2023-03-06 17:49:40.841623: Epoch: 8, Batch: 20, Loss: 0.4252, Elapsed: 0m5s
2023-03-06 17:49:43.652426: Epoch: 8, Batch: 21, Loss: 0.4019, Elapsed: 0m2s
2023-03-06 17:49:45.663034: Epoch: 8, Batch: 22, Loss: 0.3977, Elapsed: 0m2s
2023-03-06 17:49:48.086748: Epoch: 8, Batch: 23, Loss: 0.3951, Elapsed: 0m2s
2023-03-06 17:49:50.016492: Epoch: 8, Batch: 24, Loss: 0.3686, Elapsed: 0m1s
2023-03-06 17:49:52.557615: Epoch: 8, Batch: 25, Loss: 0.4002, Elapsed: 0m2s
2023-03-06 17:49:56.202873: Epoch: 8, Batch: 26, Loss: 0.4150, Elapsed: 0m3s
2023-03-06 17:50:00.561597: Epoch: 8, Batch: 27, Loss: 0.4179, Elapsed: 0m4s
2023-03-06 17:50:03.061755: Epoch: 8, Batch: 28, Loss: 0.4025, Elapsed: 0m2s
2023-03-06 17:50:07.728179: Epoch: 8, Batch: 29, Loss: 0.4209, Elapsed: 0m4s
2023-03-06 17:50:09.416746: Epoch: 8, Batch: 30, Loss: 0.3718, Elapsed: 0m1s
2023-03-06 17:50:12.534867: Epoch: 8, Batch: 31, Loss: 0.4135, Elapsed: 0m3s
2023-03-06 17:50:14.245650: Epoch: 8, Batch: 32, Loss: 0.3865, Elapsed: 0m1s
2023-03-06 17:50:15.785074: Epoch: 8, Batch: 33, Loss: 0.3669, Elapsed: 0m1s
2023-03-06 17:50:20.268597: Epoch: 8, Batch: 34, Loss: 0.4173, Elapsed: 0m4s
2023-03-06 17:50:23.455115: Epoch: 8, Batch: 35, Loss: 0.3978, Elapsed: 0m3s
2023-03-06 17:50:27.140403: Epoch: 8, Batch: 36, Loss: 0.4060, Elapsed: 0m3s
2023-03-06 17:50:28.482886: Epoch: 8, Batch: 37, Loss: 0.3464, Elapsed: 0m1s
2023-03-06 17:50:31.568846: Epoch: 8, Batch: 38, Loss: 0.4082, Elapsed: 0m3s
2023-03-06 17:50:33.521233: Epoch: 8, Batch: 39, Loss: 0.3883, Elapsed: 0m1s
2023-03-06 17:50:38.027068: Epoch: 8, Batch: 40, Loss: 0.4263, Elapsed: 0m4s
2023-03-06 17:50:40.731562: Epoch: 8, Batch: 41, Loss: 0.4151, Elapsed: 0m2s
2023-03-06 17:50:45.078320: Epoch: 8, Batch: 42, Loss: 0.4211, Elapsed: 0m4s
2023-03-06 17:50:47.651536: Epoch: 8, Batch: 43, Loss: 0.3943, Elapsed: 0m2s
2023-03-06 17:50:49.519225: Epoch: 8, Batch: 44, Loss: 0.3859, Elapsed: 0m1s
2023-03-06 17:50:52.140963: Epoch: 8, Batch: 45, Loss: 0.4038, Elapsed: 0m2s
2023-03-06 17:50:55.113904: Epoch: 8, Batch: 46, Loss: 0.3969, Elapsed: 0m2s
2023-03-06 17:50:57.639270: Epoch: 8, Batch: 47, Loss: 0.3944, Elapsed: 0m2s
2023-03-06 17:51:00.126332: Epoch: 8, Batch: 48, Loss: 0.4011, Elapsed: 0m2s
2023-03-06 17:51:02.047514: Epoch: 8, Batch: 49, Loss: 0.3816, Elapsed: 0m1s
2023-03-06 17:51:05.615789: Epoch: 8, Batch: 50, Loss: 0.4145, Elapsed: 0m3s
2023-03-06 17:51:05.624401 Starting testing the valid set with 20 subgraphs!
2023-03-06 17:52:11.705727: validation Test:  Loss: 0.4065,  AUC: 0.8737, Acc: 79.1901,  Precision: 0.8768 -- Elapsed: 1m6s
2023-03-06 17:52:11.706938 Starting testing the train set with 20 subgraphs!
2023-03-06 17:56:35.073991: training Test:  Loss: 0.4053,  AUC: 0.8745, Acc: 79.2768,  Precision: 0.8772 -- Elapsed: 4m23s
2023-03-06 17:56:37.333239: Epoch: 8, Batch: 51, Loss: 0.3834, Elapsed: 0m2s
2023-03-06 17:56:39.552074: Epoch: 8, Batch: 52, Loss: 0.3941, Elapsed: 0m2s
2023-03-06 17:56:42.064624: Epoch: 8, Batch: 53, Loss: 0.3874, Elapsed: 0m2s
2023-03-06 17:56:46.668985: Epoch: 8, Batch: 54, Loss: 0.4214, Elapsed: 0m4s
2023-03-06 17:56:48.325649: Epoch: 8, Batch: 55, Loss: 0.3681, Elapsed: 0m1s
2023-03-06 17:56:50.705945: Epoch: 8, Batch: 56, Loss: 0.3998, Elapsed: 0m2s
2023-03-06 17:56:53.650768: Epoch: 8, Batch: 57, Loss: 0.4108, Elapsed: 0m2s
2023-03-06 17:56:57.084864: Epoch: 8, Batch: 58, Loss: 0.4157, Elapsed: 0m3s
2023-03-06 17:56:59.274871: Epoch: 8, Batch: 59, Loss: 0.3796, Elapsed: 0m2s
2023-03-06 17:57:02.720673: Epoch: 8, Batch: 60, Loss: 0.4110, Elapsed: 0m3s
2023-03-06 17:57:06.192944: Epoch: 8, Batch: 61, Loss: 0.4058, Elapsed: 0m3s
2023-03-06 17:57:08.630042: Epoch: 8, Batch: 62, Loss: 0.3943, Elapsed: 0m2s
2023-03-06 17:57:13.971703: Epoch: 8, Batch: 63, Loss: 0.3837, Elapsed: 0m5s
2023-03-06 17:57:16.816145: Epoch: 8, Batch: 64, Loss: 0.4062, Elapsed: 0m2s
2023-03-06 17:57:19.077851: Epoch: 8, Batch: 65, Loss: 0.3987, Elapsed: 0m2s
2023-03-06 17:57:21.566165: Epoch: 8, Batch: 66, Loss: 0.3941, Elapsed: 0m2s
2023-03-06 17:57:24.412676: Epoch: 8, Batch: 67, Loss: 0.4029, Elapsed: 0m2s
2023-03-06 17:57:28.519336: Epoch: 8, Batch: 68, Loss: 0.4250, Elapsed: 0m4s
2023-03-06 17:57:30.348123: Epoch: 8, Batch: 69, Loss: 0.3823, Elapsed: 0m1s
2023-03-06 17:57:32.633979: Epoch: 8, Batch: 70, Loss: 0.3986, Elapsed: 0m2s
2023-03-06 17:57:38.984263: Epoch: 8, Batch: 71, Loss: 0.4367, Elapsed: 0m6s
2023-03-06 17:57:41.933796: Epoch: 8, Batch: 72, Loss: 0.4007, Elapsed: 0m2s
2023-03-06 17:57:44.716189: Epoch: 8, Batch: 73, Loss: 0.4055, Elapsed: 0m2s
2023-03-06 17:57:50.059428: Epoch: 8, Batch: 74, Loss: 0.4295, Elapsed: 0m5s
2023-03-06 17:57:53.024695: Epoch: 8, Batch: 75, Loss: 0.4132, Elapsed: 0m2s
2023-03-06 17:57:56.835500: Epoch: 8, Batch: 76, Loss: 0.4211, Elapsed: 0m3s
2023-03-06 17:58:00.676626: Epoch: 8, Batch: 77, Loss: 0.4246, Elapsed: 0m3s
2023-03-06 17:58:03.731240: Epoch: 8, Batch: 78, Loss: 0.4139, Elapsed: 0m3s
2023-03-06 17:58:07.379056: Epoch: 8, Batch: 79, Loss: 0.4155, Elapsed: 0m3s
2023-03-06 17:58:11.461576: Epoch: 8, Batch: 80, Loss: 0.4348, Elapsed: 0m4s
2023-03-06 17:58:13.729539: Epoch: 9, Batch: 1, Loss: 0.3949, Elapsed: 0m2s
2023-03-06 17:58:16.766620: Epoch: 9, Batch: 2, Loss: 0.4123, Elapsed: 0m3s
2023-03-06 17:58:19.271086: Epoch: 9, Batch: 3, Loss: 0.4018, Elapsed: 0m2s
2023-03-06 17:58:21.753909: Epoch: 9, Batch: 4, Loss: 0.3922, Elapsed: 0m2s
2023-03-06 17:58:23.286808: Epoch: 9, Batch: 5, Loss: 0.3667, Elapsed: 0m1s
2023-03-06 17:58:27.286074: Epoch: 9, Batch: 6, Loss: 0.4198, Elapsed: 0m3s
2023-03-06 17:58:30.051412: Epoch: 9, Batch: 7, Loss: 0.4148, Elapsed: 0m2s
2023-03-06 17:58:32.592449: Epoch: 9, Batch: 8, Loss: 0.4018, Elapsed: 0m2s
2023-03-06 17:58:34.246228: Epoch: 9, Batch: 9, Loss: 0.3717, Elapsed: 0m1s
2023-03-06 17:58:37.200821: Epoch: 9, Batch: 10, Loss: 0.4103, Elapsed: 0m2s
2023-03-06 17:58:39.193370: Epoch: 9, Batch: 11, Loss: 0.3956, Elapsed: 0m1s
2023-03-06 17:58:43.409980: Epoch: 9, Batch: 12, Loss: 0.4185, Elapsed: 0m4s
2023-03-06 17:58:46.137451: Epoch: 9, Batch: 13, Loss: 0.3939, Elapsed: 0m2s
2023-03-06 17:58:48.200224: Epoch: 9, Batch: 14, Loss: 0.3877, Elapsed: 0m2s
2023-03-06 17:58:51.179358: Epoch: 9, Batch: 15, Loss: 0.4070, Elapsed: 0m2s
2023-03-06 17:58:55.616802: Epoch: 9, Batch: 16, Loss: 0.4192, Elapsed: 0m4s
2023-03-06 17:58:58.193306: Epoch: 9, Batch: 17, Loss: 0.3991, Elapsed: 0m2s
2023-03-06 17:59:00.703723: Epoch: 9, Batch: 18, Loss: 0.3867, Elapsed: 0m2s
2023-03-06 17:59:03.675399: Epoch: 9, Batch: 19, Loss: 0.4120, Elapsed: 0m2s
2023-03-06 17:59:07.341966: Epoch: 9, Batch: 20, Loss: 0.4131, Elapsed: 0m3s
2023-03-06 17:59:11.656854: Epoch: 9, Batch: 21, Loss: 0.4200, Elapsed: 0m4s
2023-03-06 17:59:15.839083: Epoch: 9, Batch: 22, Loss: 0.4159, Elapsed: 0m4s
2023-03-06 17:59:21.034559: Epoch: 9, Batch: 23, Loss: 0.4193, Elapsed: 0m5s
2023-03-06 17:59:25.218252: Epoch: 9, Batch: 24, Loss: 0.4240, Elapsed: 0m4s
2023-03-06 17:59:29.751028: Epoch: 9, Batch: 25, Loss: 0.4164, Elapsed: 0m4s
2023-03-06 17:59:32.377400: Epoch: 9, Batch: 26, Loss: 0.3977, Elapsed: 0m2s
2023-03-06 17:59:34.782007: Epoch: 9, Batch: 27, Loss: 0.3967, Elapsed: 0m2s
2023-03-06 17:59:38.550930: Epoch: 9, Batch: 28, Loss: 0.4121, Elapsed: 0m3s
2023-03-06 17:59:40.717425: Epoch: 9, Batch: 29, Loss: 0.3822, Elapsed: 0m2s
2023-03-06 17:59:43.223455: Epoch: 9, Batch: 30, Loss: 0.3994, Elapsed: 0m2s
2023-03-06 17:59:44.888243: Epoch: 9, Batch: 31, Loss: 0.3673, Elapsed: 0m1s
2023-03-06 17:59:48.128486: Epoch: 9, Batch: 32, Loss: 0.3926, Elapsed: 0m3s
2023-03-06 17:59:54.662992: Epoch: 9, Batch: 33, Loss: 0.4327, Elapsed: 0m6s
2023-03-06 17:59:57.082529: Epoch: 9, Batch: 34, Loss: 0.3982, Elapsed: 0m2s
2023-03-06 18:00:00.510928: Epoch: 9, Batch: 35, Loss: 0.4084, Elapsed: 0m3s
2023-03-06 18:00:02.632122: Epoch: 9, Batch: 36, Loss: 0.3855, Elapsed: 0m2s
2023-03-06 18:00:04.490915: Epoch: 9, Batch: 37, Loss: 0.3839, Elapsed: 0m1s
2023-03-06 18:00:07.604286: Epoch: 9, Batch: 38, Loss: 0.4049, Elapsed: 0m3s
2023-03-06 18:00:09.642335: Epoch: 9, Batch: 39, Loss: 0.3844, Elapsed: 0m2s
2023-03-06 18:00:13.358762: Epoch: 9, Batch: 40, Loss: 0.4206, Elapsed: 0m3s
2023-03-06 18:00:15.271346: Epoch: 9, Batch: 41, Loss: 0.3661, Elapsed: 0m1s
2023-03-06 18:00:18.844283: Epoch: 9, Batch: 42, Loss: 0.4129, Elapsed: 0m3s
2023-03-06 18:00:20.768224: Epoch: 9, Batch: 43, Loss: 0.3799, Elapsed: 0m1s
2023-03-06 18:00:25.858699: Epoch: 9, Batch: 44, Loss: 0.3818, Elapsed: 0m5s
2023-03-06 18:00:29.754695: Epoch: 9, Batch: 45, Loss: 0.4228, Elapsed: 0m3s
2023-03-06 18:00:32.749720: Epoch: 9, Batch: 46, Loss: 0.3951, Elapsed: 0m2s
2023-03-06 18:00:36.568584: Epoch: 9, Batch: 47, Loss: 0.4166, Elapsed: 0m3s
2023-03-06 18:00:38.583086: Epoch: 9, Batch: 48, Loss: 0.3951, Elapsed: 0m2s
2023-03-06 18:00:40.964036: Epoch: 9, Batch: 49, Loss: 0.3743, Elapsed: 0m2s
2023-03-06 18:00:42.807716: Epoch: 9, Batch: 50, Loss: 0.3763, Elapsed: 0m1s
2023-03-06 18:00:42.816435 Starting testing the valid set with 20 subgraphs!
2023-03-06 18:01:48.611631: validation Test:  Loss: 0.4051,  AUC: 0.8738, Acc: 79.3133,  Precision: 0.9184 -- Elapsed: 1m5s
2023-03-06 18:01:48.612805 Starting testing the train set with 20 subgraphs!
2023-03-06 18:06:11.826633: training Test:  Loss: 0.4039,  AUC: 0.8746, Acc: 79.3750,  Precision: 0.9177 -- Elapsed: 4m23s
2023-03-06 18:06:15.543740: Epoch: 9, Batch: 51, Loss: 0.4100, Elapsed: 0m3s
2023-03-06 18:06:18.671698: Epoch: 9, Batch: 52, Loss: 0.4034, Elapsed: 0m3s
2023-03-06 18:06:23.448858: Epoch: 9, Batch: 53, Loss: 0.4246, Elapsed: 0m4s
2023-03-06 18:06:26.900192: Epoch: 9, Batch: 54, Loss: 0.4144, Elapsed: 0m3s
2023-03-06 18:06:27.920607: Epoch: 9, Batch: 55, Loss: 0.3370, Elapsed: 0m1s
2023-03-06 18:06:30.719252: Epoch: 9, Batch: 56, Loss: 0.3982, Elapsed: 0m2s
2023-03-06 18:06:36.343532: Epoch: 9, Batch: 57, Loss: 0.4266, Elapsed: 0m5s
2023-03-06 18:06:39.618352: Epoch: 9, Batch: 58, Loss: 0.4045, Elapsed: 0m3s
2023-03-06 18:06:43.012467: Epoch: 9, Batch: 59, Loss: 0.4054, Elapsed: 0m3s
2023-03-06 18:06:47.634529: Epoch: 9, Batch: 60, Loss: 0.4193, Elapsed: 0m4s
2023-03-06 18:06:50.449809: Epoch: 9, Batch: 61, Loss: 0.3992, Elapsed: 0m2s
2023-03-06 18:06:53.178726: Epoch: 9, Batch: 62, Loss: 0.4006, Elapsed: 0m2s
2023-03-06 18:06:55.359795: Epoch: 9, Batch: 63, Loss: 0.3785, Elapsed: 0m2s
2023-03-06 18:07:00.703826: Epoch: 9, Batch: 64, Loss: 0.4259, Elapsed: 0m5s
2023-03-06 18:07:03.208563: Epoch: 9, Batch: 65, Loss: 0.3924, Elapsed: 0m2s
2023-03-06 18:07:05.432906: Epoch: 9, Batch: 66, Loss: 0.3926, Elapsed: 0m2s
2023-03-06 18:07:08.434632: Epoch: 9, Batch: 67, Loss: 0.3950, Elapsed: 0m2s
2023-03-06 18:07:11.460684: Epoch: 9, Batch: 68, Loss: 0.4061, Elapsed: 0m3s
2023-03-06 18:07:13.884760: Epoch: 9, Batch: 69, Loss: 0.3924, Elapsed: 0m2s
2023-03-06 18:07:16.846447: Epoch: 9, Batch: 70, Loss: 0.3901, Elapsed: 0m2s
2023-03-06 18:07:19.328385: Epoch: 9, Batch: 71, Loss: 0.4093, Elapsed: 0m2s
2023-03-06 18:07:22.979021: Epoch: 9, Batch: 72, Loss: 0.4141, Elapsed: 0m3s
2023-03-06 18:07:27.349921: Epoch: 9, Batch: 73, Loss: 0.4186, Elapsed: 0m4s
2023-03-06 18:07:29.591837: Epoch: 9, Batch: 74, Loss: 0.3884, Elapsed: 0m2s
2023-03-06 18:07:32.439683: Epoch: 9, Batch: 75, Loss: 0.3953, Elapsed: 0m2s
2023-03-06 18:07:35.512353: Epoch: 9, Batch: 76, Loss: 0.4106, Elapsed: 0m3s
2023-03-06 18:07:38.134429: Epoch: 9, Batch: 77, Loss: 0.4008, Elapsed: 0m2s
2023-03-06 18:07:39.451172: Epoch: 9, Batch: 78, Loss: 0.3427, Elapsed: 0m1s
2023-03-06 18:07:43.531336: Epoch: 9, Batch: 79, Loss: 0.4318, Elapsed: 0m4s
2023-03-06 18:07:48.630287: Epoch: 9, Batch: 80, Loss: 0.4223, Elapsed: 0m5s
2023-03-06 18:07:51.498155: Epoch: 10, Batch: 1, Loss: 0.4039, Elapsed: 0m2s
2023-03-06 18:07:55.083418: Epoch: 10, Batch: 2, Loss: 0.4121, Elapsed: 0m3s
2023-03-06 18:07:57.602124: Epoch: 10, Batch: 3, Loss: 0.3849, Elapsed: 0m2s
2023-03-06 18:07:58.902894: Epoch: 10, Batch: 4, Loss: 0.3428, Elapsed: 0m1s
2023-03-06 18:08:01.389686: Epoch: 10, Batch: 5, Loss: 0.4094, Elapsed: 0m2s
2023-03-06 18:08:04.192609: Epoch: 10, Batch: 6, Loss: 0.4025, Elapsed: 0m2s
2023-03-06 18:08:08.342791: Epoch: 10, Batch: 7, Loss: 0.4226, Elapsed: 0m4s
2023-03-06 18:08:10.742541: Epoch: 10, Batch: 8, Loss: 0.3975, Elapsed: 0m2s
2023-03-06 18:08:14.486795: Epoch: 10, Batch: 9, Loss: 0.4103, Elapsed: 0m3s
2023-03-06 18:08:17.895219: Epoch: 10, Batch: 10, Loss: 0.3913, Elapsed: 0m3s
2023-03-06 18:08:21.531325: Epoch: 10, Batch: 11, Loss: 0.4073, Elapsed: 0m3s
2023-03-06 18:08:24.334586: Epoch: 10, Batch: 12, Loss: 0.3973, Elapsed: 0m2s
2023-03-06 18:08:26.458401: Epoch: 10, Batch: 13, Loss: 0.3938, Elapsed: 0m2s
2023-03-06 18:08:30.043216: Epoch: 10, Batch: 14, Loss: 0.4086, Elapsed: 0m3s
2023-03-06 18:08:31.106720: Epoch: 10, Batch: 15, Loss: 0.3362, Elapsed: 0m1s
2023-03-06 18:08:33.609371: Epoch: 10, Batch: 16, Loss: 0.3981, Elapsed: 0m2s
2023-03-06 18:08:37.440322: Epoch: 10, Batch: 17, Loss: 0.4221, Elapsed: 0m3s
2023-03-06 18:08:39.315379: Epoch: 10, Batch: 18, Loss: 0.3832, Elapsed: 0m1s
2023-03-06 18:08:43.944183: Epoch: 10, Batch: 19, Loss: 0.4186, Elapsed: 0m4s
2023-03-06 18:08:46.890526: Epoch: 10, Batch: 20, Loss: 0.3944, Elapsed: 0m2s
2023-03-06 18:08:52.565533: Epoch: 10, Batch: 21, Loss: 0.4252, Elapsed: 0m5s
2023-03-06 18:08:54.746959: Epoch: 10, Batch: 22, Loss: 0.3773, Elapsed: 0m2s
2023-03-06 18:08:59.094727: Epoch: 10, Batch: 23, Loss: 0.4146, Elapsed: 0m4s
2023-03-06 18:09:03.543962: Epoch: 10, Batch: 24, Loss: 0.4171, Elapsed: 0m4s
2023-03-06 18:09:06.103254: Epoch: 10, Batch: 25, Loss: 0.3977, Elapsed: 0m2s
2023-03-06 18:09:10.287791: Epoch: 10, Batch: 26, Loss: 0.4137, Elapsed: 0m4s
2023-03-06 18:09:13.458989: Epoch: 10, Batch: 27, Loss: 0.4047, Elapsed: 0m3s
2023-03-06 18:09:16.761597: Epoch: 10, Batch: 28, Loss: 0.4101, Elapsed: 0m3s
2023-03-06 18:09:19.658612: Epoch: 10, Batch: 29, Loss: 0.4115, Elapsed: 0m2s
2023-03-06 18:09:21.645189: Epoch: 10, Batch: 30, Loss: 0.3651, Elapsed: 0m1s
2023-03-06 18:09:23.634254: Epoch: 10, Batch: 31, Loss: 0.3857, Elapsed: 0m1s
2023-03-06 18:09:26.278683: Epoch: 10, Batch: 32, Loss: 0.4002, Elapsed: 0m2s
2023-03-06 18:09:29.220800: Epoch: 10, Batch: 33, Loss: 0.3893, Elapsed: 0m2s
2023-03-06 18:09:32.091513: Epoch: 10, Batch: 34, Loss: 0.3974, Elapsed: 0m2s
2023-03-06 18:09:34.897049: Epoch: 10, Batch: 35, Loss: 0.3956, Elapsed: 0m2s
2023-03-06 18:09:36.731818: Epoch: 10, Batch: 36, Loss: 0.3748, Elapsed: 0m1s
2023-03-06 18:09:38.666552: Epoch: 10, Batch: 37, Loss: 0.3833, Elapsed: 0m1s
2023-03-06 18:09:41.710569: Epoch: 10, Batch: 38, Loss: 0.4095, Elapsed: 0m3s
2023-03-06 18:09:43.326425: Epoch: 10, Batch: 39, Loss: 0.3683, Elapsed: 0m1s
2023-03-06 18:09:45.718481: Epoch: 10, Batch: 40, Loss: 0.3728, Elapsed: 0m2s
2023-03-06 18:09:50.029873: Epoch: 10, Batch: 41, Loss: 0.4178, Elapsed: 0m4s
2023-03-06 18:09:53.844398: Epoch: 10, Batch: 42, Loss: 0.4151, Elapsed: 0m3s
2023-03-06 18:10:00.092971: Epoch: 10, Batch: 43, Loss: 0.4308, Elapsed: 0m6s
2023-03-06 18:10:01.794787: Epoch: 10, Batch: 44, Loss: 0.3816, Elapsed: 0m1s
2023-03-06 18:10:05.882529: Epoch: 10, Batch: 45, Loss: 0.4309, Elapsed: 0m4s
2023-03-06 18:10:08.105232: Epoch: 10, Batch: 46, Loss: 0.3874, Elapsed: 0m2s
2023-03-06 18:10:11.089084: Epoch: 10, Batch: 47, Loss: 0.4092, Elapsed: 0m2s
2023-03-06 18:10:16.204140: Epoch: 10, Batch: 48, Loss: 0.4209, Elapsed: 0m5s
2023-03-06 18:10:17.909733: Epoch: 10, Batch: 49, Loss: 0.3654, Elapsed: 0m1s
2023-03-06 18:10:21.598936: Epoch: 10, Batch: 50, Loss: 0.4123, Elapsed: 0m3s
2023-03-06 18:10:21.608341 Starting testing the valid set with 20 subgraphs!
2023-03-06 18:11:28.584444: validation Test:  Loss: 0.4046,  AUC: 0.8741, Acc: 79.3666,  Precision: 0.9277 -- Elapsed: 1m6s
2023-03-06 18:11:28.585627 Starting testing the train set with 20 subgraphs!
2023-03-06 18:15:53.492661: training Test:  Loss: 0.4034,  AUC: 0.8749, Acc: 79.4268,  Precision: 0.9273 -- Elapsed: 4m24s
2023-03-06 18:15:56.983570: Epoch: 10, Batch: 51, Loss: 0.4143, Elapsed: 0m3s
2023-03-06 18:16:00.451381: Epoch: 10, Batch: 52, Loss: 0.4130, Elapsed: 0m3s
2023-03-06 18:16:03.644691: Epoch: 10, Batch: 53, Loss: 0.4098, Elapsed: 0m3s
2023-03-06 18:16:06.221369: Epoch: 10, Batch: 54, Loss: 0.3915, Elapsed: 0m2s
2023-03-06 18:16:10.423797: Epoch: 10, Batch: 55, Loss: 0.4170, Elapsed: 0m4s
2023-03-06 18:16:13.684768: Epoch: 10, Batch: 56, Loss: 0.4026, Elapsed: 0m3s
2023-03-06 18:16:16.206310: Epoch: 10, Batch: 57, Loss: 0.3971, Elapsed: 0m2s
2023-03-06 18:16:18.372425: Epoch: 10, Batch: 58, Loss: 0.3918, Elapsed: 0m2s
2023-03-06 18:16:21.890185: Epoch: 10, Batch: 59, Loss: 0.4194, Elapsed: 0m3s
2023-03-06 18:16:24.366478: Epoch: 10, Batch: 60, Loss: 0.3879, Elapsed: 0m2s
2023-03-06 18:16:25.909215: Epoch: 10, Batch: 61, Loss: 0.3634, Elapsed: 0m1s
2023-03-06 18:16:28.070608: Epoch: 10, Batch: 62, Loss: 0.3801, Elapsed: 0m2s
2023-03-06 18:16:30.006670: Epoch: 10, Batch: 63, Loss: 0.3784, Elapsed: 0m1s
2023-03-06 18:16:33.468899: Epoch: 10, Batch: 64, Loss: 0.4018, Elapsed: 0m3s
2023-03-06 18:16:37.523373: Epoch: 10, Batch: 65, Loss: 0.4181, Elapsed: 0m4s
2023-03-06 18:16:40.035464: Epoch: 10, Batch: 66, Loss: 0.3902, Elapsed: 0m2s
2023-03-06 18:16:44.547393: Epoch: 10, Batch: 67, Loss: 0.4224, Elapsed: 0m4s
2023-03-06 18:16:49.894129: Epoch: 10, Batch: 68, Loss: 0.4246, Elapsed: 0m5s
2023-03-06 18:16:52.751373: Epoch: 10, Batch: 69, Loss: 0.3944, Elapsed: 0m2s
2023-03-06 18:16:56.869017: Epoch: 10, Batch: 70, Loss: 0.4171, Elapsed: 0m4s
2023-03-06 18:17:02.128752: Epoch: 10, Batch: 71, Loss: 0.4168, Elapsed: 0m5s
2023-03-06 18:17:04.612371: Epoch: 10, Batch: 72, Loss: 0.3933, Elapsed: 0m2s
2023-03-06 18:17:10.108637: Epoch: 10, Batch: 73, Loss: 0.3830, Elapsed: 0m5s
2023-03-06 18:17:12.683524: Epoch: 10, Batch: 74, Loss: 0.3909, Elapsed: 0m2s
2023-03-06 18:17:15.388530: Epoch: 10, Batch: 75, Loss: 0.3997, Elapsed: 0m2s
2023-03-06 18:17:17.649823: Epoch: 10, Batch: 76, Loss: 0.3909, Elapsed: 0m2s
2023-03-06 18:17:20.582383: Epoch: 10, Batch: 77, Loss: 0.3932, Elapsed: 0m2s
2023-03-06 18:17:23.068709: Epoch: 10, Batch: 78, Loss: 0.3985, Elapsed: 0m2s
2023-03-06 18:17:25.049684: Epoch: 10, Batch: 79, Loss: 0.3923, Elapsed: 0m1s
2023-03-06 18:17:28.021901: Epoch: 10, Batch: 80, Loss: 0.4038, Elapsed: 0m2s
2023-03-06 18:17:30.955709: Epoch: 11, Batch: 1, Loss: 0.4063, Elapsed: 0m2s
2023-03-06 18:17:34.177445: Epoch: 11, Batch: 2, Loss: 0.4025, Elapsed: 0m3s
2023-03-06 18:17:38.649977: Epoch: 11, Batch: 3, Loss: 0.4213, Elapsed: 0m4s
2023-03-06 18:17:42.122577: Epoch: 11, Batch: 4, Loss: 0.4177, Elapsed: 0m3s
2023-03-06 18:17:46.187304: Epoch: 11, Batch: 5, Loss: 0.4302, Elapsed: 0m4s
2023-03-06 18:17:48.201061: Epoch: 11, Batch: 6, Loss: 0.3927, Elapsed: 0m2s
2023-03-06 18:17:50.808156: Epoch: 11, Batch: 7, Loss: 0.3991, Elapsed: 0m2s
2023-03-06 18:17:53.653304: Epoch: 11, Batch: 8, Loss: 0.4024, Elapsed: 0m2s
2023-03-06 18:17:55.336379: Epoch: 11, Batch: 9, Loss: 0.3809, Elapsed: 0m1s
2023-03-06 18:17:58.339221: Epoch: 11, Batch: 10, Loss: 0.4081, Elapsed: 0m2s
2023-03-06 18:18:02.668925: Epoch: 11, Batch: 11, Loss: 0.4132, Elapsed: 0m4s
2023-03-06 18:18:05.145944: Epoch: 11, Batch: 12, Loss: 0.3964, Elapsed: 0m2s
2023-03-06 18:18:08.532642: Epoch: 11, Batch: 13, Loss: 0.4012, Elapsed: 0m3s
2023-03-06 18:18:11.097724: Epoch: 11, Batch: 14, Loss: 0.3869, Elapsed: 0m2s
2023-03-06 18:18:13.413756: Epoch: 11, Batch: 15, Loss: 0.3868, Elapsed: 0m2s
2023-03-06 18:18:17.144754: Epoch: 11, Batch: 16, Loss: 0.4086, Elapsed: 0m3s
2023-03-06 18:18:21.750364: Epoch: 11, Batch: 17, Loss: 0.4168, Elapsed: 0m4s
2023-03-06 18:18:24.751033: Epoch: 11, Batch: 18, Loss: 0.4009, Elapsed: 0m2s
2023-03-06 18:18:28.625210: Epoch: 11, Batch: 19, Loss: 0.4099, Elapsed: 0m3s
2023-03-06 18:18:35.082298: Epoch: 11, Batch: 20, Loss: 0.4300, Elapsed: 0m6s
2023-03-06 18:18:40.180283: Epoch: 11, Batch: 21, Loss: 0.4197, Elapsed: 0m5s
2023-03-06 18:18:44.481987: Epoch: 11, Batch: 22, Loss: 0.4172, Elapsed: 0m4s
2023-03-06 18:18:47.434366: Epoch: 11, Batch: 23, Loss: 0.3877, Elapsed: 0m2s
2023-03-06 18:18:52.505562: Epoch: 11, Batch: 24, Loss: 0.3814, Elapsed: 0m5s
2023-03-06 18:18:54.432100: Epoch: 11, Batch: 25, Loss: 0.3818, Elapsed: 0m1s
2023-03-06 18:18:56.047744: Epoch: 11, Batch: 26, Loss: 0.3672, Elapsed: 0m1s
2023-03-06 18:18:59.072418: Epoch: 11, Batch: 27, Loss: 0.4035, Elapsed: 0m3s
2023-03-06 18:19:00.606785: Epoch: 11, Batch: 28, Loss: 0.3610, Elapsed: 0m1s
2023-03-06 18:19:03.332412: Epoch: 11, Batch: 29, Loss: 0.3980, Elapsed: 0m2s
2023-03-06 18:19:06.789094: Epoch: 11, Batch: 30, Loss: 0.4113, Elapsed: 0m3s
2023-03-06 18:19:10.441685: Epoch: 11, Batch: 31, Loss: 0.4097, Elapsed: 0m3s
2023-03-06 18:19:15.392142: Epoch: 11, Batch: 32, Loss: 0.4158, Elapsed: 0m4s
2023-03-06 18:19:18.650819: Epoch: 11, Batch: 33, Loss: 0.4083, Elapsed: 0m3s
2023-03-06 18:19:22.823138: Epoch: 11, Batch: 34, Loss: 0.4206, Elapsed: 0m4s
2023-03-06 18:19:25.639425: Epoch: 11, Batch: 35, Loss: 0.3955, Elapsed: 0m2s
2023-03-06 18:19:27.822406: Epoch: 11, Batch: 36, Loss: 0.3755, Elapsed: 0m2s
2023-03-06 18:19:31.664075: Epoch: 11, Batch: 37, Loss: 0.4137, Elapsed: 0m3s
2023-03-06 18:19:34.142865: Epoch: 11, Batch: 38, Loss: 0.4069, Elapsed: 0m2s
2023-03-06 18:19:36.019475: Epoch: 11, Batch: 39, Loss: 0.3812, Elapsed: 0m1s
2023-03-06 18:19:40.038840: Epoch: 11, Batch: 40, Loss: 0.4157, Elapsed: 0m4s
2023-03-06 18:19:41.340367: Epoch: 11, Batch: 41, Loss: 0.3407, Elapsed: 0m1s
2023-03-06 18:19:45.771612: Epoch: 11, Batch: 42, Loss: 0.4150, Elapsed: 0m4s
2023-03-06 18:19:48.347499: Epoch: 11, Batch: 43, Loss: 0.3956, Elapsed: 0m2s
2023-03-06 18:19:50.275584: Epoch: 11, Batch: 44, Loss: 0.3762, Elapsed: 0m1s
2023-03-06 18:19:52.665065: Epoch: 11, Batch: 45, Loss: 0.3716, Elapsed: 0m2s
2023-03-06 18:19:54.927024: Epoch: 11, Batch: 46, Loss: 0.3901, Elapsed: 0m2s
2023-03-06 18:19:58.127397: Epoch: 11, Batch: 47, Loss: 0.3899, Elapsed: 0m3s
2023-03-06 18:20:01.281589: Epoch: 11, Batch: 48, Loss: 0.3922, Elapsed: 0m3s
2023-03-06 18:20:03.087807: Epoch: 11, Batch: 49, Loss: 0.3643, Elapsed: 0m1s
2023-03-06 18:20:05.694184: Epoch: 11, Batch: 50, Loss: 0.3908, Elapsed: 0m2s
2023-03-06 18:20:05.703312 Starting testing the valid set with 20 subgraphs!
2023-03-06 18:21:11.576709: validation Test:  Loss: 0.4012,  AUC: 0.8748, Acc: 79.3042,  Precision: 0.8598 -- Elapsed: 1m5s
2023-03-06 18:21:11.577889 Starting testing the train set with 20 subgraphs!
2023-03-06 18:25:34.846971: training Test:  Loss: 0.4001,  AUC: 0.8756, Acc: 79.3786,  Precision: 0.8613 -- Elapsed: 4m23s
2023-03-06 18:25:37.357104: Epoch: 11, Batch: 51, Loss: 0.3884, Elapsed: 0m2s
2023-03-06 18:25:39.649675: Epoch: 11, Batch: 52, Loss: 0.3941, Elapsed: 0m2s
2023-03-06 18:25:41.873185: Epoch: 11, Batch: 53, Loss: 0.3925, Elapsed: 0m2s
2023-03-06 18:25:44.883658: Epoch: 11, Batch: 54, Loss: 0.3938, Elapsed: 0m3s
2023-03-06 18:25:49.166881: Epoch: 11, Batch: 55, Loss: 0.4133, Elapsed: 0m4s
2023-03-06 18:25:53.521427: Epoch: 11, Batch: 56, Loss: 0.4169, Elapsed: 0m4s
2023-03-06 18:25:57.677404: Epoch: 11, Batch: 57, Loss: 0.4210, Elapsed: 0m4s
2023-03-06 18:26:00.393476: Epoch: 11, Batch: 58, Loss: 0.3986, Elapsed: 0m2s
2023-03-06 18:26:02.856853: Epoch: 11, Batch: 59, Loss: 0.3955, Elapsed: 0m2s
2023-03-06 18:26:06.265737: Epoch: 11, Batch: 60, Loss: 0.4073, Elapsed: 0m3s
2023-03-06 18:26:09.718670: Epoch: 11, Batch: 61, Loss: 0.4113, Elapsed: 0m3s
2023-03-06 18:26:11.726707: Epoch: 11, Batch: 62, Loss: 0.3920, Elapsed: 0m1s
2023-03-06 18:26:14.230751: Epoch: 11, Batch: 63, Loss: 0.3942, Elapsed: 0m2s
2023-03-06 18:26:18.371129: Epoch: 11, Batch: 64, Loss: 0.4145, Elapsed: 0m4s
2023-03-06 18:26:21.411441: Epoch: 11, Batch: 65, Loss: 0.4030, Elapsed: 0m3s
2023-03-06 18:26:23.971041: Epoch: 11, Batch: 66, Loss: 0.3827, Elapsed: 0m2s
2023-03-06 18:26:29.319717: Epoch: 11, Batch: 67, Loss: 0.4235, Elapsed: 0m5s
2023-03-06 18:26:32.384493: Epoch: 11, Batch: 68, Loss: 0.4079, Elapsed: 0m3s
2023-03-06 18:26:35.328978: Epoch: 11, Batch: 69, Loss: 0.3926, Elapsed: 0m2s
2023-03-06 18:26:37.860690: Epoch: 11, Batch: 70, Loss: 0.3891, Elapsed: 0m2s
2023-03-06 18:26:40.375258: Epoch: 11, Batch: 71, Loss: 0.3951, Elapsed: 0m2s
2023-03-06 18:26:45.992139: Epoch: 11, Batch: 72, Loss: 0.4222, Elapsed: 0m5s
2023-03-06 18:26:49.509369: Epoch: 11, Batch: 73, Loss: 0.4046, Elapsed: 0m3s
2023-03-06 18:26:51.431325: Epoch: 11, Batch: 74, Loss: 0.3730, Elapsed: 0m1s
2023-03-06 18:26:53.675430: Epoch: 11, Batch: 75, Loss: 0.3784, Elapsed: 0m2s
2023-03-06 18:26:55.728761: Epoch: 11, Batch: 76, Loss: 0.3839, Elapsed: 0m2s
2023-03-06 18:26:57.644916: Epoch: 11, Batch: 77, Loss: 0.3635, Elapsed: 0m1s
2023-03-06 18:26:58.665423: Epoch: 11, Batch: 78, Loss: 0.3345, Elapsed: 0m1s
2023-03-06 18:27:01.349946: Epoch: 11, Batch: 79, Loss: 0.4086, Elapsed: 0m2s
2023-03-06 18:27:04.149317: Epoch: 11, Batch: 80, Loss: 0.3937, Elapsed: 0m2s
2023-03-06 18:27:06.636964: Epoch: 12, Batch: 1, Loss: 0.4064, Elapsed: 0m2s
2023-03-06 18:27:10.096010: Epoch: 12, Batch: 2, Loss: 0.4107, Elapsed: 0m3s
2023-03-06 18:27:12.105384: Epoch: 12, Batch: 3, Loss: 0.3914, Elapsed: 0m2s
2023-03-06 18:27:14.608825: Epoch: 12, Batch: 4, Loss: 0.3946, Elapsed: 0m2s
2023-03-06 18:27:18.253732: Epoch: 12, Batch: 5, Loss: 0.4087, Elapsed: 0m3s
2023-03-06 18:27:21.083643: Epoch: 12, Batch: 6, Loss: 0.3924, Elapsed: 0m2s
2023-03-06 18:27:26.792819: Epoch: 12, Batch: 7, Loss: 0.4221, Elapsed: 0m5s
2023-03-06 18:27:30.698163: Epoch: 12, Batch: 8, Loss: 0.4190, Elapsed: 0m3s
2023-03-06 18:27:34.447671: Epoch: 12, Batch: 9, Loss: 0.4161, Elapsed: 0m3s
2023-03-06 18:27:39.890534: Epoch: 12, Batch: 10, Loss: 0.3820, Elapsed: 0m5s
2023-03-06 18:27:42.481006: Epoch: 12, Batch: 11, Loss: 0.3953, Elapsed: 0m2s
2023-03-06 18:27:46.625131: Epoch: 12, Batch: 12, Loss: 0.4194, Elapsed: 0m4s
2023-03-06 18:27:49.557354: Epoch: 12, Batch: 13, Loss: 0.3915, Elapsed: 0m2s
2023-03-06 18:27:54.282439: Epoch: 12, Batch: 14, Loss: 0.4197, Elapsed: 0m4s
2023-03-06 18:27:57.287404: Epoch: 12, Batch: 15, Loss: 0.4009, Elapsed: 0m2s
2023-03-06 18:27:59.543281: Epoch: 12, Batch: 16, Loss: 0.3891, Elapsed: 0m2s
2023-03-06 18:28:03.125888: Epoch: 12, Batch: 17, Loss: 0.4086, Elapsed: 0m3s
2023-03-06 18:28:06.095955: Epoch: 12, Batch: 18, Loss: 0.4063, Elapsed: 0m2s
2023-03-06 18:28:08.280145: Epoch: 12, Batch: 19, Loss: 0.3748, Elapsed: 0m2s
2023-03-06 18:28:12.096930: Epoch: 12, Batch: 20, Loss: 0.4132, Elapsed: 0m3s
2023-03-06 18:28:14.370376: Epoch: 12, Batch: 21, Loss: 0.3910, Elapsed: 0m2s
2023-03-06 18:28:17.241357: Epoch: 12, Batch: 22, Loss: 0.3943, Elapsed: 0m2s
2023-03-06 18:28:21.594163: Epoch: 12, Batch: 23, Loss: 0.4161, Elapsed: 0m4s
2023-03-06 18:28:23.424731: Epoch: 12, Batch: 24, Loss: 0.3721, Elapsed: 0m1s
2023-03-06 18:28:26.148285: Epoch: 12, Batch: 25, Loss: 0.3969, Elapsed: 0m2s
2023-03-06 18:28:30.584498: Epoch: 12, Batch: 26, Loss: 0.4145, Elapsed: 0m4s
2023-03-06 18:28:32.596444: Epoch: 12, Batch: 27, Loss: 0.3829, Elapsed: 0m2s
2023-03-06 18:28:34.972563: Epoch: 12, Batch: 28, Loss: 0.3705, Elapsed: 0m2s
2023-03-06 18:28:38.349977: Epoch: 12, Batch: 29, Loss: 0.4031, Elapsed: 0m3s
2023-03-06 18:28:42.508070: Epoch: 12, Batch: 30, Loss: 0.4108, Elapsed: 0m4s
2023-03-06 18:28:45.151280: Epoch: 12, Batch: 31, Loss: 0.3969, Elapsed: 0m2s
2023-03-06 18:28:48.836460: Epoch: 12, Batch: 32, Loss: 0.4066, Elapsed: 0m3s
2023-03-06 18:28:51.510459: Epoch: 12, Batch: 33, Loss: 0.3816, Elapsed: 0m2s
2023-03-06 18:28:55.890263: Epoch: 12, Batch: 34, Loss: 0.4150, Elapsed: 0m4s
2023-03-06 18:28:58.683491: Epoch: 12, Batch: 35, Loss: 0.3874, Elapsed: 0m2s
2023-03-06 18:29:00.708620: Epoch: 12, Batch: 36, Loss: 0.3800, Elapsed: 0m2s
2023-03-06 18:29:02.487286: Epoch: 12, Batch: 37, Loss: 0.3790, Elapsed: 0m1s
2023-03-06 18:29:04.192111: Epoch: 12, Batch: 38, Loss: 0.3629, Elapsed: 0m1s
2023-03-06 18:29:07.435191: Epoch: 12, Batch: 39, Loss: 0.3992, Elapsed: 0m3s
2023-03-06 18:29:09.867308: Epoch: 12, Batch: 40, Loss: 0.3880, Elapsed: 0m2s
2023-03-06 18:29:13.081830: Epoch: 12, Batch: 41, Loss: 0.3879, Elapsed: 0m3s
2023-03-06 18:29:15.579249: Epoch: 12, Batch: 42, Loss: 0.3959, Elapsed: 0m2s
2023-03-06 18:29:18.091023: Epoch: 12, Batch: 43, Loss: 0.3924, Elapsed: 0m2s
2023-03-06 18:29:24.366280: Epoch: 12, Batch: 44, Loss: 0.4282, Elapsed: 0m6s
2023-03-06 18:29:27.318576: Epoch: 12, Batch: 45, Loss: 0.3859, Elapsed: 0m2s
2023-03-06 18:29:32.675469: Epoch: 12, Batch: 46, Loss: 0.4224, Elapsed: 0m5s
2023-03-06 18:29:35.190182: Epoch: 12, Batch: 47, Loss: 0.3945, Elapsed: 0m2s
2023-03-06 18:29:38.607712: Epoch: 12, Batch: 48, Loss: 0.3998, Elapsed: 0m3s
2023-03-06 18:29:42.622621: Epoch: 12, Batch: 49, Loss: 0.4159, Elapsed: 0m4s
2023-03-06 18:29:45.587684: Epoch: 12, Batch: 50, Loss: 0.3913, Elapsed: 0m2s
2023-03-06 18:29:45.597360 Starting testing the valid set with 20 subgraphs!
2023-03-06 18:30:52.336320: validation Test:  Loss: 0.4042,  AUC: 0.8749, Acc: 79.1459,  Precision: 0.8004 -- Elapsed: 1m6s
2023-03-06 18:30:52.337507 Starting testing the train set with 20 subgraphs!
2023-03-06 18:35:16.172219: training Test:  Loss: 0.4032,  AUC: 0.8756, Acc: 79.2407,  Precision: 0.8019 -- Elapsed: 4m23s
2023-03-06 18:35:18.564544: Epoch: 12, Batch: 51, Loss: 0.3981, Elapsed: 0m2s
2023-03-06 18:35:21.084021: Epoch: 12, Batch: 52, Loss: 0.3923, Elapsed: 0m2s
2023-03-06 18:35:23.008419: Epoch: 12, Batch: 53, Loss: 0.3816, Elapsed: 0m1s
2023-03-06 18:35:27.800499: Epoch: 12, Batch: 54, Loss: 0.4171, Elapsed: 0m4s
2023-03-06 18:35:30.758393: Epoch: 12, Batch: 55, Loss: 0.4072, Elapsed: 0m2s
2023-03-06 18:35:33.559960: Epoch: 12, Batch: 56, Loss: 0.4020, Elapsed: 0m2s
2023-03-06 18:35:35.799647: Epoch: 12, Batch: 57, Loss: 0.3870, Elapsed: 0m2s
2023-03-06 18:35:37.804799: Epoch: 12, Batch: 58, Loss: 0.3932, Elapsed: 0m1s
2023-03-06 18:35:41.890313: Epoch: 12, Batch: 59, Loss: 0.4293, Elapsed: 0m4s
2023-03-06 18:35:44.874934: Epoch: 12, Batch: 60, Loss: 0.4027, Elapsed: 0m2s
2023-03-06 18:35:46.486224: Epoch: 12, Batch: 61, Loss: 0.3688, Elapsed: 0m1s
2023-03-06 18:35:49.922642: Epoch: 12, Batch: 62, Loss: 0.4107, Elapsed: 0m3s
2023-03-06 18:35:54.278837: Epoch: 12, Batch: 63, Loss: 0.4132, Elapsed: 0m4s
2023-03-06 18:35:55.296966: Epoch: 12, Batch: 64, Loss: 0.3367, Elapsed: 0m1s
2023-03-06 18:35:58.687654: Epoch: 12, Batch: 65, Loss: 0.4062, Elapsed: 0m3s
2023-03-06 18:36:00.222417: Epoch: 12, Batch: 66, Loss: 0.3598, Elapsed: 0m1s
2023-03-06 18:36:02.096151: Epoch: 12, Batch: 67, Loss: 0.3805, Elapsed: 0m1s
2023-03-06 18:36:04.363209: Epoch: 12, Batch: 68, Loss: 0.3891, Elapsed: 0m2s
2023-03-06 18:36:07.397682: Epoch: 12, Batch: 69, Loss: 0.4068, Elapsed: 0m3s
2023-03-06 18:36:12.497170: Epoch: 12, Batch: 70, Loss: 0.4182, Elapsed: 0m5s
2023-03-06 18:36:14.425554: Epoch: 12, Batch: 71, Loss: 0.3628, Elapsed: 0m1s
2023-03-06 18:36:18.570754: Epoch: 12, Batch: 72, Loss: 0.4134, Elapsed: 0m4s
2023-03-06 18:36:23.472582: Epoch: 12, Batch: 73, Loss: 0.4143, Elapsed: 0m4s
2023-03-06 18:36:25.790769: Epoch: 12, Batch: 74, Loss: 0.3776, Elapsed: 0m2s
2023-03-06 18:36:28.490401: Epoch: 12, Batch: 75, Loss: 0.3849, Elapsed: 0m2s
2023-03-06 18:36:31.614377: Epoch: 12, Batch: 76, Loss: 0.3927, Elapsed: 0m3s
2023-03-06 18:36:33.068430: Epoch: 12, Batch: 77, Loss: 0.3384, Elapsed: 0m1s
2023-03-06 18:36:36.237405: Epoch: 12, Batch: 78, Loss: 0.4012, Elapsed: 0m3s
2023-03-06 18:36:39.295788: Epoch: 12, Batch: 79, Loss: 0.4067, Elapsed: 0m3s
2023-03-06 18:36:41.990502: Epoch: 12, Batch: 80, Loss: 0.4073, Elapsed: 0m2s
2023-03-06 18:36:44.793100: Epoch: 13, Batch: 1, Loss: 0.3928, Elapsed: 0m2s
2023-03-06 18:36:48.445910: Epoch: 13, Batch: 2, Loss: 0.4070, Elapsed: 0m3s
2023-03-06 18:36:49.460101: Epoch: 13, Batch: 3, Loss: 0.3343, Elapsed: 0m1s
2023-03-06 18:36:53.544338: Epoch: 13, Batch: 4, Loss: 0.4283, Elapsed: 0m4s
2023-03-06 18:36:56.049441: Epoch: 13, Batch: 5, Loss: 0.3954, Elapsed: 0m2s
2023-03-06 18:37:01.217041: Epoch: 13, Batch: 6, Loss: 0.4176, Elapsed: 0m5s
2023-03-06 18:37:03.732389: Epoch: 13, Batch: 7, Loss: 0.3881, Elapsed: 0m2s
2023-03-06 18:37:09.363625: Epoch: 13, Batch: 8, Loss: 0.4204, Elapsed: 0m5s
2023-03-06 18:37:11.386814: Epoch: 13, Batch: 9, Loss: 0.3906, Elapsed: 0m2s
2023-03-06 18:37:13.877701: Epoch: 13, Batch: 10, Loss: 0.4059, Elapsed: 0m2s
2023-03-06 18:37:18.302929: Epoch: 13, Batch: 11, Loss: 0.4127, Elapsed: 0m4s
2023-03-06 18:37:22.459784: Epoch: 13, Batch: 12, Loss: 0.4133, Elapsed: 0m4s
2023-03-06 18:37:26.280839: Epoch: 13, Batch: 13, Loss: 0.4181, Elapsed: 0m3s
2023-03-06 18:37:30.379923: Epoch: 13, Batch: 14, Loss: 0.4138, Elapsed: 0m4s
2023-03-06 18:37:34.138351: Epoch: 13, Batch: 15, Loss: 0.4077, Elapsed: 0m3s
2023-03-06 18:37:35.832671: Epoch: 13, Batch: 16, Loss: 0.3655, Elapsed: 0m1s
2023-03-06 18:37:37.449962: Epoch: 13, Batch: 17, Loss: 0.3581, Elapsed: 0m1s
2023-03-06 18:37:40.947241: Epoch: 13, Batch: 18, Loss: 0.4047, Elapsed: 0m3s
2023-03-06 18:37:43.097530: Epoch: 13, Batch: 19, Loss: 0.3770, Elapsed: 0m2s
2023-03-06 18:37:47.465932: Epoch: 13, Batch: 20, Loss: 0.4151, Elapsed: 0m4s
2023-03-06 18:37:52.936355: Epoch: 13, Batch: 21, Loss: 0.3838, Elapsed: 0m5s
2023-03-06 18:37:56.609135: Epoch: 13, Batch: 22, Loss: 0.3989, Elapsed: 0m3s
2023-03-06 18:37:58.787362: Epoch: 13, Batch: 23, Loss: 0.3743, Elapsed: 0m2s
2023-03-06 18:38:03.394317: Epoch: 13, Batch: 24, Loss: 0.4152, Elapsed: 0m4s
2023-03-06 18:38:05.770214: Epoch: 13, Batch: 25, Loss: 0.3697, Elapsed: 0m2s
2023-03-06 18:38:08.154255: Epoch: 13, Batch: 26, Loss: 0.3945, Elapsed: 0m2s
2023-03-06 18:38:11.325824: Epoch: 13, Batch: 27, Loss: 0.3916, Elapsed: 0m3s
2023-03-06 18:38:14.345978: Epoch: 13, Batch: 28, Loss: 0.4030, Elapsed: 0m3s
2023-03-06 18:38:16.859211: Epoch: 13, Batch: 29, Loss: 0.3853, Elapsed: 0m2s
2023-03-06 18:38:20.109612: Epoch: 13, Batch: 30, Loss: 0.4001, Elapsed: 0m3s
2023-03-06 18:38:24.655577: Epoch: 13, Batch: 31, Loss: 0.4216, Elapsed: 0m4s
2023-03-06 18:38:29.085768: Epoch: 13, Batch: 32, Loss: 0.4147, Elapsed: 0m4s
2023-03-06 18:38:31.893141: Epoch: 13, Batch: 33, Loss: 0.3947, Elapsed: 0m2s
2023-03-06 18:38:34.935015: Epoch: 13, Batch: 34, Loss: 0.4099, Elapsed: 0m3s
2023-03-06 18:38:36.847013: Epoch: 13, Batch: 35, Loss: 0.3796, Elapsed: 0m1s
2023-03-06 18:38:39.213370: Epoch: 13, Batch: 36, Loss: 0.3867, Elapsed: 0m2s
2023-03-06 18:38:42.222145: Epoch: 13, Batch: 37, Loss: 0.4025, Elapsed: 0m2s
2023-03-06 18:38:45.332494: Epoch: 13, Batch: 38, Loss: 0.4087, Elapsed: 0m3s
2023-03-06 18:38:48.306423: Epoch: 13, Batch: 39, Loss: 0.3915, Elapsed: 0m2s
2023-03-06 18:38:50.998291: Epoch: 13, Batch: 40, Loss: 0.4077, Elapsed: 0m2s
2023-03-06 18:38:54.826034: Epoch: 13, Batch: 41, Loss: 0.4141, Elapsed: 0m3s
2023-03-06 18:38:57.671667: Epoch: 13, Batch: 42, Loss: 0.3921, Elapsed: 0m2s
2023-03-06 18:38:59.331680: Epoch: 13, Batch: 43, Loss: 0.3623, Elapsed: 0m1s
2023-03-06 18:39:02.311094: Epoch: 13, Batch: 44, Loss: 0.4020, Elapsed: 0m2s
2023-03-06 18:39:04.956162: Epoch: 13, Batch: 45, Loss: 0.3965, Elapsed: 0m2s
2023-03-06 18:39:06.953122: Epoch: 13, Batch: 46, Loss: 0.3907, Elapsed: 0m1s
2023-03-06 18:39:09.479073: Epoch: 13, Batch: 47, Loss: 0.3876, Elapsed: 0m2s
2023-03-06 18:39:11.982184: Epoch: 13, Batch: 48, Loss: 0.3960, Elapsed: 0m2s
2023-03-06 18:39:16.872383: Epoch: 13, Batch: 49, Loss: 0.4143, Elapsed: 0m4s
2023-03-06 18:39:19.818475: Epoch: 13, Batch: 50, Loss: 0.3905, Elapsed: 0m2s
2023-03-06 18:39:19.828629 Starting testing the valid set with 20 subgraphs!
2023-03-06 18:40:26.415112: validation Test:  Loss: 0.4000,  AUC: 0.8748, Acc: 79.3802,  Precision: 0.9149 -- Elapsed: 1m6s
2023-03-06 18:40:26.416290 Starting testing the train set with 20 subgraphs!
2023-03-06 18:44:50.175889: training Test:  Loss: 0.3991,  AUC: 0.8755, Acc: 79.4364,  Precision: 0.9146 -- Elapsed: 4m23s
2023-03-06 18:44:52.761951: Epoch: 13, Batch: 51, Loss: 0.3946, Elapsed: 0m2s
2023-03-06 18:44:56.142066: Epoch: 13, Batch: 52, Loss: 0.4025, Elapsed: 0m3s
2023-03-06 18:45:01.518248: Epoch: 13, Batch: 53, Loss: 0.4225, Elapsed: 0m5s
2023-03-06 18:45:05.032472: Epoch: 13, Batch: 54, Loss: 0.4149, Elapsed: 0m3s
2023-03-06 18:45:07.640750: Epoch: 13, Batch: 55, Loss: 0.3928, Elapsed: 0m2s
2023-03-06 18:45:10.582061: Epoch: 13, Batch: 56, Loss: 0.3984, Elapsed: 0m2s
2023-03-06 18:45:12.540908: Epoch: 13, Batch: 57, Loss: 0.3618, Elapsed: 0m1s
2023-03-06 18:45:15.999595: Epoch: 13, Batch: 58, Loss: 0.4095, Elapsed: 0m3s
2023-03-06 18:45:17.825631: Epoch: 13, Batch: 59, Loss: 0.3708, Elapsed: 0m1s
2023-03-06 18:45:20.815275: Epoch: 13, Batch: 60, Loss: 0.4049, Elapsed: 0m2s
2023-03-06 18:45:23.341704: Epoch: 13, Batch: 61, Loss: 0.3912, Elapsed: 0m2s
2023-03-06 18:45:25.258642: Epoch: 13, Batch: 62, Loss: 0.3740, Elapsed: 0m1s
2023-03-06 18:45:31.736104: Epoch: 13, Batch: 63, Loss: 0.4275, Elapsed: 0m6s
2023-03-06 18:45:35.452958: Epoch: 13, Batch: 64, Loss: 0.4091, Elapsed: 0m3s
2023-03-06 18:45:37.794509: Epoch: 13, Batch: 65, Loss: 0.3877, Elapsed: 0m2s
2023-03-06 18:45:40.332281: Epoch: 13, Batch: 66, Loss: 0.3843, Elapsed: 0m2s
2023-03-06 18:45:42.021503: Epoch: 13, Batch: 67, Loss: 0.3776, Elapsed: 0m1s
2023-03-06 18:45:45.587613: Epoch: 13, Batch: 68, Loss: 0.4064, Elapsed: 0m3s
2023-03-06 18:45:49.594737: Epoch: 13, Batch: 69, Loss: 0.4131, Elapsed: 0m3s
2023-03-06 18:45:51.525247: Epoch: 13, Batch: 70, Loss: 0.3781, Elapsed: 0m1s
2023-03-06 18:45:54.246576: Epoch: 13, Batch: 71, Loss: 0.3957, Elapsed: 0m2s
2023-03-06 18:45:56.516901: Epoch: 13, Batch: 72, Loss: 0.3880, Elapsed: 0m2s
2023-03-06 18:46:00.671697: Epoch: 13, Batch: 73, Loss: 0.4098, Elapsed: 0m4s
2023-03-06 18:46:01.971304: Epoch: 13, Batch: 74, Loss: 0.3374, Elapsed: 0m1s
2023-03-06 18:46:04.913732: Epoch: 13, Batch: 75, Loss: 0.3851, Elapsed: 0m2s
2023-03-06 18:46:09.043450: Epoch: 13, Batch: 76, Loss: 0.4186, Elapsed: 0m4s
2023-03-06 18:46:12.132600: Epoch: 13, Batch: 77, Loss: 0.4016, Elapsed: 0m3s
2023-03-06 18:46:14.713078: Epoch: 13, Batch: 78, Loss: 0.3873, Elapsed: 0m2s
2023-03-06 18:46:16.725944: Epoch: 13, Batch: 79, Loss: 0.3812, Elapsed: 0m2s
2023-03-06 18:46:19.005470: Epoch: 13, Batch: 80, Loss: 0.3896, Elapsed: 0m2s
2023-03-06 18:46:21.700354: Epoch: 14, Batch: 1, Loss: 0.4067, Elapsed: 0m2s
2023-03-06 18:46:26.180153: Epoch: 14, Batch: 2, Loss: 0.4172, Elapsed: 0m4s
2023-03-06 18:46:28.571391: Epoch: 14, Batch: 3, Loss: 0.3698, Elapsed: 0m2s
2023-03-06 18:46:31.055788: Epoch: 14, Batch: 4, Loss: 0.3926, Elapsed: 0m2s
2023-03-06 18:46:34.960947: Epoch: 14, Batch: 5, Loss: 0.4122, Elapsed: 0m3s
2023-03-06 18:46:36.892963: Epoch: 14, Batch: 6, Loss: 0.3703, Elapsed: 0m1s
2023-03-06 18:46:40.189019: Epoch: 14, Batch: 7, Loss: 0.4058, Elapsed: 0m3s
2023-03-06 18:46:42.881595: Epoch: 14, Batch: 8, Loss: 0.4047, Elapsed: 0m2s
2023-03-06 18:46:47.491907: Epoch: 14, Batch: 9, Loss: 0.4103, Elapsed: 0m4s
2023-03-06 18:46:49.470997: Epoch: 14, Batch: 10, Loss: 0.3807, Elapsed: 0m1s
2023-03-06 18:46:55.083933: Epoch: 14, Batch: 11, Loss: 0.4189, Elapsed: 0m5s
2023-03-06 18:46:59.172058: Epoch: 14, Batch: 12, Loss: 0.4264, Elapsed: 0m4s
2023-03-06 18:47:00.212121: Epoch: 14, Batch: 13, Loss: 0.3344, Elapsed: 0m1s
2023-03-06 18:47:02.551804: Epoch: 14, Batch: 14, Loss: 0.3887, Elapsed: 0m2s
2023-03-06 18:47:05.409892: Epoch: 14, Batch: 15, Loss: 0.3902, Elapsed: 0m2s
2023-03-06 18:47:10.565094: Epoch: 14, Batch: 16, Loss: 0.3849, Elapsed: 0m5s
2023-03-06 18:47:12.581160: Epoch: 14, Batch: 17, Loss: 0.3902, Elapsed: 0m2s
2023-03-06 18:47:15.574409: Epoch: 14, Batch: 18, Loss: 0.4073, Elapsed: 0m2s
2023-03-06 18:47:18.793529: Epoch: 14, Batch: 19, Loss: 0.4015, Elapsed: 0m3s
2023-03-06 18:47:21.380118: Epoch: 14, Batch: 20, Loss: 0.3840, Elapsed: 0m2s
2023-03-06 18:47:24.400743: Epoch: 14, Batch: 21, Loss: 0.3912, Elapsed: 0m3s
2023-03-06 18:47:26.356798: Epoch: 14, Batch: 22, Loss: 0.3781, Elapsed: 0m1s
2023-03-06 18:47:30.485549: Epoch: 14, Batch: 23, Loss: 0.4195, Elapsed: 0m4s
2023-03-06 18:47:32.096323: Epoch: 14, Batch: 24, Loss: 0.3650, Elapsed: 0m1s
2023-03-06 18:47:34.130530: Epoch: 14, Batch: 25, Loss: 0.3902, Elapsed: 0m2s
2023-03-06 18:47:35.997051: Epoch: 14, Batch: 26, Loss: 0.3784, Elapsed: 0m1s
2023-03-06 18:47:41.113766: Epoch: 14, Batch: 27, Loss: 0.4173, Elapsed: 0m5s
2023-03-06 18:47:43.631183: Epoch: 14, Batch: 28, Loss: 0.3909, Elapsed: 0m2s
2023-03-06 18:47:49.879527: Epoch: 14, Batch: 29, Loss: 0.4270, Elapsed: 0m6s
2023-03-06 18:47:51.815854: Epoch: 14, Batch: 30, Loss: 0.3725, Elapsed: 0m1s
2023-03-06 18:47:56.736628: Epoch: 14, Batch: 31, Loss: 0.4126, Elapsed: 0m4s
2023-03-06 18:47:58.441208: Epoch: 14, Batch: 32, Loss: 0.3613, Elapsed: 0m1s
2023-03-06 18:48:00.634531: Epoch: 14, Batch: 33, Loss: 0.3870, Elapsed: 0m2s
2023-03-06 18:48:03.612236: Epoch: 14, Batch: 34, Loss: 0.4014, Elapsed: 0m2s
2023-03-06 18:48:06.836108: Epoch: 14, Batch: 35, Loss: 0.3862, Elapsed: 0m3s
2023-03-06 18:48:10.418410: Epoch: 14, Batch: 36, Loss: 0.4060, Elapsed: 0m3s
2023-03-06 18:48:15.035336: Epoch: 14, Batch: 37, Loss: 0.4134, Elapsed: 0m4s
2023-03-06 18:48:18.438926: Epoch: 14, Batch: 38, Loss: 0.3972, Elapsed: 0m3s
2023-03-06 18:48:21.494503: Epoch: 14, Batch: 39, Loss: 0.3900, Elapsed: 0m3s
2023-03-06 18:48:25.418629: Epoch: 14, Batch: 40, Loss: 0.4040, Elapsed: 0m3s
2023-03-06 18:48:29.702816: Epoch: 14, Batch: 41, Loss: 0.4125, Elapsed: 0m4s
2023-03-06 18:48:33.404842: Epoch: 14, Batch: 42, Loss: 0.4078, Elapsed: 0m3s
2023-03-06 18:48:36.233583: Epoch: 14, Batch: 43, Loss: 0.3950, Elapsed: 0m2s
2023-03-06 18:48:41.559124: Epoch: 14, Batch: 44, Loss: 0.4210, Elapsed: 0m5s
2023-03-06 18:48:43.698905: Epoch: 14, Batch: 45, Loss: 0.3757, Elapsed: 0m2s
2023-03-06 18:48:45.896083: Epoch: 14, Batch: 46, Loss: 0.3835, Elapsed: 0m2s
2023-03-06 18:48:50.296630: Epoch: 14, Batch: 47, Loss: 0.4111, Elapsed: 0m4s
2023-03-06 18:48:54.582392: Epoch: 14, Batch: 48, Loss: 0.4139, Elapsed: 0m4s
2023-03-06 18:48:57.374623: Epoch: 14, Batch: 49, Loss: 0.3909, Elapsed: 0m2s
2023-03-06 18:48:59.878063: Epoch: 14, Batch: 50, Loss: 0.3943, Elapsed: 0m2s
2023-03-06 18:48:59.886903 Starting testing the valid set with 20 subgraphs!
2023-03-06 18:50:07.013186: validation Test:  Loss: 0.3980,  AUC: 0.8760, Acc: 79.4126,  Precision: 0.8707 -- Elapsed: 1m7s
2023-03-06 18:50:07.014762 Starting testing the train set with 20 subgraphs!
2023-03-06 18:54:28.834054: training Test:  Loss: 0.3970,  AUC: 0.8766, Acc: 79.4769,  Precision: 0.8717 -- Elapsed: 4m21s
2023-03-06 18:54:31.484822: Epoch: 14, Batch: 51, Loss: 0.3854, Elapsed: 0m2s
2023-03-06 18:54:34.229147: Epoch: 14, Batch: 52, Loss: 0.3791, Elapsed: 0m2s
2023-03-06 18:54:36.985282: Epoch: 14, Batch: 53, Loss: 0.3916, Elapsed: 0m2s
2023-03-06 18:54:39.610316: Epoch: 14, Batch: 54, Loss: 0.3918, Elapsed: 0m2s
2023-03-06 18:54:41.579401: Epoch: 14, Batch: 55, Loss: 0.3617, Elapsed: 0m1s
2023-03-06 18:54:45.058111: Epoch: 14, Batch: 56, Loss: 0.4144, Elapsed: 0m3s
2023-03-06 18:54:47.846545: Epoch: 14, Batch: 57, Loss: 0.3976, Elapsed: 0m2s
2023-03-06 18:54:50.953952: Epoch: 14, Batch: 58, Loss: 0.3856, Elapsed: 0m3s
2023-03-06 18:54:53.332352: Epoch: 14, Batch: 59, Loss: 0.3880, Elapsed: 0m2s
2023-03-06 18:54:56.448477: Epoch: 14, Batch: 60, Loss: 0.4053, Elapsed: 0m3s
2023-03-06 18:55:00.582827: Epoch: 14, Batch: 61, Loss: 0.4096, Elapsed: 0m4s
2023-03-06 18:55:03.927260: Epoch: 14, Batch: 62, Loss: 0.4009, Elapsed: 0m3s
2023-03-06 18:55:07.356041: Epoch: 14, Batch: 63, Loss: 0.4091, Elapsed: 0m3s
2023-03-06 18:55:09.864989: Epoch: 14, Batch: 64, Loss: 0.3854, Elapsed: 0m2s
2023-03-06 18:55:12.416638: Epoch: 14, Batch: 65, Loss: 0.3940, Elapsed: 0m2s
2023-03-06 18:55:15.382549: Epoch: 14, Batch: 66, Loss: 0.3989, Elapsed: 0m2s
2023-03-06 18:55:18.236003: Epoch: 14, Batch: 67, Loss: 0.3917, Elapsed: 0m2s
2023-03-06 18:55:19.933938: Epoch: 14, Batch: 68, Loss: 0.3802, Elapsed: 0m1s
2023-03-06 18:55:21.460438: Epoch: 14, Batch: 69, Loss: 0.3604, Elapsed: 0m1s
2023-03-06 18:55:24.303184: Epoch: 14, Batch: 70, Loss: 0.4034, Elapsed: 0m2s
2023-03-06 18:55:26.704389: Epoch: 14, Batch: 71, Loss: 0.3945, Elapsed: 0m2s
2023-03-06 18:55:28.014594: Epoch: 14, Batch: 72, Loss: 0.3427, Elapsed: 0m1s
2023-03-06 18:55:31.470826: Epoch: 14, Batch: 73, Loss: 0.4043, Elapsed: 0m3s
2023-03-06 18:55:35.158366: Epoch: 14, Batch: 74, Loss: 0.4085, Elapsed: 0m3s
2023-03-06 18:55:39.541955: Epoch: 14, Batch: 75, Loss: 0.4168, Elapsed: 0m4s
2023-03-06 18:55:41.723374: Epoch: 14, Batch: 76, Loss: 0.3788, Elapsed: 0m2s
2023-03-06 18:55:45.831869: Epoch: 14, Batch: 77, Loss: 0.4191, Elapsed: 0m4s
2023-03-06 18:55:48.562307: Epoch: 14, Batch: 78, Loss: 0.3998, Elapsed: 0m2s
2023-03-06 18:55:52.221711: Epoch: 14, Batch: 79, Loss: 0.4114, Elapsed: 0m3s
2023-03-06 18:55:56.263618: Epoch: 14, Batch: 80, Loss: 0.4218, Elapsed: 0m4s
2023-03-06 18:55:58.295912: Epoch: 15, Batch: 1, Loss: 0.3833, Elapsed: 0m2s
2023-03-06 18:56:01.133131: Epoch: 15, Batch: 2, Loss: 0.3954, Elapsed: 0m2s
2023-03-06 18:56:03.547630: Epoch: 15, Batch: 3, Loss: 0.3735, Elapsed: 0m2s
2023-03-06 18:56:05.829133: Epoch: 15, Batch: 4, Loss: 0.3926, Elapsed: 0m2s
2023-03-06 18:56:10.196463: Epoch: 15, Batch: 5, Loss: 0.4131, Elapsed: 0m4s
2023-03-06 18:56:15.548046: Epoch: 15, Batch: 6, Loss: 0.4236, Elapsed: 0m5s
2023-03-06 18:56:17.374294: Epoch: 15, Batch: 7, Loss: 0.3736, Elapsed: 0m1s
2023-03-06 18:56:20.210335: Epoch: 15, Batch: 8, Loss: 0.3945, Elapsed: 0m2s
2023-03-06 18:56:22.709191: Epoch: 15, Batch: 9, Loss: 0.3957, Elapsed: 0m2s
2023-03-06 18:56:26.129225: Epoch: 15, Batch: 10, Loss: 0.3994, Elapsed: 0m3s
2023-03-06 18:56:28.003293: Epoch: 15, Batch: 11, Loss: 0.3802, Elapsed: 0m1s
2023-03-06 18:56:29.993151: Epoch: 15, Batch: 12, Loss: 0.3832, Elapsed: 0m1s
2023-03-06 18:56:32.503628: Epoch: 15, Batch: 13, Loss: 0.3821, Elapsed: 0m2s
2023-03-06 18:56:35.584367: Epoch: 15, Batch: 14, Loss: 0.4077, Elapsed: 0m3s
2023-03-06 18:56:39.165214: Epoch: 15, Batch: 15, Loss: 0.4080, Elapsed: 0m3s
2023-03-06 18:56:43.328236: Epoch: 15, Batch: 16, Loss: 0.4133, Elapsed: 0m4s
2023-03-06 18:56:46.289617: Epoch: 15, Batch: 17, Loss: 0.3914, Elapsed: 0m2s
2023-03-06 18:56:50.736379: Epoch: 15, Batch: 18, Loss: 0.4124, Elapsed: 0m4s
2023-03-06 18:56:53.246673: Epoch: 15, Batch: 19, Loss: 0.3955, Elapsed: 0m2s
2023-03-06 18:56:55.880615: Epoch: 15, Batch: 20, Loss: 0.3960, Elapsed: 0m2s
2023-03-06 18:56:57.607356: Epoch: 15, Batch: 21, Loss: 0.3773, Elapsed: 0m1s
2023-03-06 18:56:59.655735: Epoch: 15, Batch: 22, Loss: 0.3626, Elapsed: 0m2s
2023-03-06 18:57:02.588962: Epoch: 15, Batch: 23, Loss: 0.3987, Elapsed: 0m2s
2023-03-06 18:57:05.463098: Epoch: 15, Batch: 24, Loss: 0.3908, Elapsed: 0m2s
2023-03-06 18:57:09.117610: Epoch: 15, Batch: 25, Loss: 0.4051, Elapsed: 0m3s
2023-03-06 18:57:14.205152: Epoch: 15, Batch: 26, Loss: 0.3859, Elapsed: 0m5s
2023-03-06 18:57:19.837706: Epoch: 15, Batch: 27, Loss: 0.4194, Elapsed: 0m5s
2023-03-06 18:57:21.492048: Epoch: 15, Batch: 28, Loss: 0.3657, Elapsed: 0m1s
2023-03-06 18:57:26.156827: Epoch: 15, Batch: 29, Loss: 0.4139, Elapsed: 0m4s
2023-03-06 18:57:28.730190: Epoch: 15, Batch: 30, Loss: 0.4053, Elapsed: 0m2s
2023-03-06 18:57:33.054970: Epoch: 15, Batch: 31, Loss: 0.4130, Elapsed: 0m4s
2023-03-06 18:57:37.025118: Epoch: 15, Batch: 32, Loss: 0.4070, Elapsed: 0m3s
2023-03-06 18:57:41.252613: Epoch: 15, Batch: 33, Loss: 0.4133, Elapsed: 0m4s
2023-03-06 18:57:44.425735: Epoch: 15, Batch: 34, Loss: 0.3865, Elapsed: 0m3s
2023-03-06 18:57:46.926653: Epoch: 15, Batch: 35, Loss: 0.3915, Elapsed: 0m2s
2023-03-06 18:57:51.086737: Epoch: 15, Batch: 36, Loss: 0.4092, Elapsed: 0m4s
2023-03-06 18:57:55.153867: Epoch: 15, Batch: 37, Loss: 0.4259, Elapsed: 0m4s
2023-03-06 18:57:57.602407: Epoch: 15, Batch: 38, Loss: 0.3918, Elapsed: 0m2s
2023-03-06 18:57:59.641039: Epoch: 15, Batch: 39, Loss: 0.3885, Elapsed: 0m2s
2023-03-06 18:58:01.294979: Epoch: 15, Batch: 40, Loss: 0.3616, Elapsed: 0m1s
2023-03-06 18:58:04.126350: Epoch: 15, Batch: 41, Loss: 0.4057, Elapsed: 0m2s
2023-03-06 18:58:05.747404: Epoch: 15, Batch: 42, Loss: 0.3563, Elapsed: 0m1s
2023-03-06 18:58:12.066327: Epoch: 15, Batch: 43, Loss: 0.4261, Elapsed: 0m6s
2023-03-06 18:58:14.483678: Epoch: 15, Batch: 44, Loss: 0.3859, Elapsed: 0m2s
2023-03-06 18:58:16.979887: Epoch: 15, Batch: 45, Loss: 0.3854, Elapsed: 0m2s
2023-03-06 18:58:19.149931: Epoch: 15, Batch: 46, Loss: 0.3865, Elapsed: 0m2s
2023-03-06 18:58:21.622964: Epoch: 15, Batch: 47, Loss: 0.3831, Elapsed: 0m2s
2023-03-06 18:58:23.799649: Epoch: 15, Batch: 48, Loss: 0.3750, Elapsed: 0m2s
2023-03-06 18:58:26.474128: Epoch: 15, Batch: 49, Loss: 0.3925, Elapsed: 0m2s
2023-03-06 18:58:29.384057: Epoch: 15, Batch: 50, Loss: 0.3938, Elapsed: 0m2s
2023-03-06 18:58:29.392252 Starting testing the valid set with 20 subgraphs!
2023-03-06 18:59:37.219949: validation Test:  Loss: 0.3977,  AUC: 0.8762, Acc: 79.4137,  Precision: 0.8554 -- Elapsed: 1m7s
2023-03-06 18:59:37.221232 Starting testing the train set with 20 subgraphs!
2023-03-06 19:04:02.180740: training Test:  Loss: 0.3968,  AUC: 0.8768, Acc: 79.5144,  Precision: 0.8562 -- Elapsed: 4m24s
2023-03-06 19:04:05.963480: Epoch: 15, Batch: 51, Loss: 0.4081, Elapsed: 0m3s
2023-03-06 19:04:09.510936: Epoch: 15, Batch: 52, Loss: 0.3969, Elapsed: 0m3s
2023-03-06 19:04:12.134053: Epoch: 15, Batch: 53, Loss: 0.3900, Elapsed: 0m2s
2023-03-06 19:04:15.062692: Epoch: 15, Batch: 54, Loss: 0.3839, Elapsed: 0m2s
2023-03-06 19:04:16.976592: Epoch: 15, Batch: 55, Loss: 0.3714, Elapsed: 0m1s
2023-03-06 19:04:21.454090: Epoch: 15, Batch: 56, Loss: 0.4159, Elapsed: 0m4s
2023-03-06 19:04:23.452828: Epoch: 15, Batch: 57, Loss: 0.3876, Elapsed: 0m1s
2023-03-06 19:04:27.252255: Epoch: 15, Batch: 58, Loss: 0.4158, Elapsed: 0m3s
2023-03-06 19:04:28.571756: Epoch: 15, Batch: 59, Loss: 0.3359, Elapsed: 0m1s
2023-03-06 19:04:31.012259: Epoch: 15, Batch: 60, Loss: 0.3874, Elapsed: 0m2s
2023-03-06 19:04:35.511351: Epoch: 15, Batch: 61, Loss: 0.4136, Elapsed: 0m4s
2023-03-06 19:04:38.485194: Epoch: 15, Batch: 62, Loss: 0.3985, Elapsed: 0m2s
2023-03-06 19:04:42.273471: Epoch: 15, Batch: 63, Loss: 0.4101, Elapsed: 0m3s
2023-03-06 19:04:45.702746: Epoch: 15, Batch: 64, Loss: 0.4006, Elapsed: 0m3s
2023-03-06 19:04:49.478322: Epoch: 15, Batch: 65, Loss: 0.4133, Elapsed: 0m3s
2023-03-06 19:04:52.220326: Epoch: 15, Batch: 66, Loss: 0.3851, Elapsed: 0m2s
2023-03-06 19:04:55.378017: Epoch: 15, Batch: 67, Loss: 0.4031, Elapsed: 0m3s
2023-03-06 19:04:58.489819: Epoch: 15, Batch: 68, Loss: 0.4041, Elapsed: 0m3s
2023-03-06 19:05:00.691074: Epoch: 15, Batch: 69, Loss: 0.3829, Elapsed: 0m2s
2023-03-06 19:05:05.556521: Epoch: 15, Batch: 70, Loss: 0.4119, Elapsed: 0m4s
2023-03-06 19:05:09.865468: Epoch: 15, Batch: 71, Loss: 0.4162, Elapsed: 0m4s
2023-03-06 19:05:12.854234: Epoch: 15, Batch: 72, Loss: 0.3883, Elapsed: 0m2s
2023-03-06 19:05:15.878884: Epoch: 15, Batch: 73, Loss: 0.3986, Elapsed: 0m3s
2023-03-06 19:05:16.895102: Epoch: 15, Batch: 74, Loss: 0.3340, Elapsed: 0m1s
2023-03-06 19:05:19.890635: Epoch: 15, Batch: 75, Loss: 0.4008, Elapsed: 0m2s
2023-03-06 19:05:22.067770: Epoch: 15, Batch: 76, Loss: 0.3719, Elapsed: 0m2s
2023-03-06 19:05:25.507783: Epoch: 15, Batch: 77, Loss: 0.4066, Elapsed: 0m3s
2023-03-06 19:05:28.908927: Epoch: 15, Batch: 78, Loss: 0.4028, Elapsed: 0m3s
2023-03-06 19:05:34.118956: Epoch: 15, Batch: 79, Loss: 0.4157, Elapsed: 0m5s
2023-03-06 19:05:37.148052: Epoch: 15, Batch: 80, Loss: 0.3981, Elapsed: 0m3s
2023-03-06 19:05:39.766623: Epoch: 16, Batch: 1, Loss: 0.4035, Elapsed: 0m2s
2023-03-06 19:05:40.779373: Epoch: 16, Batch: 2, Loss: 0.3343, Elapsed: 0m1s
2023-03-06 19:05:43.944246: Epoch: 16, Batch: 3, Loss: 0.3851, Elapsed: 0m3s
2023-03-06 19:05:45.946292: Epoch: 16, Batch: 4, Loss: 0.3875, Elapsed: 0m1s
2023-03-06 19:05:47.786694: Epoch: 16, Batch: 5, Loss: 0.3699, Elapsed: 0m1s
2023-03-06 19:05:51.886925: Epoch: 16, Batch: 6, Loss: 0.4129, Elapsed: 0m4s
2023-03-06 19:05:54.309734: Epoch: 16, Batch: 7, Loss: 0.3858, Elapsed: 0m2s
2023-03-06 19:05:58.928940: Epoch: 16, Batch: 8, Loss: 0.4125, Elapsed: 0m4s
2023-03-06 19:06:01.772890: Epoch: 16, Batch: 9, Loss: 0.3899, Elapsed: 0m2s
2023-03-06 19:06:03.387123: Epoch: 16, Batch: 10, Loss: 0.3639, Elapsed: 0m1s
2023-03-06 19:06:06.358350: Epoch: 16, Batch: 11, Loss: 0.4028, Elapsed: 0m2s
2023-03-06 19:06:08.844265: Epoch: 16, Batch: 12, Loss: 0.3841, Elapsed: 0m2s
2023-03-06 19:06:10.136843: Epoch: 16, Batch: 13, Loss: 0.3359, Elapsed: 0m1s
2023-03-06 19:06:14.577087: Epoch: 16, Batch: 14, Loss: 0.4101, Elapsed: 0m4s
2023-03-06 19:06:17.982522: Epoch: 16, Batch: 15, Loss: 0.4037, Elapsed: 0m3s
2023-03-06 19:06:20.132158: Epoch: 16, Batch: 16, Loss: 0.3747, Elapsed: 0m2s
2023-03-06 19:06:22.670390: Epoch: 16, Batch: 17, Loss: 0.3847, Elapsed: 0m2s
2023-03-06 19:06:25.907681: Epoch: 16, Batch: 18, Loss: 0.3970, Elapsed: 0m3s
2023-03-06 19:06:30.062253: Epoch: 16, Batch: 19, Loss: 0.4084, Elapsed: 0m4s
2023-03-06 19:06:33.016357: Epoch: 16, Batch: 20, Loss: 0.3878, Elapsed: 0m2s
2023-03-06 19:06:36.382567: Epoch: 16, Batch: 21, Loss: 0.4011, Elapsed: 0m3s
2023-03-06 19:06:38.784461: Epoch: 16, Batch: 22, Loss: 0.3882, Elapsed: 0m2s
2023-03-06 19:06:45.231024: Epoch: 16, Batch: 23, Loss: 0.4260, Elapsed: 0m6s
2023-03-06 19:06:48.889248: Epoch: 16, Batch: 24, Loss: 0.4069, Elapsed: 0m3s
2023-03-06 19:06:51.465557: Epoch: 16, Batch: 25, Loss: 0.3922, Elapsed: 0m2s
2023-03-06 19:06:53.338349: Epoch: 16, Batch: 26, Loss: 0.3774, Elapsed: 0m1s
2023-03-06 19:06:57.510450: Epoch: 16, Batch: 27, Loss: 0.4118, Elapsed: 0m4s
2023-03-06 19:06:59.554746: Epoch: 16, Batch: 28, Loss: 0.3759, Elapsed: 0m2s
2023-03-06 19:07:01.933590: Epoch: 16, Batch: 29, Loss: 0.3826, Elapsed: 0m2s
2023-03-06 19:07:04.636698: Epoch: 16, Batch: 30, Loss: 0.3914, Elapsed: 0m2s
2023-03-06 19:07:06.991216: Epoch: 16, Batch: 31, Loss: 0.3713, Elapsed: 0m2s
2023-03-06 19:07:11.055512: Epoch: 16, Batch: 32, Loss: 0.4114, Elapsed: 0m4s
2023-03-06 19:07:15.378995: Epoch: 16, Batch: 33, Loss: 0.4093, Elapsed: 0m4s
2023-03-06 19:07:18.055146: Epoch: 16, Batch: 34, Loss: 0.4043, Elapsed: 0m2s
2023-03-06 19:07:20.764400: Epoch: 16, Batch: 35, Loss: 0.3928, Elapsed: 0m2s
2023-03-06 19:07:24.818256: Epoch: 16, Batch: 36, Loss: 0.4251, Elapsed: 0m4s
2023-03-06 19:07:27.312076: Epoch: 16, Batch: 37, Loss: 0.3778, Elapsed: 0m2s
2023-03-06 19:07:30.952898: Epoch: 16, Batch: 38, Loss: 0.4026, Elapsed: 0m3s
2023-03-06 19:07:33.560314: Epoch: 16, Batch: 39, Loss: 0.3935, Elapsed: 0m2s
2023-03-06 19:07:36.416286: Epoch: 16, Batch: 40, Loss: 0.3977, Elapsed: 0m2s
2023-03-06 19:07:38.368978: Epoch: 16, Batch: 41, Loss: 0.3705, Elapsed: 0m1s
2023-03-06 19:07:40.659602: Epoch: 16, Batch: 42, Loss: 0.3866, Elapsed: 0m2s
2023-03-06 19:07:46.411469: Epoch: 16, Batch: 43, Loss: 0.4204, Elapsed: 0m5s
2023-03-06 19:07:49.165495: Epoch: 16, Batch: 44, Loss: 0.3842, Elapsed: 0m2s
2023-03-06 19:07:52.374947: Epoch: 16, Batch: 45, Loss: 0.3996, Elapsed: 0m3s
2023-03-06 19:07:56.505914: Epoch: 16, Batch: 46, Loss: 0.4158, Elapsed: 0m4s
2023-03-06 19:07:59.944519: Epoch: 16, Batch: 47, Loss: 0.4060, Elapsed: 0m3s
2023-03-06 19:08:05.529225: Epoch: 16, Batch: 48, Loss: 0.4171, Elapsed: 0m5s
2023-03-06 19:08:09.081237: Epoch: 16, Batch: 49, Loss: 0.4044, Elapsed: 0m3s
2023-03-06 19:08:10.766607: Epoch: 16, Batch: 50, Loss: 0.3744, Elapsed: 0m1s
2023-03-06 19:08:10.777737 Starting testing the valid set with 20 subgraphs!
2023-03-06 19:09:16.183612: validation Test:  Loss: 0.3968,  AUC: 0.8763, Acc: 79.4773,  Precision: 0.9003 -- Elapsed: 1m5s
2023-03-06 19:09:16.184815 Starting testing the train set with 20 subgraphs!
2023-03-06 19:13:39.445209: training Test:  Loss: 0.3960,  AUC: 0.8769, Acc: 79.5497,  Precision: 0.9019 -- Elapsed: 4m23s
2023-03-06 19:13:44.041975: Epoch: 16, Batch: 51, Loss: 0.4151, Elapsed: 0m4s
2023-03-06 19:13:49.150236: Epoch: 16, Batch: 52, Loss: 0.4154, Elapsed: 0m5s
2023-03-06 19:13:51.706654: Epoch: 16, Batch: 53, Loss: 0.3900, Elapsed: 0m2s
2023-03-06 19:13:54.240505: Epoch: 16, Batch: 54, Loss: 0.3906, Elapsed: 0m2s
2023-03-06 19:13:56.933346: Epoch: 16, Batch: 55, Loss: 0.3934, Elapsed: 0m2s
2023-03-06 19:14:01.609816: Epoch: 16, Batch: 56, Loss: 0.4130, Elapsed: 0m4s
2023-03-06 19:14:05.449670: Epoch: 16, Batch: 57, Loss: 0.4097, Elapsed: 0m3s
2023-03-06 19:14:08.262790: Epoch: 16, Batch: 58, Loss: 0.3904, Elapsed: 0m2s
2023-03-06 19:14:10.326563: Epoch: 16, Batch: 59, Loss: 0.3794, Elapsed: 0m2s
2023-03-06 19:14:12.362357: Epoch: 16, Batch: 60, Loss: 0.3604, Elapsed: 0m2s
2023-03-06 19:14:15.911411: Epoch: 16, Batch: 61, Loss: 0.3965, Elapsed: 0m3s
2023-03-06 19:14:17.462128: Epoch: 16, Batch: 62, Loss: 0.3547, Elapsed: 0m1s
2023-03-06 19:14:20.256571: Epoch: 16, Batch: 63, Loss: 0.3897, Elapsed: 0m2s
2023-03-06 19:14:22.414055: Epoch: 16, Batch: 64, Loss: 0.3854, Elapsed: 0m2s
2023-03-06 19:14:25.445958: Epoch: 16, Batch: 65, Loss: 0.4036, Elapsed: 0m3s
2023-03-06 19:14:30.564445: Epoch: 16, Batch: 66, Loss: 0.3862, Elapsed: 0m5s
2023-03-06 19:14:33.066190: Epoch: 16, Batch: 67, Loss: 0.3893, Elapsed: 0m2s
2023-03-06 19:14:36.506371: Epoch: 16, Batch: 68, Loss: 0.4073, Elapsed: 0m3s
2023-03-06 19:14:40.366093: Epoch: 16, Batch: 69, Loss: 0.4152, Elapsed: 0m3s
2023-03-06 19:14:42.814626: Epoch: 16, Batch: 70, Loss: 0.3679, Elapsed: 0m2s
2023-03-06 19:14:44.482701: Epoch: 16, Batch: 71, Loss: 0.3599, Elapsed: 0m1s
2023-03-06 19:14:47.285091: Epoch: 16, Batch: 72, Loss: 0.3962, Elapsed: 0m2s
2023-03-06 19:14:50.765681: Epoch: 16, Batch: 73, Loss: 0.4129, Elapsed: 0m3s
2023-03-06 19:14:53.837671: Epoch: 16, Batch: 74, Loss: 0.4042, Elapsed: 0m3s
2023-03-06 19:14:56.787686: Epoch: 16, Batch: 75, Loss: 0.3879, Elapsed: 0m2s
2023-03-06 19:14:58.801622: Epoch: 16, Batch: 76, Loss: 0.3864, Elapsed: 0m2s
2023-03-06 19:15:01.723408: Epoch: 16, Batch: 77, Loss: 0.3826, Elapsed: 0m2s
2023-03-06 19:15:04.704331: Epoch: 16, Batch: 78, Loss: 0.3974, Elapsed: 0m2s
2023-03-06 19:15:09.641061: Epoch: 16, Batch: 79, Loss: 0.4109, Elapsed: 0m4s
2023-03-06 19:15:12.706810: Epoch: 16, Batch: 80, Loss: 0.3974, Elapsed: 0m3s
2023-03-06 19:15:19.233954: Epoch: 17, Batch: 1, Loss: 0.4253, Elapsed: 0m6s
2023-03-06 19:15:21.158327: Epoch: 17, Batch: 2, Loss: 0.3705, Elapsed: 0m1s
2023-03-06 19:15:22.843800: Epoch: 17, Batch: 3, Loss: 0.3742, Elapsed: 0m1s
2023-03-06 19:15:26.279567: Epoch: 17, Batch: 4, Loss: 0.4057, Elapsed: 0m3s
2023-03-06 19:15:28.804759: Epoch: 17, Batch: 5, Loss: 0.3839, Elapsed: 0m2s
2023-03-06 19:15:31.733304: Epoch: 17, Batch: 6, Loss: 0.3874, Elapsed: 0m2s
2023-03-06 19:15:33.029079: Epoch: 17, Batch: 7, Loss: 0.3346, Elapsed: 0m1s
2023-03-06 19:15:36.059195: Epoch: 17, Batch: 8, Loss: 0.3972, Elapsed: 0m3s
2023-03-06 19:15:40.191900: Epoch: 17, Batch: 9, Loss: 0.4074, Elapsed: 0m4s
2023-03-06 19:15:44.674506: Epoch: 17, Batch: 10, Loss: 0.4152, Elapsed: 0m4s
2023-03-06 19:15:49.877084: Epoch: 17, Batch: 11, Loss: 0.4110, Elapsed: 0m5s
2023-03-06 19:15:55.350782: Epoch: 17, Batch: 12, Loss: 0.4152, Elapsed: 0m5s
2023-03-06 19:15:57.761996: Epoch: 17, Batch: 13, Loss: 0.3841, Elapsed: 0m2s
2023-03-06 19:15:59.692193: Epoch: 17, Batch: 14, Loss: 0.3751, Elapsed: 0m1s
2023-03-06 19:16:02.548507: Epoch: 17, Batch: 15, Loss: 0.3976, Elapsed: 0m2s
2023-03-06 19:16:05.476071: Epoch: 17, Batch: 16, Loss: 0.3824, Elapsed: 0m2s
2023-03-06 19:16:10.075058: Epoch: 17, Batch: 17, Loss: 0.4121, Elapsed: 0m4s
2023-03-06 19:16:15.411719: Epoch: 17, Batch: 18, Loss: 0.4202, Elapsed: 0m5s
2023-03-06 19:16:18.133032: Epoch: 17, Batch: 19, Loss: 0.3922, Elapsed: 0m2s
2023-03-06 19:16:20.817371: Epoch: 17, Batch: 20, Loss: 0.3904, Elapsed: 0m2s
2023-03-06 19:16:25.114452: Epoch: 17, Batch: 21, Loss: 0.4121, Elapsed: 0m4s
2023-03-06 19:16:28.161568: Epoch: 17, Batch: 22, Loss: 0.4032, Elapsed: 0m3s
2023-03-06 19:16:29.813019: Epoch: 17, Batch: 23, Loss: 0.3598, Elapsed: 0m1s
2023-03-06 19:16:32.429471: Epoch: 17, Batch: 24, Loss: 0.3935, Elapsed: 0m2s
2023-03-06 19:16:35.885711: Epoch: 17, Batch: 25, Loss: 0.4070, Elapsed: 0m3s
2023-03-06 19:16:37.873418: Epoch: 17, Batch: 26, Loss: 0.3874, Elapsed: 0m1s
2023-03-06 19:16:41.519768: Epoch: 17, Batch: 27, Loss: 0.4038, Elapsed: 0m3s
2023-03-06 19:16:45.182355: Epoch: 17, Batch: 28, Loss: 0.4052, Elapsed: 0m3s
2023-03-06 19:16:47.577869: Epoch: 17, Batch: 29, Loss: 0.3910, Elapsed: 0m2s
2023-03-06 19:16:50.209882: Epoch: 17, Batch: 30, Loss: 0.3905, Elapsed: 0m2s
2023-03-06 19:16:55.693441: Epoch: 17, Batch: 31, Loss: 0.3863, Elapsed: 0m5s
2023-03-06 19:17:00.054663: Epoch: 17, Batch: 32, Loss: 0.4111, Elapsed: 0m4s
2023-03-06 19:17:03.287175: Epoch: 17, Batch: 33, Loss: 0.3956, Elapsed: 0m3s
2023-03-06 19:17:05.747165: Epoch: 17, Batch: 34, Loss: 0.3824, Elapsed: 0m2s
2023-03-06 19:17:09.818793: Epoch: 17, Batch: 35, Loss: 0.4246, Elapsed: 0m4s
2023-03-06 19:17:13.941118: Epoch: 17, Batch: 36, Loss: 0.4152, Elapsed: 0m4s
2023-03-06 19:17:17.367763: Epoch: 17, Batch: 37, Loss: 0.4021, Elapsed: 0m3s
2023-03-06 19:17:19.932934: Epoch: 17, Batch: 38, Loss: 0.3915, Elapsed: 0m2s
2023-03-06 19:17:23.540084: Epoch: 17, Batch: 39, Loss: 0.4041, Elapsed: 0m3s
2023-03-06 19:17:27.184160: Epoch: 17, Batch: 40, Loss: 0.3950, Elapsed: 0m3s
2023-03-06 19:17:29.353831: Epoch: 17, Batch: 41, Loss: 0.3847, Elapsed: 0m2s
2023-03-06 19:17:31.531462: Epoch: 17, Batch: 42, Loss: 0.3710, Elapsed: 0m2s
2023-03-06 19:17:34.479285: Epoch: 17, Batch: 43, Loss: 0.3879, Elapsed: 0m2s
2023-03-06 19:17:37.540838: Epoch: 17, Batch: 44, Loss: 0.4039, Elapsed: 0m3s
2023-03-06 19:17:41.029366: Epoch: 17, Batch: 45, Loss: 0.4132, Elapsed: 0m3s
2023-03-06 19:17:46.632063: Epoch: 17, Batch: 46, Loss: 0.4170, Elapsed: 0m5s
2023-03-06 19:17:50.984915: Epoch: 17, Batch: 47, Loss: 0.4086, Elapsed: 0m4s
2023-03-06 19:17:55.285458: Epoch: 17, Batch: 48, Loss: 0.4127, Elapsed: 0m4s
2023-03-06 19:17:58.442681: Epoch: 17, Batch: 49, Loss: 0.3839, Elapsed: 0m3s
2023-03-06 19:18:00.646991: Epoch: 17, Batch: 50, Loss: 0.3820, Elapsed: 0m2s
2023-03-06 19:18:00.658055 Starting testing the valid set with 20 subgraphs!
2023-03-06 19:19:07.505453: validation Test:  Loss: 0.3971,  AUC: 0.8766, Acc: 79.4994,  Precision: 0.9359 -- Elapsed: 1m6s
2023-03-06 19:19:07.506642 Starting testing the train set with 20 subgraphs!
2023-03-06 19:23:31.078940: training Test:  Loss: 0.3962,  AUC: 0.8772, Acc: 79.5777,  Precision: 0.9363 -- Elapsed: 4m23s
2023-03-06 19:23:33.893317: Epoch: 17, Batch: 51, Loss: 0.3900, Elapsed: 0m2s
2023-03-06 19:23:38.441537: Epoch: 17, Batch: 52, Loss: 0.4090, Elapsed: 0m4s
2023-03-06 19:23:40.306563: Epoch: 17, Batch: 53, Loss: 0.3676, Elapsed: 0m1s
2023-03-06 19:23:43.139003: Epoch: 17, Batch: 54, Loss: 0.3900, Elapsed: 0m2s
2023-03-06 19:23:47.064309: Epoch: 17, Batch: 55, Loss: 0.4093, Elapsed: 0m3s
2023-03-06 19:23:49.588839: Epoch: 17, Batch: 56, Loss: 0.3771, Elapsed: 0m2s
2023-03-06 19:23:52.699277: Epoch: 17, Batch: 57, Loss: 0.3970, Elapsed: 0m3s
2023-03-06 19:23:55.105403: Epoch: 17, Batch: 58, Loss: 0.3869, Elapsed: 0m2s
2023-03-06 19:23:59.113726: Epoch: 17, Batch: 59, Loss: 0.4111, Elapsed: 0m3s
2023-03-06 19:24:01.268809: Epoch: 17, Batch: 60, Loss: 0.3740, Elapsed: 0m2s
2023-03-06 19:24:03.176785: Epoch: 17, Batch: 61, Loss: 0.3606, Elapsed: 0m1s
2023-03-06 19:24:05.678257: Epoch: 17, Batch: 62, Loss: 0.4028, Elapsed: 0m2s
2023-03-06 19:24:07.671325: Epoch: 17, Batch: 63, Loss: 0.3788, Elapsed: 0m1s
2023-03-06 19:24:10.180159: Epoch: 17, Batch: 64, Loss: 0.3839, Elapsed: 0m2s
2023-03-06 19:24:12.877068: Epoch: 17, Batch: 65, Loss: 0.4040, Elapsed: 0m2s
2023-03-06 19:24:14.739630: Epoch: 17, Batch: 66, Loss: 0.3767, Elapsed: 0m1s
2023-03-06 19:24:17.696618: Epoch: 17, Batch: 67, Loss: 0.3991, Elapsed: 0m2s
2023-03-06 19:24:20.541453: Epoch: 17, Batch: 68, Loss: 0.3878, Elapsed: 0m2s
2023-03-06 19:24:23.028092: Epoch: 17, Batch: 69, Loss: 0.3907, Elapsed: 0m2s
2023-03-06 19:24:25.033305: Epoch: 17, Batch: 70, Loss: 0.3862, Elapsed: 0m1s
2023-03-06 19:24:27.418995: Epoch: 17, Batch: 71, Loss: 0.3677, Elapsed: 0m2s
2023-03-06 19:24:29.071639: Epoch: 17, Batch: 72, Loss: 0.3627, Elapsed: 0m1s
2023-03-06 19:24:30.664699: Epoch: 17, Batch: 73, Loss: 0.3533, Elapsed: 0m1s
2023-03-06 19:24:33.648494: Epoch: 17, Batch: 74, Loss: 0.4013, Elapsed: 0m2s
2023-03-06 19:24:36.176123: Epoch: 17, Batch: 75, Loss: 0.3923, Elapsed: 0m2s
2023-03-06 19:24:38.633878: Epoch: 17, Batch: 76, Loss: 0.3867, Elapsed: 0m2s
2023-03-06 19:24:41.695066: Epoch: 17, Batch: 77, Loss: 0.3966, Elapsed: 0m3s
2023-03-06 19:24:45.371104: Epoch: 17, Batch: 78, Loss: 0.3997, Elapsed: 0m3s
2023-03-06 19:24:46.490351: Epoch: 17, Batch: 79, Loss: 0.3331, Elapsed: 0m1s
2023-03-06 19:24:50.312856: Epoch: 17, Batch: 80, Loss: 0.4145, Elapsed: 0m3s
2023-03-06 19:24:52.224250: Epoch: 18, Batch: 1, Loss: 0.3694, Elapsed: 0m1s
2023-03-06 19:24:54.776899: Epoch: 18, Batch: 2, Loss: 0.3913, Elapsed: 0m2s
2023-03-06 19:24:57.643141: Epoch: 18, Batch: 3, Loss: 0.3922, Elapsed: 0m2s
2023-03-06 19:25:01.971707: Epoch: 18, Batch: 4, Loss: 0.4247, Elapsed: 0m4s
2023-03-06 19:25:06.319347: Epoch: 18, Batch: 5, Loss: 0.4132, Elapsed: 0m4s
2023-03-06 19:25:08.934363: Epoch: 18, Batch: 6, Loss: 0.3928, Elapsed: 0m2s
2023-03-06 19:25:11.862258: Epoch: 18, Batch: 7, Loss: 0.3839, Elapsed: 0m2s
2023-03-06 19:25:13.846484: Epoch: 18, Batch: 8, Loss: 0.3872, Elapsed: 0m1s
2023-03-06 19:25:16.013667: Epoch: 18, Batch: 9, Loss: 0.3706, Elapsed: 0m2s
2023-03-06 19:25:20.146401: Epoch: 18, Batch: 10, Loss: 0.4093, Elapsed: 0m4s
2023-03-06 19:25:22.402393: Epoch: 18, Batch: 11, Loss: 0.3859, Elapsed: 0m2s
2023-03-06 19:25:24.913389: Epoch: 18, Batch: 12, Loss: 0.3792, Elapsed: 0m2s
2023-03-06 19:25:26.934571: Epoch: 18, Batch: 13, Loss: 0.3859, Elapsed: 0m2s
2023-03-06 19:25:29.077552: Epoch: 18, Batch: 14, Loss: 0.3749, Elapsed: 0m2s
2023-03-06 19:25:32.009790: Epoch: 18, Batch: 15, Loss: 0.3988, Elapsed: 0m2s
2023-03-06 19:25:36.531350: Epoch: 18, Batch: 16, Loss: 0.4151, Elapsed: 0m4s
2023-03-06 19:25:40.170122: Epoch: 18, Batch: 17, Loss: 0.3952, Elapsed: 0m3s
2023-03-06 19:25:42.632412: Epoch: 18, Batch: 18, Loss: 0.3869, Elapsed: 0m2s
2023-03-06 19:25:45.331543: Epoch: 18, Batch: 19, Loss: 0.3902, Elapsed: 0m2s
2023-03-06 19:25:47.908640: Epoch: 18, Batch: 20, Loss: 0.3835, Elapsed: 0m2s
2023-03-06 19:25:52.057545: Epoch: 18, Batch: 21, Loss: 0.4112, Elapsed: 0m4s
2023-03-06 19:25:55.518672: Epoch: 18, Batch: 22, Loss: 0.4069, Elapsed: 0m3s
2023-03-06 19:25:59.098832: Epoch: 18, Batch: 23, Loss: 0.4040, Elapsed: 0m3s
2023-03-06 19:26:03.108276: Epoch: 18, Batch: 24, Loss: 0.4154, Elapsed: 0m3s
2023-03-06 19:26:05.808542: Epoch: 18, Batch: 25, Loss: 0.4027, Elapsed: 0m2s
2023-03-06 19:26:08.277005: Epoch: 18, Batch: 26, Loss: 0.3907, Elapsed: 0m2s
2023-03-06 19:26:12.112867: Epoch: 18, Batch: 27, Loss: 0.4091, Elapsed: 0m3s
2023-03-06 19:26:14.488829: Epoch: 18, Batch: 28, Loss: 0.3678, Elapsed: 0m2s
2023-03-06 19:26:18.247865: Epoch: 18, Batch: 29, Loss: 0.4126, Elapsed: 0m3s
2023-03-06 19:26:21.829618: Epoch: 18, Batch: 30, Loss: 0.3989, Elapsed: 0m3s
2023-03-06 19:26:24.810056: Epoch: 18, Batch: 31, Loss: 0.3865, Elapsed: 0m2s
2023-03-06 19:26:26.730808: Epoch: 18, Batch: 32, Loss: 0.3761, Elapsed: 0m1s
2023-03-06 19:26:29.714586: Epoch: 18, Batch: 33, Loss: 0.4016, Elapsed: 0m2s
2023-03-06 19:26:31.323317: Epoch: 18, Batch: 34, Loss: 0.3628, Elapsed: 0m1s
2023-03-06 19:26:34.723364: Epoch: 18, Batch: 35, Loss: 0.4018, Elapsed: 0m3s
2023-03-06 19:26:37.214264: Epoch: 18, Batch: 36, Loss: 0.3904, Elapsed: 0m2s
2023-03-06 19:26:40.881902: Epoch: 18, Batch: 37, Loss: 0.4017, Elapsed: 0m3s
2023-03-06 19:26:44.062895: Epoch: 18, Batch: 38, Loss: 0.3837, Elapsed: 0m3s
2023-03-06 19:26:46.003246: Epoch: 18, Batch: 39, Loss: 0.3750, Elapsed: 0m1s
2023-03-06 19:26:48.001815: Epoch: 18, Batch: 40, Loss: 0.3790, Elapsed: 0m1s
2023-03-06 19:26:49.300543: Epoch: 18, Batch: 41, Loss: 0.3339, Elapsed: 0m1s
2023-03-06 19:26:51.818410: Epoch: 18, Batch: 42, Loss: 0.3880, Elapsed: 0m2s
2023-03-06 19:26:54.659286: Epoch: 18, Batch: 43, Loss: 0.3876, Elapsed: 0m2s
2023-03-06 19:26:56.373883: Epoch: 18, Batch: 44, Loss: 0.3736, Elapsed: 0m1s
2023-03-06 19:27:00.999434: Epoch: 18, Batch: 45, Loss: 0.4118, Elapsed: 0m4s
2023-03-06 19:27:04.696567: Epoch: 18, Batch: 46, Loss: 0.4048, Elapsed: 0m3s
2023-03-06 19:27:07.773981: Epoch: 18, Batch: 47, Loss: 0.3969, Elapsed: 0m3s
2023-03-06 19:27:09.433555: Epoch: 18, Batch: 48, Loss: 0.3530, Elapsed: 0m1s
2023-03-06 19:27:11.769238: Epoch: 18, Batch: 49, Loss: 0.3813, Elapsed: 0m2s
2023-03-06 19:27:14.576627: Epoch: 18, Batch: 50, Loss: 0.3887, Elapsed: 0m2s
2023-03-06 19:27:14.588408 Starting testing the valid set with 20 subgraphs!
2023-03-06 19:28:21.088393: validation Test:  Loss: 0.3959,  AUC: 0.8768, Acc: 79.4955,  Precision: 0.8573 -- Elapsed: 1m6s
2023-03-06 19:28:21.090037 Starting testing the train set with 20 subgraphs!
2023-03-06 19:32:45.770617: training Test:  Loss: 0.3951,  AUC: 0.8773, Acc: 79.5614,  Precision: 0.8584 -- Elapsed: 4m24s
2023-03-06 19:32:48.284628: Epoch: 18, Batch: 51, Loss: 0.3921, Elapsed: 0m2s
2023-03-06 19:32:51.243342: Epoch: 18, Batch: 52, Loss: 0.3871, Elapsed: 0m2s
2023-03-06 19:32:52.903961: Epoch: 18, Batch: 53, Loss: 0.3588, Elapsed: 0m1s
2023-03-06 19:32:55.373056: Epoch: 18, Batch: 54, Loss: 0.3818, Elapsed: 0m2s
2023-03-06 19:32:58.412576: Epoch: 18, Batch: 55, Loss: 0.4033, Elapsed: 0m3s
2023-03-06 19:33:03.290428: Epoch: 18, Batch: 56, Loss: 0.4104, Elapsed: 0m4s
2023-03-06 19:33:08.639688: Epoch: 18, Batch: 57, Loss: 0.4201, Elapsed: 0m5s
2023-03-06 19:33:12.081801: Epoch: 18, Batch: 58, Loss: 0.4055, Elapsed: 0m3s
2023-03-06 19:33:18.323492: Epoch: 18, Batch: 59, Loss: 0.4250, Elapsed: 0m6s
2023-03-06 19:33:23.496870: Epoch: 18, Batch: 60, Loss: 0.3869, Elapsed: 0m5s
2023-03-06 19:33:26.712768: Epoch: 18, Batch: 61, Loss: 0.3978, Elapsed: 0m3s
2023-03-06 19:33:29.597989: Epoch: 18, Batch: 62, Loss: 0.4043, Elapsed: 0m2s
2023-03-06 19:33:32.591332: Epoch: 18, Batch: 63, Loss: 0.3900, Elapsed: 0m2s
2023-03-06 19:33:37.303752: Epoch: 18, Batch: 64, Loss: 0.4100, Elapsed: 0m4s
2023-03-06 19:33:41.800618: Epoch: 18, Batch: 65, Loss: 0.4090, Elapsed: 0m4s
2023-03-06 19:33:42.821079: Epoch: 18, Batch: 66, Loss: 0.3332, Elapsed: 0m1s
2023-03-06 19:33:44.733041: Epoch: 18, Batch: 67, Loss: 0.3618, Elapsed: 0m1s
2023-03-06 19:33:47.715102: Epoch: 18, Batch: 68, Loss: 0.3977, Elapsed: 0m2s
2023-03-06 19:33:52.815217: Epoch: 18, Batch: 69, Loss: 0.4162, Elapsed: 0m5s
2023-03-06 19:33:55.234957: Epoch: 18, Batch: 70, Loss: 0.3852, Elapsed: 0m2s
2023-03-06 19:34:00.966294: Epoch: 18, Batch: 71, Loss: 0.4171, Elapsed: 0m5s
2023-03-06 19:34:03.126289: Epoch: 18, Batch: 72, Loss: 0.3868, Elapsed: 0m2s
2023-03-06 19:34:07.285397: Epoch: 18, Batch: 73, Loss: 0.4153, Elapsed: 0m4s
2023-03-06 19:34:11.397729: Epoch: 18, Batch: 74, Loss: 0.4115, Elapsed: 0m4s
2023-03-06 19:34:15.417226: Epoch: 18, Batch: 75, Loss: 0.4110, Elapsed: 0m4s
2023-03-06 19:34:18.480458: Epoch: 18, Batch: 76, Loss: 0.4043, Elapsed: 0m3s
2023-03-06 19:34:21.279229: Epoch: 18, Batch: 77, Loss: 0.3960, Elapsed: 0m2s
2023-03-06 19:34:24.546896: Epoch: 18, Batch: 78, Loss: 0.3954, Elapsed: 0m3s
2023-03-06 19:34:27.131194: Epoch: 18, Batch: 79, Loss: 0.3841, Elapsed: 0m2s
2023-03-06 19:34:28.967690: Epoch: 18, Batch: 80, Loss: 0.3678, Elapsed: 0m1s
2023-03-06 19:34:31.361145: Epoch: 19, Batch: 1, Loss: 0.3681, Elapsed: 0m2s
2023-03-06 19:34:33.850505: Epoch: 19, Batch: 2, Loss: 0.4027, Elapsed: 0m2s
2023-03-06 19:34:35.403993: Epoch: 19, Batch: 3, Loss: 0.3535, Elapsed: 0m1s
2023-03-06 19:34:38.892740: Epoch: 19, Batch: 4, Loss: 0.3991, Elapsed: 0m3s
2023-03-06 19:34:42.874262: Epoch: 19, Batch: 5, Loss: 0.4058, Elapsed: 0m3s
2023-03-06 19:34:46.046136: Epoch: 19, Batch: 6, Loss: 0.3861, Elapsed: 0m3s
2023-03-06 19:34:49.806534: Epoch: 19, Batch: 7, Loss: 0.4028, Elapsed: 0m3s
2023-03-06 19:34:50.818537: Epoch: 19, Batch: 8, Loss: 0.3333, Elapsed: 0m1s
2023-03-06 19:34:52.802135: Epoch: 19, Batch: 9, Loss: 0.3871, Elapsed: 0m1s
2023-03-06 19:34:55.815138: Epoch: 19, Batch: 10, Loss: 0.4031, Elapsed: 0m3s
2023-03-06 19:34:58.862911: Epoch: 19, Batch: 11, Loss: 0.4039, Elapsed: 0m3s
2023-03-06 19:35:01.003769: Epoch: 19, Batch: 12, Loss: 0.3736, Elapsed: 0m2s
2023-03-06 19:35:06.072294: Epoch: 19, Batch: 13, Loss: 0.4147, Elapsed: 0m5s
2023-03-06 19:35:08.330435: Epoch: 19, Batch: 14, Loss: 0.3867, Elapsed: 0m2s
2023-03-06 19:35:11.173660: Epoch: 19, Batch: 15, Loss: 0.3969, Elapsed: 0m2s
2023-03-06 19:35:13.848890: Epoch: 19, Batch: 16, Loss: 0.4036, Elapsed: 0m2s
2023-03-06 19:35:16.562374: Epoch: 19, Batch: 17, Loss: 0.3926, Elapsed: 0m2s
2023-03-06 19:35:20.960529: Epoch: 19, Batch: 18, Loss: 0.4082, Elapsed: 0m4s
2023-03-06 19:35:23.907399: Epoch: 19, Batch: 19, Loss: 0.4020, Elapsed: 0m2s
2023-03-06 19:35:26.403148: Epoch: 19, Batch: 20, Loss: 0.3768, Elapsed: 0m2s
2023-03-06 19:35:28.889998: Epoch: 19, Batch: 21, Loss: 0.3905, Elapsed: 0m2s
2023-03-06 19:35:33.477843: Epoch: 19, Batch: 22, Loss: 0.4126, Elapsed: 0m4s
2023-03-06 19:35:37.947695: Epoch: 19, Batch: 23, Loss: 0.4153, Elapsed: 0m4s
2023-03-06 19:35:41.379021: Epoch: 19, Batch: 24, Loss: 0.4062, Elapsed: 0m3s
2023-03-06 19:35:43.242684: Epoch: 19, Batch: 25, Loss: 0.3762, Elapsed: 0m1s
2023-03-06 19:35:46.045000: Epoch: 19, Batch: 26, Loss: 0.3937, Elapsed: 0m2s
2023-03-06 19:35:50.229655: Epoch: 19, Batch: 27, Loss: 0.4107, Elapsed: 0m4s
2023-03-06 19:35:51.826154: Epoch: 19, Batch: 28, Loss: 0.3632, Elapsed: 0m1s
2023-03-06 19:35:54.302522: Epoch: 19, Batch: 29, Loss: 0.3909, Elapsed: 0m2s
2023-03-06 19:35:59.872712: Epoch: 19, Batch: 30, Loss: 0.4175, Elapsed: 0m5s
2023-03-06 19:36:03.091217: Epoch: 19, Batch: 31, Loss: 0.3959, Elapsed: 0m3s
2023-03-06 19:36:04.907611: Epoch: 19, Batch: 32, Loss: 0.3690, Elapsed: 0m1s
2023-03-06 19:36:06.886202: Epoch: 19, Batch: 33, Loss: 0.3784, Elapsed: 0m1s
2023-03-06 19:36:11.935326: Epoch: 19, Batch: 34, Loss: 0.3865, Elapsed: 0m5s
2023-03-06 19:36:14.306183: Epoch: 19, Batch: 35, Loss: 0.3912, Elapsed: 0m2s
2023-03-06 19:36:15.988199: Epoch: 19, Batch: 36, Loss: 0.3761, Elapsed: 0m1s
2023-03-06 19:36:19.136926: Epoch: 19, Batch: 37, Loss: 0.3836, Elapsed: 0m3s
2023-03-06 19:36:20.878118: Epoch: 19, Batch: 38, Loss: 0.3610, Elapsed: 0m1s
2023-03-06 19:36:24.725133: Epoch: 19, Batch: 39, Loss: 0.4036, Elapsed: 0m3s
2023-03-06 19:36:29.193606: Epoch: 19, Batch: 40, Loss: 0.4161, Elapsed: 0m4s
2023-03-06 19:36:32.218764: Epoch: 19, Batch: 41, Loss: 0.3872, Elapsed: 0m3s
2023-03-06 19:36:38.440618: Epoch: 19, Batch: 42, Loss: 0.4255, Elapsed: 0m6s
2023-03-06 19:36:40.706006: Epoch: 19, Batch: 43, Loss: 0.3866, Elapsed: 0m2s
2023-03-06 19:36:42.871073: Epoch: 19, Batch: 44, Loss: 0.3705, Elapsed: 0m2s
2023-03-06 19:36:45.654346: Epoch: 19, Batch: 45, Loss: 0.3892, Elapsed: 0m2s
2023-03-06 19:36:50.344929: Epoch: 19, Batch: 46, Loss: 0.4127, Elapsed: 0m4s
2023-03-06 19:36:52.989481: Epoch: 19, Batch: 47, Loss: 0.3929, Elapsed: 0m2s
2023-03-06 19:36:54.993677: Epoch: 19, Batch: 48, Loss: 0.3606, Elapsed: 0m1s
2023-03-06 19:36:58.395791: Epoch: 19, Batch: 49, Loss: 0.4014, Elapsed: 0m3s
2023-03-06 19:37:02.189233: Epoch: 19, Batch: 50, Loss: 0.4094, Elapsed: 0m3s
2023-03-06 19:37:02.199151 Starting testing the valid set with 20 subgraphs!
2023-03-06 19:38:09.012662: validation Test:  Loss: 0.3959,  AUC: 0.8771, Acc: 79.5289,  Precision: 0.8974 -- Elapsed: 1m6s
2023-03-06 19:38:09.013835 Starting testing the train set with 20 subgraphs!
2023-03-06 19:42:31.935746: training Test:  Loss: 0.3950,  AUC: 0.8777, Acc: 79.5733,  Precision: 0.8976 -- Elapsed: 4m22s
2023-03-06 19:42:33.868374: Epoch: 19, Batch: 51, Loss: 0.3694, Elapsed: 0m1s
2023-03-06 19:42:35.893034: Epoch: 19, Batch: 52, Loss: 0.3869, Elapsed: 0m2s
2023-03-06 19:42:39.737976: Epoch: 19, Batch: 53, Loss: 0.4140, Elapsed: 0m3s
2023-03-06 19:42:42.259987: Epoch: 19, Batch: 54, Loss: 0.3886, Elapsed: 0m2s
2023-03-06 19:42:45.220462: Epoch: 19, Batch: 55, Loss: 0.3819, Elapsed: 0m2s
2023-03-06 19:42:48.041382: Epoch: 19, Batch: 56, Loss: 0.3956, Elapsed: 0m2s
2023-03-06 19:42:52.080846: Epoch: 19, Batch: 57, Loss: 0.4106, Elapsed: 0m4s
2023-03-06 19:42:56.174716: Epoch: 19, Batch: 58, Loss: 0.4242, Elapsed: 0m4s
2023-03-06 19:42:59.203209: Epoch: 19, Batch: 59, Loss: 0.3966, Elapsed: 0m3s
2023-03-06 19:43:04.094298: Epoch: 19, Batch: 60, Loss: 0.4106, Elapsed: 0m4s
2023-03-06 19:43:07.512370: Epoch: 19, Batch: 61, Loss: 0.3950, Elapsed: 0m3s
2023-03-06 19:43:10.025733: Epoch: 19, Batch: 62, Loss: 0.3832, Elapsed: 0m2s
2023-03-06 19:43:13.532205: Epoch: 19, Batch: 63, Loss: 0.4124, Elapsed: 0m3s
2023-03-06 19:43:16.003399: Epoch: 19, Batch: 64, Loss: 0.3835, Elapsed: 0m2s
2023-03-06 19:43:18.280255: Epoch: 19, Batch: 65, Loss: 0.3844, Elapsed: 0m2s
2023-03-06 19:43:21.024044: Epoch: 19, Batch: 66, Loss: 0.3912, Elapsed: 0m2s
2023-03-06 19:43:25.313366: Epoch: 19, Batch: 67, Loss: 0.4070, Elapsed: 0m4s
2023-03-06 19:43:28.310103: Epoch: 19, Batch: 68, Loss: 0.3966, Elapsed: 0m2s
2023-03-06 19:43:32.691407: Epoch: 19, Batch: 69, Loss: 0.4083, Elapsed: 0m4s
2023-03-06 19:43:38.046183: Epoch: 19, Batch: 70, Loss: 0.4196, Elapsed: 0m5s
2023-03-06 19:43:41.534628: Epoch: 19, Batch: 71, Loss: 0.4067, Elapsed: 0m3s
2023-03-06 19:43:44.360333: Epoch: 19, Batch: 72, Loss: 0.3888, Elapsed: 0m2s
2023-03-06 19:43:45.661436: Epoch: 19, Batch: 73, Loss: 0.3337, Elapsed: 0m1s
2023-03-06 19:43:48.280136: Epoch: 19, Batch: 74, Loss: 0.3832, Elapsed: 0m2s
2023-03-06 19:43:51.046242: Epoch: 19, Batch: 75, Loss: 0.3817, Elapsed: 0m2s
2023-03-06 19:43:53.211252: Epoch: 19, Batch: 76, Loss: 0.3745, Elapsed: 0m2s
2023-03-06 19:43:55.682272: Epoch: 19, Batch: 77, Loss: 0.3810, Elapsed: 0m2s
2023-03-06 19:44:00.000784: Epoch: 19, Batch: 78, Loss: 0.4100, Elapsed: 0m4s
2023-03-06 19:44:02.961172: Epoch: 19, Batch: 79, Loss: 0.3979, Elapsed: 0m2s
2023-03-06 19:44:05.825656: Epoch: 19, Batch: 80, Loss: 0.3878, Elapsed: 0m2s
2023-03-06 19:44:08.629108: Epoch: 20, Batch: 1, Loss: 0.3886, Elapsed: 0m2s
2023-03-06 19:44:11.105888: Epoch: 20, Batch: 2, Loss: 0.4023, Elapsed: 0m2s
2023-03-06 19:44:13.911874: Epoch: 20, Batch: 3, Loss: 0.3886, Elapsed: 0m2s
2023-03-06 19:44:18.055119: Epoch: 20, Batch: 4, Loss: 0.4106, Elapsed: 0m4s
2023-03-06 19:44:22.205635: Epoch: 20, Batch: 5, Loss: 0.4066, Elapsed: 0m4s
2023-03-06 19:44:23.928685: Epoch: 20, Batch: 6, Loss: 0.3622, Elapsed: 0m1s
2023-03-06 19:44:26.335823: Epoch: 20, Batch: 7, Loss: 0.3861, Elapsed: 0m2s
2023-03-06 19:44:29.346650: Epoch: 20, Batch: 8, Loss: 0.3962, Elapsed: 0m3s
2023-03-06 19:44:33.469606: Epoch: 20, Batch: 9, Loss: 0.4145, Elapsed: 0m4s
2023-03-06 19:44:35.874533: Epoch: 20, Batch: 10, Loss: 0.3891, Elapsed: 0m2s
2023-03-06 19:44:38.411843: Epoch: 20, Batch: 11, Loss: 0.3830, Elapsed: 0m2s
2023-03-06 19:44:40.819581: Epoch: 20, Batch: 12, Loss: 0.3830, Elapsed: 0m2s
2023-03-06 19:44:45.428479: Epoch: 20, Batch: 13, Loss: 0.4112, Elapsed: 0m4s
2023-03-06 19:44:46.445603: Epoch: 20, Batch: 14, Loss: 0.3325, Elapsed: 0m1s
2023-03-06 19:44:48.433804: Epoch: 20, Batch: 15, Loss: 0.3782, Elapsed: 0m1s
2023-03-06 19:44:50.615661: Epoch: 20, Batch: 16, Loss: 0.3700, Elapsed: 0m2s
2023-03-06 19:44:53.774304: Epoch: 20, Batch: 17, Loss: 0.3832, Elapsed: 0m3s
2023-03-06 19:44:57.885330: Epoch: 20, Batch: 18, Loss: 0.4095, Elapsed: 0m4s
2023-03-06 19:45:03.242503: Epoch: 20, Batch: 19, Loss: 0.4143, Elapsed: 0m5s
2023-03-06 19:45:06.948784: Epoch: 20, Batch: 20, Loss: 0.4046, Elapsed: 0m3s
2023-03-06 19:45:11.558027: Epoch: 20, Batch: 21, Loss: 0.4139, Elapsed: 0m4s
2023-03-06 19:45:16.639141: Epoch: 20, Batch: 22, Loss: 0.3844, Elapsed: 0m5s
2023-03-06 19:45:18.659020: Epoch: 20, Batch: 23, Loss: 0.3860, Elapsed: 0m2s
2023-03-06 19:45:21.619975: Epoch: 20, Batch: 24, Loss: 0.4013, Elapsed: 0m2s
2023-03-06 19:45:23.553709: Epoch: 20, Batch: 25, Loss: 0.3591, Elapsed: 0m1s
2023-03-06 19:45:25.777256: Epoch: 20, Batch: 26, Loss: 0.3824, Elapsed: 0m2s
2023-03-06 19:45:30.304466: Epoch: 20, Batch: 27, Loss: 0.4134, Elapsed: 0m4s
2023-03-06 19:45:34.892732: Epoch: 20, Batch: 28, Loss: 0.4079, Elapsed: 0m4s
2023-03-06 19:45:37.844572: Epoch: 20, Batch: 29, Loss: 0.3823, Elapsed: 0m2s
2023-03-06 19:45:41.339253: Epoch: 20, Batch: 30, Loss: 0.4117, Elapsed: 0m3s
2023-03-06 19:45:45.353118: Epoch: 20, Batch: 31, Loss: 0.4108, Elapsed: 0m4s
2023-03-06 19:45:48.211427: Epoch: 20, Batch: 32, Loss: 0.3964, Elapsed: 0m2s
2023-03-06 19:45:53.827395: Epoch: 20, Batch: 33, Loss: 0.4168, Elapsed: 0m5s
2023-03-06 19:45:57.073871: Epoch: 20, Batch: 34, Loss: 0.3950, Elapsed: 0m3s
2023-03-06 19:46:00.103747: Epoch: 20, Batch: 35, Loss: 0.4029, Elapsed: 0m3s
2023-03-06 19:46:02.904577: Epoch: 20, Batch: 36, Loss: 0.3953, Elapsed: 0m2s
2023-03-06 19:46:04.209913: Epoch: 20, Batch: 37, Loss: 0.3331, Elapsed: 0m1s
2023-03-06 19:46:06.717785: Epoch: 20, Batch: 38, Loss: 0.3895, Elapsed: 0m2s
2023-03-06 19:46:10.121932: Epoch: 20, Batch: 39, Loss: 0.4020, Elapsed: 0m3s
2023-03-06 19:46:13.077010: Epoch: 20, Batch: 40, Loss: 0.3981, Elapsed: 0m2s
2023-03-06 19:46:15.709152: Epoch: 20, Batch: 41, Loss: 0.3927, Elapsed: 0m2s
2023-03-06 19:46:17.576284: Epoch: 20, Batch: 42, Loss: 0.3754, Elapsed: 0m1s
2023-03-06 19:46:19.857513: Epoch: 20, Batch: 43, Loss: 0.3859, Elapsed: 0m2s
2023-03-06 19:46:23.221346: Epoch: 20, Batch: 44, Loss: 0.3987, Elapsed: 0m3s
2023-03-06 19:46:29.466136: Epoch: 20, Batch: 45, Loss: 0.4252, Elapsed: 0m6s
2023-03-06 19:46:31.163683: Epoch: 20, Batch: 46, Loss: 0.3732, Elapsed: 0m1s
2023-03-06 19:46:33.809656: Epoch: 20, Batch: 47, Loss: 0.3921, Elapsed: 0m2s
2023-03-06 19:46:35.765838: Epoch: 20, Batch: 48, Loss: 0.3668, Elapsed: 0m1s
2023-03-06 19:46:39.669423: Epoch: 20, Batch: 49, Loss: 0.4083, Elapsed: 0m3s
2023-03-06 19:46:41.202812: Epoch: 20, Batch: 50, Loss: 0.3523, Elapsed: 0m1s
2023-03-06 19:46:41.213521 Starting testing the valid set with 20 subgraphs!
2023-03-06 19:47:48.086959: validation Test:  Loss: 0.3954,  AUC: 0.8769, Acc: 79.4716,  Precision: 0.8699 -- Elapsed: 1m6s
2023-03-06 19:47:48.088080 Starting testing the train set with 20 subgraphs!
2023-03-06 19:52:10.341374: training Test:  Loss: 0.3946,  AUC: 0.8774, Acc: 79.5625,  Precision: 0.8716 -- Elapsed: 4m22s
2023-03-06 19:52:12.715151: Epoch: 20, Batch: 51, Loss: 0.3669, Elapsed: 0m2s
2023-03-06 19:52:14.867163: Epoch: 20, Batch: 52, Loss: 0.3725, Elapsed: 0m2s
2023-03-06 19:52:17.824952: Epoch: 20, Batch: 53, Loss: 0.3868, Elapsed: 0m2s
2023-03-06 19:52:21.478182: Epoch: 20, Batch: 54, Loss: 0.4009, Elapsed: 0m3s
2023-03-06 19:52:24.321749: Epoch: 20, Batch: 55, Loss: 0.3871, Elapsed: 0m2s
2023-03-06 19:52:28.434526: Epoch: 20, Batch: 56, Loss: 0.4232, Elapsed: 0m4s
2023-03-06 19:52:31.981097: Epoch: 20, Batch: 57, Loss: 0.4059, Elapsed: 0m3s
2023-03-06 19:52:34.512387: Epoch: 20, Batch: 58, Loss: 0.3813, Elapsed: 0m2s
2023-03-06 19:52:38.966357: Epoch: 20, Batch: 59, Loss: 0.4077, Elapsed: 0m4s
2023-03-06 19:52:42.696241: Epoch: 20, Batch: 60, Loss: 0.4031, Elapsed: 0m3s
2023-03-06 19:52:45.904858: Epoch: 20, Batch: 61, Loss: 0.4030, Elapsed: 0m3s
2023-03-06 19:52:49.795381: Epoch: 20, Batch: 62, Loss: 0.4044, Elapsed: 0m3s
2023-03-06 19:52:51.798703: Epoch: 20, Batch: 63, Loss: 0.3687, Elapsed: 0m1s
2023-03-06 19:52:53.730001: Epoch: 20, Batch: 64, Loss: 0.3738, Elapsed: 0m1s
2023-03-06 19:52:58.602140: Epoch: 20, Batch: 65, Loss: 0.4099, Elapsed: 0m4s
2023-03-06 19:53:00.314800: Epoch: 20, Batch: 66, Loss: 0.3586, Elapsed: 0m1s
2023-03-06 19:53:03.222576: Epoch: 20, Batch: 67, Loss: 0.3909, Elapsed: 0m2s
2023-03-06 19:53:06.387488: Epoch: 20, Batch: 68, Loss: 0.3958, Elapsed: 0m3s
2023-03-06 19:53:08.422976: Epoch: 20, Batch: 69, Loss: 0.3859, Elapsed: 0m2s
2023-03-06 19:53:10.927878: Epoch: 20, Batch: 70, Loss: 0.3878, Elapsed: 0m2s
2023-03-06 19:53:13.101925: Epoch: 20, Batch: 71, Loss: 0.3836, Elapsed: 0m2s
2023-03-06 19:53:18.454262: Epoch: 20, Batch: 72, Loss: 0.4196, Elapsed: 0m5s
2023-03-06 19:53:22.283906: Epoch: 20, Batch: 73, Loss: 0.4135, Elapsed: 0m3s
2023-03-06 19:53:24.863182: Epoch: 20, Batch: 74, Loss: 0.3905, Elapsed: 0m2s
2023-03-06 19:53:28.315062: Epoch: 20, Batch: 75, Loss: 0.3940, Elapsed: 0m3s
2023-03-06 19:53:31.262436: Epoch: 20, Batch: 76, Loss: 0.3857, Elapsed: 0m2s
2023-03-06 19:53:33.762583: Epoch: 20, Batch: 77, Loss: 0.3829, Elapsed: 0m2s
2023-03-06 19:53:36.278534: Epoch: 20, Batch: 78, Loss: 0.3764, Elapsed: 0m2s
2023-03-06 19:53:38.760567: Epoch: 20, Batch: 79, Loss: 0.3897, Elapsed: 0m2s
2023-03-06 19:53:41.450989: Epoch: 20, Batch: 80, Loss: 0.4025, Elapsed: 0m2s
2023-03-06 19:53:45.274931: Epoch: 21, Batch: 1, Loss: 0.4134, Elapsed: 0m3s
2023-03-06 19:53:48.093656: Epoch: 21, Batch: 2, Loss: 0.3946, Elapsed: 0m2s
2023-03-06 19:53:52.251784: Epoch: 21, Batch: 3, Loss: 0.4064, Elapsed: 0m4s
2023-03-06 19:53:54.742775: Epoch: 21, Batch: 4, Loss: 0.3896, Elapsed: 0m2s
2023-03-06 19:53:57.251115: Epoch: 21, Batch: 5, Loss: 0.3878, Elapsed: 0m2s
2023-03-06 19:54:00.082457: Epoch: 21, Batch: 6, Loss: 0.3882, Elapsed: 0m2s
2023-03-06 19:54:01.788202: Epoch: 21, Batch: 7, Loss: 0.3582, Elapsed: 0m1s
2023-03-06 19:54:04.913151: Epoch: 21, Batch: 8, Loss: 0.3813, Elapsed: 0m3s
2023-03-06 19:54:07.703297: Epoch: 21, Batch: 9, Loss: 0.3824, Elapsed: 0m2s
2023-03-06 19:54:09.854256: Epoch: 21, Batch: 10, Loss: 0.3736, Elapsed: 0m2s
2023-03-06 19:54:12.509196: Epoch: 21, Batch: 11, Loss: 0.3828, Elapsed: 0m2s
2023-03-06 19:54:15.098927: Epoch: 21, Batch: 12, Loss: 0.3906, Elapsed: 0m2s
2023-03-06 19:54:18.730911: Epoch: 21, Batch: 13, Loss: 0.4042, Elapsed: 0m3s
2023-03-06 19:54:22.809801: Epoch: 21, Batch: 14, Loss: 0.4090, Elapsed: 0m4s
2023-03-06 19:54:24.785029: Epoch: 21, Batch: 15, Loss: 0.3777, Elapsed: 0m1s
2023-03-06 19:54:27.046014: Epoch: 21, Batch: 16, Loss: 0.3855, Elapsed: 0m2s
2023-03-06 19:54:28.059761: Epoch: 21, Batch: 17, Loss: 0.3330, Elapsed: 0m1s
2023-03-06 19:54:31.054859: Epoch: 21, Batch: 18, Loss: 0.3959, Elapsed: 0m2s
2023-03-06 19:54:32.965091: Epoch: 21, Batch: 19, Loss: 0.3686, Elapsed: 0m1s
2023-03-06 19:54:37.015410: Epoch: 21, Batch: 20, Loss: 0.4228, Elapsed: 0m4s
2023-03-06 19:54:39.501187: Epoch: 21, Batch: 21, Loss: 0.3914, Elapsed: 0m2s
2023-03-06 19:54:43.782972: Epoch: 21, Batch: 22, Loss: 0.4118, Elapsed: 0m4s
2023-03-06 19:54:45.972949: Epoch: 21, Batch: 23, Loss: 0.3809, Elapsed: 0m2s
2023-03-06 19:54:51.552867: Epoch: 21, Batch: 24, Loss: 0.4161, Elapsed: 0m5s
2023-03-06 19:54:53.924684: Epoch: 21, Batch: 25, Loss: 0.3889, Elapsed: 0m2s
2023-03-06 19:54:58.506460: Epoch: 21, Batch: 26, Loss: 0.4108, Elapsed: 0m4s
2023-03-06 19:55:02.629566: Epoch: 21, Batch: 27, Loss: 0.4095, Elapsed: 0m4s
2023-03-06 19:55:05.496964: Epoch: 21, Batch: 28, Loss: 0.3963, Elapsed: 0m2s
2023-03-06 19:55:09.789247: Epoch: 21, Batch: 29, Loss: 0.4138, Elapsed: 0m4s
2023-03-06 19:55:12.067842: Epoch: 21, Batch: 30, Loss: 0.3722, Elapsed: 0m2s
2023-03-06 19:55:15.176100: Epoch: 21, Batch: 31, Loss: 0.3960, Elapsed: 0m3s
2023-03-06 19:55:17.962853: Epoch: 21, Batch: 32, Loss: 0.3884, Elapsed: 0m2s
2023-03-06 19:55:20.329474: Epoch: 21, Batch: 33, Loss: 0.3665, Elapsed: 0m2s
2023-03-06 19:55:23.368917: Epoch: 21, Batch: 34, Loss: 0.4029, Elapsed: 0m3s
2023-03-06 19:55:25.348482: Epoch: 21, Batch: 35, Loss: 0.3854, Elapsed: 0m1s
2023-03-06 19:55:28.175503: Epoch: 21, Batch: 36, Loss: 0.3867, Elapsed: 0m2s
2023-03-06 19:55:31.617560: Epoch: 21, Batch: 37, Loss: 0.4056, Elapsed: 0m3s
2023-03-06 19:55:33.270637: Epoch: 21, Batch: 38, Loss: 0.3621, Elapsed: 0m1s
2023-03-06 19:55:36.297110: Epoch: 21, Batch: 39, Loss: 0.4022, Elapsed: 0m3s
2023-03-06 19:55:42.643677: Epoch: 21, Batch: 40, Loss: 0.4243, Elapsed: 0m6s
2023-03-06 19:55:44.834099: Epoch: 21, Batch: 41, Loss: 0.3850, Elapsed: 0m2s
2023-03-06 19:55:48.724328: Epoch: 21, Batch: 42, Loss: 0.4035, Elapsed: 0m3s
2023-03-06 19:55:51.592602: Epoch: 21, Batch: 43, Loss: 0.4024, Elapsed: 0m2s
2023-03-06 19:55:55.225483: Epoch: 21, Batch: 44, Loss: 0.4011, Elapsed: 0m3s
2023-03-06 19:55:58.609157: Epoch: 21, Batch: 45, Loss: 0.4016, Elapsed: 0m3s
2023-03-06 19:56:01.524960: Epoch: 21, Batch: 46, Loss: 0.3855, Elapsed: 0m2s
2023-03-06 19:56:06.580538: Epoch: 21, Batch: 47, Loss: 0.3866, Elapsed: 0m5s
2023-03-06 19:56:09.518566: Epoch: 21, Batch: 48, Loss: 0.3862, Elapsed: 0m2s
2023-03-06 19:56:11.675102: Epoch: 21, Batch: 49, Loss: 0.3847, Elapsed: 0m2s
2023-03-06 19:56:17.279013: Epoch: 21, Batch: 50, Loss: 0.4213, Elapsed: 0m5s
2023-03-06 19:56:17.290526 Starting testing the valid set with 20 subgraphs!
2023-03-06 19:57:24.049666: validation Test:  Loss: 0.3964,  AUC: 0.8766, Acc: 79.4977,  Precision: 0.9291 -- Elapsed: 1m6s
2023-03-06 19:57:24.050890 Starting testing the train set with 20 subgraphs!
2023-03-06 20:01:46.777859: training Test:  Loss: 0.3956,  AUC: 0.8771, Acc: 79.5666,  Precision: 0.9289 -- Elapsed: 4m22s
2023-03-06 20:01:49.072505: Epoch: 21, Batch: 51, Loss: 0.3868, Elapsed: 0m2s
2023-03-06 20:01:50.987651: Epoch: 21, Batch: 52, Loss: 0.3590, Elapsed: 0m1s
2023-03-06 20:01:52.539289: Epoch: 21, Batch: 53, Loss: 0.3528, Elapsed: 0m1s
2023-03-06 20:01:55.633997: Epoch: 21, Batch: 54, Loss: 0.3976, Elapsed: 0m3s
2023-03-06 20:01:58.349741: Epoch: 21, Batch: 55, Loss: 0.4021, Elapsed: 0m2s
2023-03-06 20:02:01.338174: Epoch: 21, Batch: 56, Loss: 0.3914, Elapsed: 0m2s
2023-03-06 20:02:04.883694: Epoch: 21, Batch: 57, Loss: 0.3944, Elapsed: 0m3s
2023-03-06 20:02:09.327995: Epoch: 21, Batch: 58, Loss: 0.4076, Elapsed: 0m4s
2023-03-06 20:02:13.829653: Epoch: 21, Batch: 59, Loss: 0.4132, Elapsed: 0m4s
2023-03-06 20:02:15.135037: Epoch: 21, Batch: 60, Loss: 0.3328, Elapsed: 0m1s
2023-03-06 20:02:17.654684: Epoch: 21, Batch: 61, Loss: 0.3761, Elapsed: 0m2s
2023-03-06 20:02:19.498439: Epoch: 21, Batch: 62, Loss: 0.3671, Elapsed: 0m1s
2023-03-06 20:02:22.079925: Epoch: 21, Batch: 63, Loss: 0.3891, Elapsed: 0m2s
2023-03-06 20:02:25.936906: Epoch: 21, Batch: 64, Loss: 0.4081, Elapsed: 0m3s
2023-03-06 20:02:28.579193: Epoch: 21, Batch: 65, Loss: 0.3923, Elapsed: 0m2s
2023-03-06 20:02:30.281858: Epoch: 21, Batch: 66, Loss: 0.3726, Elapsed: 0m1s
2023-03-06 20:02:35.454638: Epoch: 21, Batch: 67, Loss: 0.4144, Elapsed: 0m5s
2023-03-06 20:02:38.523457: Epoch: 21, Batch: 68, Loss: 0.4005, Elapsed: 0m3s
2023-03-06 20:02:40.839276: Epoch: 21, Batch: 69, Loss: 0.3698, Elapsed: 0m2s
2023-03-06 20:02:43.452320: Epoch: 21, Batch: 70, Loss: 0.3811, Elapsed: 0m2s
2023-03-06 20:02:47.119373: Epoch: 21, Batch: 71, Loss: 0.3943, Elapsed: 0m3s
2023-03-06 20:02:50.933775: Epoch: 21, Batch: 72, Loss: 0.4115, Elapsed: 0m3s
2023-03-06 20:02:54.612485: Epoch: 21, Batch: 73, Loss: 0.4047, Elapsed: 0m3s
2023-03-06 20:02:59.098373: Epoch: 21, Batch: 74, Loss: 0.4084, Elapsed: 0m4s
2023-03-06 20:03:02.472543: Epoch: 21, Batch: 75, Loss: 0.3986, Elapsed: 0m3s
2023-03-06 20:03:06.502938: Epoch: 21, Batch: 76, Loss: 0.4116, Elapsed: 0m4s
2023-03-06 20:03:09.040148: Epoch: 21, Batch: 77, Loss: 0.3823, Elapsed: 0m2s
2023-03-06 20:03:14.015675: Epoch: 21, Batch: 78, Loss: 0.4106, Elapsed: 0m4s
2023-03-06 20:03:15.933584: Epoch: 21, Batch: 79, Loss: 0.3751, Elapsed: 0m1s
2023-03-06 20:03:19.153736: Epoch: 21, Batch: 80, Loss: 0.3833, Elapsed: 0m3s
2023-03-06 20:03:21.698285: Epoch: 22, Batch: 1, Loss: 0.3825, Elapsed: 0m2s
2023-03-06 20:03:24.262811: Epoch: 22, Batch: 2, Loss: 0.3869, Elapsed: 0m2s
2023-03-06 20:03:26.289714: Epoch: 22, Batch: 3, Loss: 0.3848, Elapsed: 0m2s
2023-03-06 20:03:28.900566: Epoch: 22, Batch: 4, Loss: 0.3906, Elapsed: 0m2s
2023-03-06 20:03:30.443430: Epoch: 22, Batch: 5, Loss: 0.3524, Elapsed: 0m1s
2023-03-06 20:03:32.449766: Epoch: 22, Batch: 6, Loss: 0.3853, Elapsed: 0m1s
2023-03-06 20:03:34.953787: Epoch: 22, Batch: 7, Loss: 0.4018, Elapsed: 0m2s
2023-03-06 20:03:39.413279: Epoch: 22, Batch: 8, Loss: 0.4077, Elapsed: 0m4s
2023-03-06 20:03:42.835882: Epoch: 22, Batch: 9, Loss: 0.3935, Elapsed: 0m3s
2023-03-06 20:03:47.223970: Epoch: 22, Batch: 10, Loss: 0.4101, Elapsed: 0m4s
2023-03-06 20:03:51.234423: Epoch: 22, Batch: 11, Loss: 0.4081, Elapsed: 0m4s
2023-03-06 20:03:55.872902: Epoch: 22, Batch: 12, Loss: 0.4112, Elapsed: 0m4s
2023-03-06 20:04:00.178655: Epoch: 22, Batch: 13, Loss: 0.4126, Elapsed: 0m4s
2023-03-06 20:04:04.663243: Epoch: 22, Batch: 14, Loss: 0.4130, Elapsed: 0m4s
2023-03-06 20:04:10.890616: Epoch: 22, Batch: 15, Loss: 0.4246, Elapsed: 0m6s
2023-03-06 20:04:13.381816: Epoch: 22, Batch: 16, Loss: 0.3884, Elapsed: 0m2s
2023-03-06 20:04:16.309355: Epoch: 22, Batch: 17, Loss: 0.3812, Elapsed: 0m2s
2023-03-06 20:04:19.128707: Epoch: 22, Batch: 18, Loss: 0.3881, Elapsed: 0m2s
2023-03-06 20:04:22.103367: Epoch: 22, Batch: 19, Loss: 0.3956, Elapsed: 0m2s
2023-03-06 20:04:25.906601: Epoch: 22, Batch: 20, Loss: 0.4133, Elapsed: 0m3s
2023-03-06 20:04:28.400110: Epoch: 22, Batch: 21, Loss: 0.3824, Elapsed: 0m2s
2023-03-06 20:04:30.880510: Epoch: 22, Batch: 22, Loss: 0.3896, Elapsed: 0m2s
2023-03-06 20:04:33.037994: Epoch: 22, Batch: 23, Loss: 0.3833, Elapsed: 0m2s
2023-03-06 20:04:34.638745: Epoch: 22, Batch: 24, Loss: 0.3615, Elapsed: 0m1s
2023-03-06 20:04:36.462657: Epoch: 22, Batch: 25, Loss: 0.3663, Elapsed: 0m1s
2023-03-06 20:04:39.684183: Epoch: 22, Batch: 26, Loss: 0.3939, Elapsed: 0m3s
2023-03-06 20:04:43.812219: Epoch: 22, Batch: 27, Loss: 0.4061, Elapsed: 0m4s
2023-03-06 20:04:46.487584: Epoch: 22, Batch: 28, Loss: 0.4022, Elapsed: 0m2s
2023-03-06 20:04:50.815707: Epoch: 22, Batch: 29, Loss: 0.4137, Elapsed: 0m4s
2023-03-06 20:04:51.882442: Epoch: 22, Batch: 30, Loss: 0.3322, Elapsed: 0m1s
2023-03-06 20:04:55.690632: Epoch: 22, Batch: 31, Loss: 0.4004, Elapsed: 0m3s
2023-03-06 20:05:00.015047: Epoch: 22, Batch: 32, Loss: 0.4075, Elapsed: 0m4s
2023-03-06 20:05:02.968876: Epoch: 22, Batch: 33, Loss: 0.3972, Elapsed: 0m2s
2023-03-06 20:05:07.060582: Epoch: 22, Batch: 34, Loss: 0.4096, Elapsed: 0m4s
2023-03-06 20:05:09.071499: Epoch: 22, Batch: 35, Loss: 0.3586, Elapsed: 0m2s
2023-03-06 20:05:13.478916: Epoch: 22, Batch: 36, Loss: 0.4094, Elapsed: 0m4s
2023-03-06 20:05:18.676437: Epoch: 22, Batch: 37, Loss: 0.4138, Elapsed: 0m5s
2023-03-06 20:05:22.150461: Epoch: 22, Batch: 38, Loss: 0.4114, Elapsed: 0m3s
2023-03-06 20:05:25.584266: Epoch: 22, Batch: 39, Loss: 0.4056, Elapsed: 0m3s
2023-03-06 20:05:31.169834: Epoch: 22, Batch: 40, Loss: 0.4153, Elapsed: 0m5s
2023-03-06 20:05:33.956318: Epoch: 22, Batch: 41, Loss: 0.3943, Elapsed: 0m2s
2023-03-06 20:05:36.356464: Epoch: 22, Batch: 42, Loss: 0.3827, Elapsed: 0m2s
2023-03-06 20:05:40.530486: Epoch: 22, Batch: 43, Loss: 0.4227, Elapsed: 0m4s
2023-03-06 20:05:44.218233: Epoch: 22, Batch: 44, Loss: 0.4009, Elapsed: 0m3s
2023-03-06 20:05:47.504074: Epoch: 22, Batch: 45, Loss: 0.4018, Elapsed: 0m3s
2023-03-06 20:05:49.824632: Epoch: 22, Batch: 46, Loss: 0.3802, Elapsed: 0m2s
2023-03-06 20:05:52.133402: Epoch: 22, Batch: 47, Loss: 0.3856, Elapsed: 0m2s
2023-03-06 20:05:55.261549: Epoch: 22, Batch: 48, Loss: 0.4001, Elapsed: 0m3s
2023-03-06 20:05:58.241568: Epoch: 22, Batch: 49, Loss: 0.3864, Elapsed: 0m2s
2023-03-06 20:06:01.091148: Epoch: 22, Batch: 50, Loss: 0.3883, Elapsed: 0m2s
2023-03-06 20:06:01.100731 Starting testing the valid set with 20 subgraphs!
2023-03-06 20:07:07.242257: validation Test:  Loss: 0.3951,  AUC: 0.8773, Acc: 79.4722,  Precision: 0.8394 -- Elapsed: 1m6s
2023-03-06 20:07:07.243422 Starting testing the train set with 20 subgraphs!
2023-03-06 20:11:30.512539: training Test:  Loss: 0.3943,  AUC: 0.8777, Acc: 79.5753,  Precision: 0.8410 -- Elapsed: 4m23s
2023-03-06 20:11:34.412216: Epoch: 22, Batch: 51, Loss: 0.4028, Elapsed: 0m3s
2023-03-06 20:11:37.600255: Epoch: 22, Batch: 52, Loss: 0.4026, Elapsed: 0m3s
2023-03-06 20:11:40.769227: Epoch: 22, Batch: 53, Loss: 0.3828, Elapsed: 0m3s
2023-03-06 20:11:43.315461: Epoch: 22, Batch: 54, Loss: 0.3758, Elapsed: 0m2s
2023-03-06 20:11:46.761740: Epoch: 22, Batch: 55, Loss: 0.4039, Elapsed: 0m3s
2023-03-06 20:11:49.722133: Epoch: 22, Batch: 56, Loss: 0.3864, Elapsed: 0m2s
2023-03-06 20:11:51.996952: Epoch: 22, Batch: 57, Loss: 0.3853, Elapsed: 0m2s
2023-03-06 20:11:55.361649: Epoch: 22, Batch: 58, Loss: 0.3978, Elapsed: 0m3s
2023-03-06 20:11:57.522222: Epoch: 22, Batch: 59, Loss: 0.3718, Elapsed: 0m2s
2023-03-06 20:12:01.179495: Epoch: 22, Batch: 60, Loss: 0.4041, Elapsed: 0m3s
2023-03-06 20:12:03.107603: Epoch: 22, Batch: 61, Loss: 0.3682, Elapsed: 0m1s
2023-03-06 20:12:05.099422: Epoch: 22, Batch: 62, Loss: 0.3780, Elapsed: 0m1s
2023-03-06 20:12:07.299949: Epoch: 22, Batch: 63, Loss: 0.3691, Elapsed: 0m2s
2023-03-06 20:12:09.236286: Epoch: 22, Batch: 64, Loss: 0.3731, Elapsed: 0m1s
2023-03-06 20:12:11.711914: Epoch: 22, Batch: 65, Loss: 0.3808, Elapsed: 0m2s
2023-03-06 20:12:14.098402: Epoch: 22, Batch: 66, Loss: 0.3889, Elapsed: 0m2s
2023-03-06 20:12:16.656725: Epoch: 22, Batch: 67, Loss: 0.3913, Elapsed: 0m2s
2023-03-06 20:12:21.753399: Epoch: 22, Batch: 68, Loss: 0.4099, Elapsed: 0m5s
2023-03-06 20:12:27.200771: Epoch: 22, Batch: 69, Loss: 0.3872, Elapsed: 0m5s
2023-03-06 20:12:29.829046: Epoch: 22, Batch: 70, Loss: 0.3930, Elapsed: 0m2s
2023-03-06 20:12:31.708180: Epoch: 22, Batch: 71, Loss: 0.3788, Elapsed: 0m1s
2023-03-06 20:12:34.120138: Epoch: 22, Batch: 72, Loss: 0.3697, Elapsed: 0m2s
2023-03-06 20:12:35.783360: Epoch: 22, Batch: 73, Loss: 0.3612, Elapsed: 0m1s
2023-03-06 20:12:38.801274: Epoch: 22, Batch: 74, Loss: 0.4004, Elapsed: 0m3s
2023-03-06 20:12:40.104643: Epoch: 22, Batch: 75, Loss: 0.3336, Elapsed: 0m1s
2023-03-06 20:12:41.844705: Epoch: 22, Batch: 76, Loss: 0.3755, Elapsed: 0m1s
2023-03-06 20:12:44.715035: Epoch: 22, Batch: 77, Loss: 0.3998, Elapsed: 0m2s
2023-03-06 20:12:50.064311: Epoch: 22, Batch: 78, Loss: 0.4208, Elapsed: 0m5s
2023-03-06 20:12:53.017626: Epoch: 22, Batch: 79, Loss: 0.3874, Elapsed: 0m2s
2023-03-06 20:12:55.755102: Epoch: 22, Batch: 80, Loss: 0.3926, Elapsed: 0m2s
2023-03-06 20:12:58.137754: Epoch: 23, Batch: 1, Loss: 0.3676, Elapsed: 0m2s
2023-03-06 20:13:00.329528: Epoch: 23, Batch: 2, Loss: 0.3725, Elapsed: 0m2s
2023-03-06 20:13:05.668700: Epoch: 23, Batch: 3, Loss: 0.4200, Elapsed: 0m5s
2023-03-06 20:13:07.879526: Epoch: 23, Batch: 4, Loss: 0.3825, Elapsed: 0m2s
2023-03-06 20:13:10.261851: Epoch: 23, Batch: 5, Loss: 0.3889, Elapsed: 0m2s
2023-03-06 20:13:13.247845: Epoch: 23, Batch: 6, Loss: 0.3968, Elapsed: 0m2s
2023-03-06 20:13:15.759905: Epoch: 23, Batch: 7, Loss: 0.3875, Elapsed: 0m2s
2023-03-06 20:13:18.569880: Epoch: 23, Batch: 8, Loss: 0.3887, Elapsed: 0m2s
2023-03-06 20:13:20.515731: Epoch: 23, Batch: 9, Loss: 0.3740, Elapsed: 0m1s
2023-03-06 20:13:23.350524: Epoch: 23, Batch: 10, Loss: 0.3872, Elapsed: 0m2s
2023-03-06 20:13:27.583110: Epoch: 23, Batch: 11, Loss: 0.4105, Elapsed: 0m4s
2023-03-06 20:13:29.884838: Epoch: 23, Batch: 12, Loss: 0.3725, Elapsed: 0m2s
2023-03-06 20:13:32.793635: Epoch: 23, Batch: 13, Loss: 0.3884, Elapsed: 0m2s
2023-03-06 20:13:35.363622: Epoch: 23, Batch: 14, Loss: 0.3837, Elapsed: 0m2s
2023-03-06 20:13:37.364460: Epoch: 23, Batch: 15, Loss: 0.3860, Elapsed: 0m1s
2023-03-06 20:13:40.097580: Epoch: 23, Batch: 16, Loss: 0.3912, Elapsed: 0m2s
2023-03-06 20:13:43.774937: Epoch: 23, Batch: 17, Loss: 0.4047, Elapsed: 0m3s
2023-03-06 20:13:46.199123: Epoch: 23, Batch: 18, Loss: 0.3830, Elapsed: 0m2s
2023-03-06 20:13:49.154977: Epoch: 23, Batch: 19, Loss: 0.3980, Elapsed: 0m2s
2023-03-06 20:13:54.244480: Epoch: 23, Batch: 20, Loss: 0.4144, Elapsed: 0m5s
2023-03-06 20:13:55.560455: Epoch: 23, Batch: 21, Loss: 0.3327, Elapsed: 0m1s
2023-03-06 20:13:57.258665: Epoch: 23, Batch: 22, Loss: 0.3724, Elapsed: 0m1s
2023-03-06 20:13:59.181686: Epoch: 23, Batch: 23, Loss: 0.3687, Elapsed: 0m1s
2023-03-06 20:14:03.004006: Epoch: 23, Batch: 24, Loss: 0.4131, Elapsed: 0m3s
2023-03-06 20:14:06.173863: Epoch: 23, Batch: 25, Loss: 0.3830, Elapsed: 0m3s
2023-03-06 20:14:10.690657: Epoch: 23, Batch: 26, Loss: 0.4132, Elapsed: 0m4s
2023-03-06 20:14:13.729356: Epoch: 23, Batch: 27, Loss: 0.3953, Elapsed: 0m3s
2023-03-06 20:14:18.591473: Epoch: 23, Batch: 28, Loss: 0.4107, Elapsed: 0m4s
2023-03-06 20:14:21.515185: Epoch: 23, Batch: 29, Loss: 0.3759, Elapsed: 0m2s
2023-03-06 20:14:24.425125: Epoch: 23, Batch: 30, Loss: 0.3914, Elapsed: 0m2s
2023-03-06 20:14:26.194184: Epoch: 23, Batch: 31, Loss: 0.3518, Elapsed: 0m1s
2023-03-06 20:14:28.420324: Epoch: 23, Batch: 32, Loss: 0.3775, Elapsed: 0m2s
2023-03-06 20:14:30.813619: Epoch: 23, Batch: 33, Loss: 0.3833, Elapsed: 0m2s
2023-03-06 20:14:32.822883: Epoch: 23, Batch: 34, Loss: 0.3583, Elapsed: 0m1s
2023-03-06 20:14:34.512722: Epoch: 23, Batch: 35, Loss: 0.3614, Elapsed: 0m1s
2023-03-06 20:14:37.958876: Epoch: 23, Batch: 36, Loss: 0.4038, Elapsed: 0m3s
2023-03-06 20:14:40.749121: Epoch: 23, Batch: 37, Loss: 0.3941, Elapsed: 0m2s
2023-03-06 20:14:43.773001: Epoch: 23, Batch: 38, Loss: 0.4018, Elapsed: 0m3s
2023-03-06 20:14:46.719970: Epoch: 23, Batch: 39, Loss: 0.4001, Elapsed: 0m2s
2023-03-06 20:14:50.996594: Epoch: 23, Batch: 40, Loss: 0.4118, Elapsed: 0m4s
2023-03-06 20:14:52.647533: Epoch: 23, Batch: 41, Loss: 0.3578, Elapsed: 0m1s
2023-03-06 20:14:55.492142: Epoch: 23, Batch: 42, Loss: 0.3959, Elapsed: 0m2s
2023-03-06 20:14:57.757575: Epoch: 23, Batch: 43, Loss: 0.3854, Elapsed: 0m2s
2023-03-06 20:14:58.770894: Epoch: 23, Batch: 44, Loss: 0.3325, Elapsed: 0m1s
2023-03-06 20:15:04.356884: Epoch: 23, Batch: 45, Loss: 0.4155, Elapsed: 0m5s
2023-03-06 20:15:08.408063: Epoch: 23, Batch: 46, Loss: 0.4228, Elapsed: 0m4s
2023-03-06 20:15:10.886515: Epoch: 23, Batch: 47, Loss: 0.3901, Elapsed: 0m2s
2023-03-06 20:15:14.265589: Epoch: 23, Batch: 48, Loss: 0.4007, Elapsed: 0m3s
2023-03-06 20:15:17.611372: Epoch: 23, Batch: 49, Loss: 0.3982, Elapsed: 0m3s
2023-03-06 20:15:20.080976: Epoch: 23, Batch: 50, Loss: 0.4014, Elapsed: 0m2s
2023-03-06 20:15:20.091360 Starting testing the valid set with 20 subgraphs!
2023-03-06 20:16:25.366305: validation Test:  Loss: 0.3955,  AUC: 0.8776, Acc: 79.5482,  Precision: 0.9259 -- Elapsed: 1m5s
2023-03-06 20:16:25.367480 Starting testing the train set with 20 subgraphs!
2023-03-06 20:20:50.303634: training Test:  Loss: 0.3947,  AUC: 0.8781, Acc: 79.5953,  Precision: 0.9257 -- Elapsed: 4m24s
2023-03-06 20:20:54.780926: Epoch: 23, Batch: 51, Loss: 0.4077, Elapsed: 0m4s
2023-03-06 20:20:59.092804: Epoch: 23, Batch: 52, Loss: 0.4088, Elapsed: 0m4s
2023-03-06 20:21:02.918362: Epoch: 23, Batch: 53, Loss: 0.4009, Elapsed: 0m3s
2023-03-06 20:21:06.427871: Epoch: 23, Batch: 54, Loss: 0.4111, Elapsed: 0m3s
2023-03-06 20:21:09.819844: Epoch: 23, Batch: 55, Loss: 0.3938, Elapsed: 0m3s
2023-03-06 20:21:12.291350: Epoch: 23, Batch: 56, Loss: 0.3819, Elapsed: 0m2s
2023-03-06 20:21:15.769669: Epoch: 23, Batch: 57, Loss: 0.4052, Elapsed: 0m3s
2023-03-06 20:21:18.285332: Epoch: 23, Batch: 58, Loss: 0.3830, Elapsed: 0m2s
2023-03-06 20:21:23.464795: Epoch: 23, Batch: 59, Loss: 0.3849, Elapsed: 0m5s
2023-03-06 20:21:28.347933: Epoch: 23, Batch: 60, Loss: 0.4097, Elapsed: 0m4s
2023-03-06 20:21:30.629644: Epoch: 23, Batch: 61, Loss: 0.3853, Elapsed: 0m2s
2023-03-06 20:21:34.439756: Epoch: 23, Batch: 62, Loss: 0.4075, Elapsed: 0m3s
2023-03-06 20:21:36.973007: Epoch: 23, Batch: 63, Loss: 0.3891, Elapsed: 0m2s
2023-03-06 20:21:38.839751: Epoch: 23, Batch: 64, Loss: 0.3761, Elapsed: 0m1s
2023-03-06 20:21:42.988924: Epoch: 23, Batch: 65, Loss: 0.4098, Elapsed: 0m4s
2023-03-06 20:21:45.925522: Epoch: 23, Batch: 66, Loss: 0.3809, Elapsed: 0m2s
2023-03-06 20:21:50.078917: Epoch: 23, Batch: 67, Loss: 0.4143, Elapsed: 0m4s
2023-03-06 20:21:52.744345: Epoch: 23, Batch: 68, Loss: 0.3916, Elapsed: 0m2s
2023-03-06 20:21:56.325692: Epoch: 23, Batch: 69, Loss: 0.4027, Elapsed: 0m3s
2023-03-06 20:22:00.470349: Epoch: 23, Batch: 70, Loss: 0.4062, Elapsed: 0m4s
2023-03-06 20:22:03.542929: Epoch: 23, Batch: 71, Loss: 0.3854, Elapsed: 0m3s
2023-03-06 20:22:09.932143: Epoch: 23, Batch: 72, Loss: 0.4245, Elapsed: 0m6s
2023-03-06 20:22:14.291521: Epoch: 23, Batch: 73, Loss: 0.4072, Elapsed: 0m4s
2023-03-06 20:22:17.538579: Epoch: 23, Batch: 74, Loss: 0.3941, Elapsed: 0m3s
2023-03-06 20:22:20.109542: Epoch: 23, Batch: 75, Loss: 0.3905, Elapsed: 0m2s
2023-03-06 20:22:22.128040: Epoch: 23, Batch: 76, Loss: 0.3847, Elapsed: 0m2s
2023-03-06 20:22:24.824528: Epoch: 23, Batch: 77, Loss: 0.4024, Elapsed: 0m2s
2023-03-06 20:22:27.788455: Epoch: 23, Batch: 78, Loss: 0.3860, Elapsed: 0m2s
2023-03-06 20:22:30.855926: Epoch: 23, Batch: 79, Loss: 0.4026, Elapsed: 0m3s
2023-03-06 20:22:32.689163: Epoch: 23, Batch: 80, Loss: 0.3663, Elapsed: 0m1s
2023-03-06 20:22:35.484046: Epoch: 24, Batch: 1, Loss: 0.3881, Elapsed: 0m2s
2023-03-06 20:22:38.473172: Epoch: 24, Batch: 2, Loss: 0.3958, Elapsed: 0m2s
2023-03-06 20:22:40.138296: Epoch: 24, Batch: 3, Loss: 0.3578, Elapsed: 0m1s
2023-03-06 20:22:42.608429: Epoch: 24, Batch: 4, Loss: 0.3808, Elapsed: 0m2s
2023-03-06 20:22:45.113299: Epoch: 24, Batch: 5, Loss: 0.3820, Elapsed: 0m2s
2023-03-06 20:22:50.072692: Epoch: 24, Batch: 6, Loss: 0.4096, Elapsed: 0m4s
2023-03-06 20:22:56.353511: Epoch: 24, Batch: 7, Loss: 0.4242, Elapsed: 0m6s
2023-03-06 20:23:00.177566: Epoch: 24, Batch: 8, Loss: 0.4074, Elapsed: 0m3s
2023-03-06 20:23:04.288871: Epoch: 24, Batch: 9, Loss: 0.4088, Elapsed: 0m4s
2023-03-06 20:23:07.022570: Epoch: 24, Batch: 10, Loss: 0.3906, Elapsed: 0m2s
2023-03-06 20:23:11.995667: Epoch: 24, Batch: 11, Loss: 0.4107, Elapsed: 0m4s
2023-03-06 20:23:15.240337: Epoch: 24, Batch: 12, Loss: 0.4018, Elapsed: 0m3s
2023-03-06 20:23:17.157630: Epoch: 24, Batch: 13, Loss: 0.3682, Elapsed: 0m1s
2023-03-06 20:23:22.304165: Epoch: 24, Batch: 14, Loss: 0.3846, Elapsed: 0m5s
2023-03-06 20:23:24.861233: Epoch: 24, Batch: 15, Loss: 0.3667, Elapsed: 0m2s
2023-03-06 20:23:27.754956: Epoch: 24, Batch: 16, Loss: 0.4022, Elapsed: 0m2s
2023-03-06 20:23:33.083727: Epoch: 24, Batch: 17, Loss: 0.4145, Elapsed: 0m5s
2023-03-06 20:23:37.505177: Epoch: 24, Batch: 18, Loss: 0.4083, Elapsed: 0m4s
2023-03-06 20:23:39.037379: Epoch: 24, Batch: 19, Loss: 0.3520, Elapsed: 0m1s
2023-03-06 20:23:43.362397: Epoch: 24, Batch: 20, Loss: 0.4089, Elapsed: 0m4s
2023-03-06 20:23:46.071526: Epoch: 24, Batch: 21, Loss: 0.3911, Elapsed: 0m2s
2023-03-06 20:23:47.088459: Epoch: 24, Batch: 22, Loss: 0.3319, Elapsed: 0m1s
2023-03-06 20:23:49.575149: Epoch: 24, Batch: 23, Loss: 0.4022, Elapsed: 0m2s
2023-03-06 20:23:53.135815: Epoch: 24, Batch: 24, Loss: 0.4029, Elapsed: 0m3s
2023-03-06 20:23:57.262988: Epoch: 24, Batch: 25, Loss: 0.4062, Elapsed: 0m4s
2023-03-06 20:23:59.766299: Epoch: 24, Batch: 26, Loss: 0.3873, Elapsed: 0m2s
2023-03-06 20:24:01.621045: Epoch: 24, Batch: 27, Loss: 0.3751, Elapsed: 0m1s
2023-03-06 20:24:04.107668: Epoch: 24, Batch: 28, Loss: 0.3885, Elapsed: 0m2s
2023-03-06 20:24:06.079271: Epoch: 24, Batch: 29, Loss: 0.3774, Elapsed: 0m1s
2023-03-06 20:24:08.901851: Epoch: 24, Batch: 30, Loss: 0.3865, Elapsed: 0m2s
2023-03-06 20:24:12.787665: Epoch: 24, Batch: 31, Loss: 0.4132, Elapsed: 0m3s
2023-03-06 20:24:14.897904: Epoch: 24, Batch: 32, Loss: 0.3846, Elapsed: 0m2s
2023-03-06 20:24:20.220960: Epoch: 24, Batch: 33, Loss: 0.4190, Elapsed: 0m5s
2023-03-06 20:24:23.603615: Epoch: 24, Batch: 34, Loss: 0.4006, Elapsed: 0m3s
2023-03-06 20:24:26.395060: Epoch: 24, Batch: 35, Loss: 0.3876, Elapsed: 0m2s
2023-03-06 20:24:28.808762: Epoch: 24, Batch: 36, Loss: 0.3827, Elapsed: 0m2s
2023-03-06 20:24:30.646457: Epoch: 24, Batch: 37, Loss: 0.3660, Elapsed: 0m1s
2023-03-06 20:24:32.842003: Epoch: 24, Batch: 38, Loss: 0.3803, Elapsed: 0m2s
2023-03-06 20:24:38.420809: Epoch: 24, Batch: 39, Loss: 0.4153, Elapsed: 0m5s
2023-03-06 20:24:42.577578: Epoch: 24, Batch: 40, Loss: 0.4093, Elapsed: 0m4s
2023-03-06 20:24:44.952647: Epoch: 24, Batch: 41, Loss: 0.3887, Elapsed: 0m2s
2023-03-06 20:24:47.894236: Epoch: 24, Batch: 42, Loss: 0.3851, Elapsed: 0m2s
2023-03-06 20:24:50.040130: Epoch: 24, Batch: 43, Loss: 0.3725, Elapsed: 0m2s
2023-03-06 20:24:51.339560: Epoch: 24, Batch: 44, Loss: 0.3324, Elapsed: 0m1s
2023-03-06 20:24:55.612099: Epoch: 24, Batch: 45, Loss: 0.4118, Elapsed: 0m4s
2023-03-06 20:24:58.555464: Epoch: 24, Batch: 46, Loss: 0.3969, Elapsed: 0m2s
2023-03-06 20:25:00.713730: Epoch: 24, Batch: 47, Loss: 0.3833, Elapsed: 0m2s
2023-03-06 20:25:03.619761: Epoch: 24, Batch: 48, Loss: 0.3810, Elapsed: 0m2s
2023-03-06 20:25:06.665102: Epoch: 24, Batch: 49, Loss: 0.4023, Elapsed: 0m3s
2023-03-06 20:25:09.270461: Epoch: 24, Batch: 50, Loss: 0.3913, Elapsed: 0m2s
2023-03-06 20:25:09.280364 Starting testing the valid set with 20 subgraphs!
2023-03-06 20:26:16.274753: validation Test:  Loss: 0.3948,  AUC: 0.8774, Acc: 79.5119,  Precision: 0.8632 -- Elapsed: 1m6s
2023-03-06 20:26:16.276128 Starting testing the train set with 20 subgraphs!
2023-03-06 20:30:45.260706: training Test:  Loss: 0.3940,  AUC: 0.8778, Acc: 79.5816,  Precision: 0.8646 -- Elapsed: 4m28s
2023-03-06 20:30:48.368124: Epoch: 24, Batch: 51, Loss: 0.3950, Elapsed: 0m3s
2023-03-06 20:30:50.554022: Epoch: 24, Batch: 52, Loss: 0.3689, Elapsed: 0m2s
2023-03-06 20:30:53.813586: Epoch: 24, Batch: 53, Loss: 0.3934, Elapsed: 0m3s
2023-03-06 20:30:57.279073: Epoch: 24, Batch: 54, Loss: 0.4055, Elapsed: 0m3s
2023-03-06 20:30:59.563453: Epoch: 24, Batch: 55, Loss: 0.3855, Elapsed: 0m2s
2023-03-06 20:31:03.228296: Epoch: 24, Batch: 56, Loss: 0.4002, Elapsed: 0m3s
2023-03-06 20:31:06.750960: Epoch: 24, Batch: 57, Loss: 0.4115, Elapsed: 0m3s
2023-03-06 20:31:10.204655: Epoch: 24, Batch: 58, Loss: 0.3974, Elapsed: 0m3s
2023-03-06 20:31:12.744653: Epoch: 24, Batch: 59, Loss: 0.3920, Elapsed: 0m2s
2023-03-06 20:31:16.451903: Epoch: 24, Batch: 60, Loss: 0.4040, Elapsed: 0m3s
2023-03-06 20:31:19.497539: Epoch: 24, Batch: 61, Loss: 0.3861, Elapsed: 0m3s
2023-03-06 20:31:21.785548: Epoch: 24, Batch: 62, Loss: 0.3852, Elapsed: 0m2s
2023-03-06 20:31:23.730259: Epoch: 24, Batch: 63, Loss: 0.3732, Elapsed: 0m1s
2023-03-06 20:31:27.788791: Epoch: 24, Batch: 64, Loss: 0.4103, Elapsed: 0m4s
2023-03-06 20:31:32.394740: Epoch: 24, Batch: 65, Loss: 0.4127, Elapsed: 0m4s
2023-03-06 20:31:34.105105: Epoch: 24, Batch: 66, Loss: 0.3726, Elapsed: 0m1s
2023-03-06 20:31:35.722295: Epoch: 24, Batch: 67, Loss: 0.3613, Elapsed: 0m1s
2023-03-06 20:31:38.217439: Epoch: 24, Batch: 68, Loss: 0.3896, Elapsed: 0m2s
2023-03-06 20:31:41.665100: Epoch: 24, Batch: 69, Loss: 0.3933, Elapsed: 0m3s
2023-03-06 20:31:43.614299: Epoch: 24, Batch: 70, Loss: 0.3582, Elapsed: 0m1s
2023-03-06 20:31:46.625242: Epoch: 24, Batch: 71, Loss: 0.3939, Elapsed: 0m3s
2023-03-06 20:31:49.639571: Epoch: 24, Batch: 72, Loss: 0.3956, Elapsed: 0m3s
2023-03-06 20:31:51.716445: Epoch: 24, Batch: 73, Loss: 0.3848, Elapsed: 0m2s
2023-03-06 20:31:55.822569: Epoch: 24, Batch: 74, Loss: 0.4224, Elapsed: 0m4s
2023-03-06 20:31:58.346028: Epoch: 24, Batch: 75, Loss: 0.3755, Elapsed: 0m2s
2023-03-06 20:32:00.888283: Epoch: 24, Batch: 76, Loss: 0.3822, Elapsed: 0m2s
2023-03-06 20:32:03.872702: Epoch: 24, Batch: 77, Loss: 0.3999, Elapsed: 0m2s
2023-03-06 20:32:07.047493: Epoch: 24, Batch: 78, Loss: 0.3824, Elapsed: 0m3s
2023-03-06 20:32:11.184766: Epoch: 24, Batch: 79, Loss: 0.4134, Elapsed: 0m4s
2023-03-06 20:32:14.643020: Epoch: 24, Batch: 80, Loss: 0.4038, Elapsed: 0m3s
2023-03-06 20:32:17.039482: Epoch: 25, Batch: 1, Loss: 0.3881, Elapsed: 0m2s
2023-03-06 20:32:19.986117: Epoch: 25, Batch: 2, Loss: 0.3808, Elapsed: 0m2s
2023-03-06 20:32:23.439942: Epoch: 25, Batch: 3, Loss: 0.3931, Elapsed: 0m3s
2023-03-06 20:32:24.772067: Epoch: 25, Batch: 4, Loss: 0.3318, Elapsed: 0m1s
2023-03-06 20:32:27.815427: Epoch: 25, Batch: 5, Loss: 0.3951, Elapsed: 0m3s
2023-03-06 20:32:30.681997: Epoch: 25, Batch: 6, Loss: 0.3955, Elapsed: 0m2s
2023-03-06 20:32:35.575844: Epoch: 25, Batch: 7, Loss: 0.4104, Elapsed: 0m4s
2023-03-06 20:32:39.977685: Epoch: 25, Batch: 8, Loss: 0.4224, Elapsed: 0m4s
2023-03-06 20:32:43.572617: Epoch: 25, Batch: 9, Loss: 0.3933, Elapsed: 0m3s
2023-03-06 20:32:47.412180: Epoch: 25, Batch: 10, Loss: 0.4107, Elapsed: 0m3s
2023-03-06 20:32:53.521987: Epoch: 25, Batch: 11, Loss: 0.4149, Elapsed: 0m6s
2023-03-06 20:32:57.189626: Epoch: 25, Batch: 12, Loss: 0.4024, Elapsed: 0m3s
2023-03-06 20:33:00.829468: Epoch: 25, Batch: 13, Loss: 0.4038, Elapsed: 0m3s
2023-03-06 20:33:02.754051: Epoch: 25, Batch: 14, Loss: 0.3675, Elapsed: 0m1s
2023-03-06 20:33:05.724573: Epoch: 25, Batch: 15, Loss: 0.3997, Elapsed: 0m2s
2023-03-06 20:33:08.191440: Epoch: 25, Batch: 16, Loss: 0.3805, Elapsed: 0m2s
2023-03-06 20:33:12.014815: Epoch: 25, Batch: 17, Loss: 0.4128, Elapsed: 0m3s
2023-03-06 20:33:13.633016: Epoch: 25, Batch: 18, Loss: 0.3616, Elapsed: 0m1s
2023-03-06 20:33:16.600246: Epoch: 25, Batch: 19, Loss: 0.3858, Elapsed: 0m2s
2023-03-06 20:33:19.669992: Epoch: 25, Batch: 20, Loss: 0.4023, Elapsed: 0m3s
2023-03-06 20:33:22.355598: Epoch: 25, Batch: 21, Loss: 0.4017, Elapsed: 0m2s
2023-03-06 20:33:27.261834: Epoch: 25, Batch: 22, Loss: 0.4093, Elapsed: 0m4s
2023-03-06 20:33:29.857902: Epoch: 25, Batch: 23, Loss: 0.3818, Elapsed: 0m2s
2023-03-06 20:33:32.928662: Epoch: 25, Batch: 24, Loss: 0.4015, Elapsed: 0m3s
2023-03-06 20:33:35.503898: Epoch: 25, Batch: 25, Loss: 0.3904, Elapsed: 0m2s
2023-03-06 20:33:40.905170: Epoch: 25, Batch: 26, Loss: 0.4193, Elapsed: 0m5s
2023-03-06 20:33:44.752985: Epoch: 25, Batch: 27, Loss: 0.4073, Elapsed: 0m3s
2023-03-06 20:33:48.966845: Epoch: 25, Batch: 28, Loss: 0.4092, Elapsed: 0m4s
2023-03-06 20:33:52.140925: Epoch: 25, Batch: 29, Loss: 0.3825, Elapsed: 0m3s
2023-03-06 20:33:54.752798: Epoch: 25, Batch: 30, Loss: 0.3821, Elapsed: 0m2s
2023-03-06 20:33:57.070467: Epoch: 25, Batch: 31, Loss: 0.3691, Elapsed: 0m2s
2023-03-06 20:33:59.095128: Epoch: 25, Batch: 32, Loss: 0.3728, Elapsed: 0m2s
2023-03-06 20:34:01.589560: Epoch: 25, Batch: 33, Loss: 0.3893, Elapsed: 0m2s
2023-03-06 20:34:03.470087: Epoch: 25, Batch: 34, Loss: 0.3661, Elapsed: 0m1s
2023-03-06 20:34:07.776882: Epoch: 25, Batch: 35, Loss: 0.4121, Elapsed: 0m4s
2023-03-06 20:34:09.648694: Epoch: 25, Batch: 36, Loss: 0.3750, Elapsed: 0m1s
2023-03-06 20:34:14.010040: Epoch: 25, Batch: 37, Loss: 0.4072, Elapsed: 0m4s
2023-03-06 20:34:15.714070: Epoch: 25, Batch: 38, Loss: 0.3721, Elapsed: 0m1s
2023-03-06 20:34:21.968247: Epoch: 25, Batch: 39, Loss: 0.4247, Elapsed: 0m6s
2023-03-06 20:34:25.361628: Epoch: 25, Batch: 40, Loss: 0.4006, Elapsed: 0m3s
2023-03-06 20:34:27.384826: Epoch: 25, Batch: 41, Loss: 0.3847, Elapsed: 0m2s
2023-03-06 20:34:29.668086: Epoch: 25, Batch: 42, Loss: 0.3854, Elapsed: 0m2s
2023-03-06 20:34:33.826945: Epoch: 25, Batch: 43, Loss: 0.4063, Elapsed: 0m4s
2023-03-06 20:34:35.826155: Epoch: 25, Batch: 44, Loss: 0.3855, Elapsed: 0m1s
2023-03-06 20:34:38.335697: Epoch: 25, Batch: 45, Loss: 0.3754, Elapsed: 0m2s
2023-03-06 20:34:41.144605: Epoch: 25, Batch: 46, Loss: 0.3878, Elapsed: 0m2s
2023-03-06 20:34:43.779954: Epoch: 25, Batch: 47, Loss: 0.3912, Elapsed: 0m2s
2023-03-06 20:34:46.578894: Epoch: 25, Batch: 48, Loss: 0.3878, Elapsed: 0m2s
2023-03-06 20:34:50.714095: Epoch: 25, Batch: 49, Loss: 0.4133, Elapsed: 0m4s
2023-03-06 20:34:53.106533: Epoch: 25, Batch: 50, Loss: 0.3661, Elapsed: 0m2s
2023-03-06 20:34:53.114716 Starting testing the valid set with 20 subgraphs!
2023-03-06 20:36:01.491580: validation Test:  Loss: 0.3946,  AUC: 0.8776, Acc: 79.4943,  Precision: 0.8700 -- Elapsed: 1m8s
2023-03-06 20:36:01.492794 Starting testing the train set with 20 subgraphs!
2023-03-06 20:40:24.472739: training Test:  Loss: 0.3938,  AUC: 0.8781, Acc: 79.5940,  Precision: 0.8709 -- Elapsed: 4m22s
2023-03-06 20:40:27.450342: Epoch: 25, Batch: 51, Loss: 0.3939, Elapsed: 0m2s
2023-03-06 20:40:29.111269: Epoch: 25, Batch: 52, Loss: 0.3576, Elapsed: 0m1s
2023-03-06 20:40:31.312031: Epoch: 25, Batch: 53, Loss: 0.3802, Elapsed: 0m2s
2023-03-06 20:40:35.326358: Epoch: 25, Batch: 54, Loss: 0.4097, Elapsed: 0m4s
2023-03-06 20:40:38.775529: Epoch: 25, Batch: 55, Loss: 0.4035, Elapsed: 0m3s
2023-03-06 20:40:43.903300: Epoch: 25, Batch: 56, Loss: 0.4147, Elapsed: 0m5s
2023-03-06 20:40:48.442392: Epoch: 25, Batch: 57, Loss: 0.4130, Elapsed: 0m4s
2023-03-06 20:40:51.837797: Epoch: 25, Batch: 58, Loss: 0.3974, Elapsed: 0m3s
2023-03-06 20:40:53.997981: Epoch: 25, Batch: 59, Loss: 0.3721, Elapsed: 0m2s
2023-03-06 20:40:56.850391: Epoch: 25, Batch: 60, Loss: 0.3862, Elapsed: 0m2s
2023-03-06 20:41:01.292643: Epoch: 25, Batch: 61, Loss: 0.4074, Elapsed: 0m4s
2023-03-06 20:41:03.814258: Epoch: 25, Batch: 62, Loss: 0.3868, Elapsed: 0m2s
2023-03-06 20:41:06.230179: Epoch: 25, Batch: 63, Loss: 0.3820, Elapsed: 0m2s
2023-03-06 20:41:09.881994: Epoch: 25, Batch: 64, Loss: 0.4002, Elapsed: 0m3s
2023-03-06 20:41:12.385013: Epoch: 25, Batch: 65, Loss: 0.3910, Elapsed: 0m2s
2023-03-06 20:41:14.292902: Epoch: 25, Batch: 66, Loss: 0.3580, Elapsed: 0m1s
2023-03-06 20:41:15.841023: Epoch: 25, Batch: 67, Loss: 0.3523, Elapsed: 0m1s
2023-03-06 20:41:18.848127: Epoch: 25, Batch: 68, Loss: 0.3954, Elapsed: 0m2s
2023-03-06 20:41:21.570934: Epoch: 25, Batch: 69, Loss: 0.3899, Elapsed: 0m2s
2023-03-06 20:41:24.062601: Epoch: 25, Batch: 70, Loss: 0.4010, Elapsed: 0m2s
2023-03-06 20:41:28.247374: Epoch: 25, Batch: 71, Loss: 0.4084, Elapsed: 0m4s
2023-03-06 20:41:30.333603: Epoch: 25, Batch: 72, Loss: 0.3779, Elapsed: 0m2s
2023-03-06 20:41:36.063752: Epoch: 25, Batch: 73, Loss: 0.3863, Elapsed: 0m5s
2023-03-06 20:41:39.515019: Epoch: 25, Batch: 74, Loss: 0.3860, Elapsed: 0m3s
2023-03-06 20:41:42.462702: Epoch: 25, Batch: 75, Loss: 0.3899, Elapsed: 0m2s
2023-03-06 20:41:44.965916: Epoch: 25, Batch: 76, Loss: 0.3834, Elapsed: 0m2s
2023-03-06 20:41:46.065106: Epoch: 25, Batch: 77, Loss: 0.3323, Elapsed: 0m1s
2023-03-06 20:41:48.364821: Epoch: 25, Batch: 78, Loss: 0.3863, Elapsed: 0m2s
2023-03-06 20:41:51.794029: Epoch: 25, Batch: 79, Loss: 0.4049, Elapsed: 0m3s
2023-03-06 20:41:54.723367: Epoch: 25, Batch: 80, Loss: 0.3978, Elapsed: 0m2s
2023-03-06 20:41:56.890107: Epoch: 26, Batch: 1, Loss: 0.3692, Elapsed: 0m2s
2023-03-06 20:41:59.853601: Epoch: 26, Batch: 2, Loss: 0.3954, Elapsed: 0m2s
2023-03-06 20:42:03.267197: Epoch: 26, Batch: 3, Loss: 0.4043, Elapsed: 0m3s
2023-03-06 20:42:05.177109: Epoch: 26, Batch: 4, Loss: 0.3678, Elapsed: 0m1s
2023-03-06 20:42:08.092030: Epoch: 26, Batch: 5, Loss: 0.3857, Elapsed: 0m2s
2023-03-06 20:42:09.986834: Epoch: 26, Batch: 6, Loss: 0.3582, Elapsed: 0m1s
2023-03-06 20:42:12.924001: Epoch: 26, Batch: 7, Loss: 0.3872, Elapsed: 0m2s
2023-03-06 20:42:15.836224: Epoch: 26, Batch: 8, Loss: 0.3805, Elapsed: 0m2s
2023-03-06 20:42:18.312090: Epoch: 26, Batch: 9, Loss: 0.3915, Elapsed: 0m2s
2023-03-06 20:42:21.525504: Epoch: 26, Batch: 10, Loss: 0.3939, Elapsed: 0m3s
2023-03-06 20:42:23.991635: Epoch: 26, Batch: 11, Loss: 0.4013, Elapsed: 0m2s
2023-03-06 20:42:27.032420: Epoch: 26, Batch: 12, Loss: 0.4024, Elapsed: 0m3s
2023-03-06 20:42:28.046653: Epoch: 26, Batch: 13, Loss: 0.3325, Elapsed: 0m1s
2023-03-06 20:42:31.687751: Epoch: 26, Batch: 14, Loss: 0.4040, Elapsed: 0m3s
2023-03-06 20:42:36.035773: Epoch: 26, Batch: 15, Loss: 0.4089, Elapsed: 0m4s
2023-03-06 20:42:40.497001: Epoch: 26, Batch: 16, Loss: 0.4119, Elapsed: 0m4s
2023-03-06 20:42:42.958516: Epoch: 26, Batch: 17, Loss: 0.3809, Elapsed: 0m2s
2023-03-06 20:42:45.113971: Epoch: 26, Batch: 18, Loss: 0.3829, Elapsed: 0m2s
2023-03-06 20:42:49.246600: Epoch: 26, Batch: 19, Loss: 0.4090, Elapsed: 0m4s
2023-03-06 20:42:51.434541: Epoch: 26, Batch: 20, Loss: 0.3800, Elapsed: 0m2s
2023-03-06 20:42:53.260046: Epoch: 26, Batch: 21, Loss: 0.3661, Elapsed: 0m1s
2023-03-06 20:42:56.600868: Epoch: 26, Batch: 22, Loss: 0.3975, Elapsed: 0m3s
2023-03-06 20:43:01.442176: Epoch: 26, Batch: 23, Loss: 0.4093, Elapsed: 0m4s
2023-03-06 20:43:04.822721: Epoch: 26, Batch: 24, Loss: 0.4006, Elapsed: 0m3s
2023-03-06 20:43:07.314370: Epoch: 26, Batch: 25, Loss: 0.3752, Elapsed: 0m2s
2023-03-06 20:43:11.437543: Epoch: 26, Batch: 26, Loss: 0.4053, Elapsed: 0m4s
2023-03-06 20:43:13.356361: Epoch: 26, Batch: 27, Loss: 0.3728, Elapsed: 0m1s
2023-03-06 20:43:16.180917: Epoch: 26, Batch: 28, Loss: 0.3861, Elapsed: 0m2s
2023-03-06 20:43:20.500121: Epoch: 26, Batch: 29, Loss: 0.4070, Elapsed: 0m4s
2023-03-06 20:43:23.014266: Epoch: 26, Batch: 30, Loss: 0.3817, Elapsed: 0m2s
2023-03-06 20:43:25.948091: Epoch: 26, Batch: 31, Loss: 0.3967, Elapsed: 0m2s
2023-03-06 20:43:27.242872: Epoch: 26, Batch: 32, Loss: 0.3317, Elapsed: 0m1s
2023-03-06 20:43:33.442037: Epoch: 26, Batch: 33, Loss: 0.4242, Elapsed: 0m6s
2023-03-06 20:43:37.296502: Epoch: 26, Batch: 34, Loss: 0.3998, Elapsed: 0m3s
2023-03-06 20:43:40.032712: Epoch: 26, Batch: 35, Loss: 0.3858, Elapsed: 0m2s
2023-03-06 20:43:42.535224: Epoch: 26, Batch: 36, Loss: 0.3669, Elapsed: 0m2s
2023-03-06 20:43:45.715664: Epoch: 26, Batch: 37, Loss: 0.3827, Elapsed: 0m3s
2023-03-06 20:43:47.853894: Epoch: 26, Batch: 38, Loss: 0.3725, Elapsed: 0m2s
2023-03-06 20:43:52.928153: Epoch: 26, Batch: 39, Loss: 0.4136, Elapsed: 0m5s
2023-03-06 20:43:56.979036: Epoch: 26, Batch: 40, Loss: 0.4237, Elapsed: 0m4s
2023-03-06 20:43:58.577878: Epoch: 26, Batch: 41, Loss: 0.3616, Elapsed: 0m1s
2023-03-06 20:44:00.224813: Epoch: 26, Batch: 42, Loss: 0.3583, Elapsed: 0m1s
2023-03-06 20:44:03.006382: Epoch: 26, Batch: 43, Loss: 0.3884, Elapsed: 0m2s
2023-03-06 20:44:05.503571: Epoch: 26, Batch: 44, Loss: 0.3830, Elapsed: 0m2s
2023-03-06 20:44:08.002784: Epoch: 26, Batch: 45, Loss: 0.3917, Elapsed: 0m2s
2023-03-06 20:44:11.977996: Epoch: 26, Batch: 46, Loss: 0.4104, Elapsed: 0m3s
2023-03-06 20:44:15.763124: Epoch: 26, Batch: 47, Loss: 0.4073, Elapsed: 0m3s
2023-03-06 20:44:17.442427: Epoch: 26, Batch: 48, Loss: 0.3729, Elapsed: 0m1s
2023-03-06 20:44:19.416400: Epoch: 26, Batch: 49, Loss: 0.3777, Elapsed: 0m1s
2023-03-06 20:44:21.897971: Epoch: 26, Batch: 50, Loss: 0.3886, Elapsed: 0m2s
2023-03-06 20:44:21.909552 Starting testing the valid set with 20 subgraphs!
2023-03-06 20:45:28.916202: validation Test:  Loss: 0.3946,  AUC: 0.8777, Acc: 79.5040,  Precision: 0.8525 -- Elapsed: 1m7s
2023-03-06 20:45:28.917426 Starting testing the train set with 20 subgraphs!
2023-03-06 20:49:52.141416: training Test:  Loss: 0.3938,  AUC: 0.8781, Acc: 79.5763,  Precision: 0.8544 -- Elapsed: 4m23s
2023-03-06 20:49:54.774126: Epoch: 26, Batch: 51, Loss: 0.3909, Elapsed: 0m2s
2023-03-06 20:49:57.052869: Epoch: 26, Batch: 52, Loss: 0.3854, Elapsed: 0m2s
2023-03-06 20:50:00.864254: Epoch: 26, Batch: 53, Loss: 0.4128, Elapsed: 0m3s
2023-03-06 20:50:05.048156: Epoch: 26, Batch: 54, Loss: 0.4136, Elapsed: 0m4s
2023-03-06 20:50:08.023339: Epoch: 26, Batch: 55, Loss: 0.3873, Elapsed: 0m2s
2023-03-06 20:50:09.983924: Epoch: 26, Batch: 56, Loss: 0.3750, Elapsed: 0m1s
2023-03-06 20:50:12.031627: Epoch: 26, Batch: 57, Loss: 0.3848, Elapsed: 0m2s
2023-03-06 20:50:14.437154: Epoch: 26, Batch: 58, Loss: 0.3821, Elapsed: 0m2s
2023-03-06 20:50:17.837908: Epoch: 26, Batch: 59, Loss: 0.3927, Elapsed: 0m3s
2023-03-06 20:50:19.863578: Epoch: 26, Batch: 60, Loss: 0.3842, Elapsed: 0m2s
2023-03-06 20:50:22.893836: Epoch: 26, Batch: 61, Loss: 0.4014, Elapsed: 0m3s
2023-03-06 20:50:25.401305: Epoch: 26, Batch: 62, Loss: 0.3863, Elapsed: 0m2s
2023-03-06 20:50:27.792071: Epoch: 26, Batch: 63, Loss: 0.3880, Elapsed: 0m2s
2023-03-06 20:50:31.024588: Epoch: 26, Batch: 64, Loss: 0.3945, Elapsed: 0m3s
2023-03-06 20:50:34.125730: Epoch: 26, Batch: 65, Loss: 0.3954, Elapsed: 0m3s
2023-03-06 20:50:37.080543: Epoch: 26, Batch: 66, Loss: 0.3899, Elapsed: 0m2s
2023-03-06 20:50:39.807550: Epoch: 26, Batch: 67, Loss: 0.3901, Elapsed: 0m2s
2023-03-06 20:50:43.279185: Epoch: 26, Batch: 68, Loss: 0.4107, Elapsed: 0m3s
2023-03-06 20:50:48.698912: Epoch: 26, Batch: 69, Loss: 0.3848, Elapsed: 0m5s
2023-03-06 20:50:51.942198: Epoch: 26, Batch: 70, Loss: 0.3996, Elapsed: 0m3s
2023-03-06 20:50:56.608250: Epoch: 26, Batch: 71, Loss: 0.4123, Elapsed: 0m4s
2023-03-06 20:51:02.199448: Epoch: 26, Batch: 72, Loss: 0.4147, Elapsed: 0m5s
2023-03-06 20:51:04.872599: Epoch: 26, Batch: 73, Loss: 0.4018, Elapsed: 0m2s
2023-03-06 20:51:06.405226: Epoch: 26, Batch: 74, Loss: 0.3518, Elapsed: 0m1s
2023-03-06 20:51:09.951255: Epoch: 26, Batch: 75, Loss: 0.4034, Elapsed: 0m3s
2023-03-06 20:51:14.790041: Epoch: 26, Batch: 76, Loss: 0.4110, Elapsed: 0m4s
2023-03-06 20:51:19.212934: Epoch: 26, Batch: 77, Loss: 0.4067, Elapsed: 0m4s
2023-03-06 20:51:21.999486: Epoch: 26, Batch: 78, Loss: 0.3944, Elapsed: 0m2s
2023-03-06 20:51:25.429508: Epoch: 26, Batch: 79, Loss: 0.4049, Elapsed: 0m3s
2023-03-06 20:51:30.742963: Epoch: 26, Batch: 80, Loss: 0.4190, Elapsed: 0m5s
2023-03-06 20:51:32.268764: Epoch: 27, Batch: 1, Loss: 0.3514, Elapsed: 0m1s
2023-03-06 20:51:34.457411: Epoch: 27, Batch: 2, Loss: 0.3811, Elapsed: 0m2s
2023-03-06 20:51:36.166201: Epoch: 27, Batch: 3, Loss: 0.3719, Elapsed: 0m1s
2023-03-06 20:51:40.212725: Epoch: 27, Batch: 4, Loss: 0.4228, Elapsed: 0m4s
2023-03-06 20:51:42.466573: Epoch: 27, Batch: 5, Loss: 0.3850, Elapsed: 0m2s
2023-03-06 20:51:44.919886: Epoch: 27, Batch: 6, Loss: 0.3809, Elapsed: 0m2s
2023-03-06 20:51:48.351567: Epoch: 27, Batch: 7, Loss: 0.4050, Elapsed: 0m3s
2023-03-06 20:51:50.903818: Epoch: 27, Batch: 8, Loss: 0.3900, Elapsed: 0m2s
2023-03-06 20:51:52.514447: Epoch: 27, Batch: 9, Loss: 0.3616, Elapsed: 0m1s
2023-03-06 20:51:55.448453: Epoch: 27, Batch: 10, Loss: 0.3855, Elapsed: 0m2s
2023-03-06 20:51:57.842504: Epoch: 27, Batch: 11, Loss: 0.3659, Elapsed: 0m2s
2023-03-06 20:52:02.429480: Epoch: 27, Batch: 12, Loss: 0.4105, Elapsed: 0m4s
2023-03-06 20:52:05.896363: Epoch: 27, Batch: 13, Loss: 0.4107, Elapsed: 0m3s
2023-03-06 20:52:09.236524: Epoch: 27, Batch: 14, Loss: 0.3971, Elapsed: 0m3s
2023-03-06 20:52:11.508402: Epoch: 27, Batch: 15, Loss: 0.3848, Elapsed: 0m2s
2023-03-06 20:52:13.995234: Epoch: 27, Batch: 16, Loss: 0.3817, Elapsed: 0m2s
2023-03-06 20:52:17.348070: Epoch: 27, Batch: 17, Loss: 0.3824, Elapsed: 0m3s
2023-03-06 20:52:19.091115: Epoch: 27, Batch: 18, Loss: 0.3576, Elapsed: 0m1s
2023-03-06 20:52:23.220911: Epoch: 27, Batch: 19, Loss: 0.4092, Elapsed: 0m4s
2023-03-06 20:52:25.221979: Epoch: 27, Batch: 20, Loss: 0.3843, Elapsed: 0m1s
2023-03-06 20:52:28.855579: Epoch: 27, Batch: 21, Loss: 0.3998, Elapsed: 0m3s
2023-03-06 20:52:30.770884: Epoch: 27, Batch: 22, Loss: 0.3729, Elapsed: 0m1s
2023-03-06 20:52:34.844232: Epoch: 27, Batch: 23, Loss: 0.4084, Elapsed: 0m4s
2023-03-06 20:52:37.653556: Epoch: 27, Batch: 24, Loss: 0.3936, Elapsed: 0m2s
2023-03-06 20:52:40.509200: Epoch: 27, Batch: 25, Loss: 0.3957, Elapsed: 0m2s
2023-03-06 20:52:42.407113: Epoch: 27, Batch: 26, Loss: 0.3577, Elapsed: 0m1s
2023-03-06 20:52:45.112891: Epoch: 27, Batch: 27, Loss: 0.3905, Elapsed: 0m2s
2023-03-06 20:52:47.902172: Epoch: 27, Batch: 28, Loss: 0.3879, Elapsed: 0m2s
2023-03-06 20:52:50.316759: Epoch: 27, Batch: 29, Loss: 0.3822, Elapsed: 0m2s
2023-03-06 20:52:54.724390: Epoch: 27, Batch: 30, Loss: 0.4068, Elapsed: 0m4s
2023-03-06 20:52:57.553462: Epoch: 27, Batch: 31, Loss: 0.3860, Elapsed: 0m2s
2023-03-06 20:53:00.487327: Epoch: 27, Batch: 32, Loss: 0.3966, Elapsed: 0m2s
2023-03-06 20:53:02.984815: Epoch: 27, Batch: 33, Loss: 0.3905, Elapsed: 0m2s
2023-03-06 20:53:08.048144: Epoch: 27, Batch: 34, Loss: 0.4133, Elapsed: 0m5s
2023-03-06 20:53:09.342860: Epoch: 27, Batch: 35, Loss: 0.3314, Elapsed: 0m1s
2023-03-06 20:53:11.253746: Epoch: 27, Batch: 36, Loss: 0.3674, Elapsed: 0m1s
2023-03-06 20:53:14.899955: Epoch: 27, Batch: 37, Loss: 0.4036, Elapsed: 0m3s
2023-03-06 20:53:16.873752: Epoch: 27, Batch: 38, Loss: 0.3771, Elapsed: 0m1s
2023-03-06 20:53:20.753421: Epoch: 27, Batch: 39, Loss: 0.4070, Elapsed: 0m3s
2023-03-06 20:53:24.155838: Epoch: 27, Batch: 40, Loss: 0.3931, Elapsed: 0m3s
2023-03-06 20:53:27.320920: Epoch: 27, Batch: 41, Loss: 0.3945, Elapsed: 0m3s
2023-03-06 20:53:29.795686: Epoch: 27, Batch: 42, Loss: 0.3890, Elapsed: 0m2s
2023-03-06 20:53:32.911420: Epoch: 27, Batch: 43, Loss: 0.3996, Elapsed: 0m3s
2023-03-06 20:53:36.108618: Epoch: 27, Batch: 44, Loss: 0.3847, Elapsed: 0m3s
2023-03-06 20:53:40.438453: Epoch: 27, Batch: 45, Loss: 0.4090, Elapsed: 0m4s
2023-03-06 20:53:42.500619: Epoch: 27, Batch: 46, Loss: 0.3846, Elapsed: 0m2s
2023-03-06 20:53:45.338110: Epoch: 27, Batch: 47, Loss: 0.3871, Elapsed: 0m2s
2023-03-06 20:53:48.593050: Epoch: 27, Batch: 48, Loss: 0.4013, Elapsed: 0m3s
2023-03-06 20:53:50.963324: Epoch: 27, Batch: 49, Loss: 0.3685, Elapsed: 0m2s
2023-03-06 20:53:54.668050: Epoch: 27, Batch: 50, Loss: 0.3926, Elapsed: 0m3s
2023-03-06 20:53:54.677352 Starting testing the valid set with 20 subgraphs!
2023-03-06 20:55:00.321994: validation Test:  Loss: 0.3949,  AUC: 0.8775, Acc: 79.4994,  Precision: 0.8255 -- Elapsed: 1m5s
2023-03-06 20:55:00.323347 Starting testing the train set with 20 subgraphs!
2023-03-06 20:59:22.895363: training Test:  Loss: 0.3942,  AUC: 0.8779, Acc: 79.5537,  Precision: 0.8273 -- Elapsed: 4m22s
2023-03-06 20:59:26.492910: Epoch: 27, Batch: 51, Loss: 0.4025, Elapsed: 0m3s
2023-03-06 20:59:29.950052: Epoch: 27, Batch: 52, Loss: 0.4034, Elapsed: 0m3s
2023-03-06 20:59:30.969343: Epoch: 27, Batch: 53, Loss: 0.3323, Elapsed: 0m1s
2023-03-06 20:59:35.499093: Epoch: 27, Batch: 54, Loss: 0.4072, Elapsed: 0m4s
2023-03-06 20:59:39.175057: Epoch: 27, Batch: 55, Loss: 0.4002, Elapsed: 0m3s
2023-03-06 20:59:42.661765: Epoch: 27, Batch: 56, Loss: 0.3959, Elapsed: 0m3s
2023-03-06 20:59:46.134747: Epoch: 27, Batch: 57, Loss: 0.4023, Elapsed: 0m3s
2023-03-06 20:59:50.804401: Epoch: 27, Batch: 58, Loss: 0.4052, Elapsed: 0m4s
2023-03-06 20:59:53.461880: Epoch: 27, Batch: 59, Loss: 0.3814, Elapsed: 0m2s
2023-03-06 20:59:56.474210: Epoch: 27, Batch: 60, Loss: 0.3804, Elapsed: 0m3s
2023-03-06 20:59:58.965357: Epoch: 27, Batch: 61, Loss: 0.3862, Elapsed: 0m2s
2023-03-06 21:00:03.443892: Epoch: 27, Batch: 62, Loss: 0.4127, Elapsed: 0m4s
2023-03-06 21:00:08.775364: Epoch: 27, Batch: 63, Loss: 0.4187, Elapsed: 0m5s
2023-03-06 21:00:14.977247: Epoch: 27, Batch: 64, Loss: 0.4238, Elapsed: 0m6s
2023-03-06 21:00:16.837732: Epoch: 27, Batch: 65, Loss: 0.3748, Elapsed: 0m1s
2023-03-06 21:00:19.330747: Epoch: 27, Batch: 66, Loss: 0.3751, Elapsed: 0m2s
2023-03-06 21:00:23.606333: Epoch: 27, Batch: 67, Loss: 0.4116, Elapsed: 0m4s
2023-03-06 21:00:25.759071: Epoch: 27, Batch: 68, Loss: 0.3827, Elapsed: 0m2s
2023-03-06 21:00:27.584912: Epoch: 27, Batch: 69, Loss: 0.3657, Elapsed: 0m1s
2023-03-06 21:00:31.374374: Epoch: 27, Batch: 70, Loss: 0.4124, Elapsed: 0m3s
2023-03-06 21:00:35.519142: Epoch: 27, Batch: 71, Loss: 0.4131, Elapsed: 0m4s
2023-03-06 21:00:38.164933: Epoch: 27, Batch: 72, Loss: 0.3906, Elapsed: 0m2s
2023-03-06 21:00:43.771930: Epoch: 27, Batch: 73, Loss: 0.4144, Elapsed: 0m5s
2023-03-06 21:00:45.919466: Epoch: 27, Batch: 74, Loss: 0.3714, Elapsed: 0m2s
2023-03-06 21:00:48.389567: Epoch: 27, Batch: 75, Loss: 0.4009, Elapsed: 0m2s
2023-03-06 21:00:53.293552: Epoch: 27, Batch: 76, Loss: 0.4094, Elapsed: 0m4s
2023-03-06 21:00:56.142845: Epoch: 27, Batch: 77, Loss: 0.4018, Elapsed: 0m2s
2023-03-06 21:00:58.766489: Epoch: 27, Batch: 78, Loss: 0.3878, Elapsed: 0m2s
2023-03-06 21:01:03.849511: Epoch: 27, Batch: 79, Loss: 0.3850, Elapsed: 0m5s
2023-03-06 21:01:06.221327: Epoch: 27, Batch: 80, Loss: 0.3884, Elapsed: 0m2s
2023-03-06 21:01:08.195235: Epoch: 28, Batch: 1, Loss: 0.3811, Elapsed: 0m1s
2023-03-06 21:01:10.646762: Epoch: 28, Batch: 2, Loss: 0.3824, Elapsed: 0m2s
2023-03-06 21:01:13.432475: Epoch: 28, Batch: 3, Loss: 0.3951, Elapsed: 0m2s
2023-03-06 21:01:16.423864: Epoch: 28, Batch: 4, Loss: 0.3979, Elapsed: 0m2s
2023-03-06 21:01:18.891940: Epoch: 28, Batch: 5, Loss: 0.4013, Elapsed: 0m2s
2023-03-06 21:01:20.824044: Epoch: 28, Batch: 6, Loss: 0.3759, Elapsed: 0m1s
2023-03-06 21:01:23.333102: Epoch: 28, Batch: 7, Loss: 0.3881, Elapsed: 0m2s
2023-03-06 21:01:27.915607: Epoch: 28, Batch: 8, Loss: 0.4113, Elapsed: 0m4s
2023-03-06 21:01:28.958798: Epoch: 28, Batch: 9, Loss: 0.3335, Elapsed: 0m1s
2023-03-06 21:01:34.566444: Epoch: 28, Batch: 10, Loss: 0.4152, Elapsed: 0m5s
2023-03-06 21:01:38.638819: Epoch: 28, Batch: 11, Loss: 0.4096, Elapsed: 0m4s
2023-03-06 21:01:42.264837: Epoch: 28, Batch: 12, Loss: 0.4006, Elapsed: 0m3s
2023-03-06 21:01:44.456681: Epoch: 28, Batch: 13, Loss: 0.3813, Elapsed: 0m2s
2023-03-06 21:01:47.398530: Epoch: 28, Batch: 14, Loss: 0.3966, Elapsed: 0m2s
2023-03-06 21:01:51.376653: Epoch: 28, Batch: 15, Loss: 0.4094, Elapsed: 0m3s
2023-03-06 21:01:54.312793: Epoch: 28, Batch: 16, Loss: 0.3867, Elapsed: 0m2s
2023-03-06 21:01:56.567347: Epoch: 28, Batch: 17, Loss: 0.3858, Elapsed: 0m2s
2023-03-06 21:01:58.340452: Epoch: 28, Batch: 18, Loss: 0.3576, Elapsed: 0m1s
2023-03-06 21:02:01.568708: Epoch: 28, Batch: 19, Loss: 0.4021, Elapsed: 0m3s
2023-03-06 21:02:04.061561: Epoch: 28, Batch: 20, Loss: 0.3826, Elapsed: 0m2s
2023-03-06 21:02:06.049309: Epoch: 28, Batch: 21, Loss: 0.3845, Elapsed: 0m1s
2023-03-06 21:02:08.599127: Epoch: 28, Batch: 22, Loss: 0.3900, Elapsed: 0m2s
2023-03-06 21:02:13.910745: Epoch: 28, Batch: 23, Loss: 0.4187, Elapsed: 0m5s
2023-03-06 21:02:17.453316: Epoch: 28, Batch: 24, Loss: 0.4024, Elapsed: 0m3s
2023-03-06 21:02:20.163455: Epoch: 28, Batch: 25, Loss: 0.3901, Elapsed: 0m2s
2023-03-06 21:02:24.282574: Epoch: 28, Batch: 26, Loss: 0.4090, Elapsed: 0m4s
2023-03-06 21:02:26.111385: Epoch: 28, Batch: 27, Loss: 0.3658, Elapsed: 0m1s
2023-03-06 21:02:28.008920: Epoch: 28, Batch: 28, Loss: 0.3583, Elapsed: 0m1s
2023-03-06 21:02:31.034476: Epoch: 28, Batch: 29, Loss: 0.4012, Elapsed: 0m3s
2023-03-06 21:02:34.618838: Epoch: 28, Batch: 30, Loss: 0.4038, Elapsed: 0m3s
2023-03-06 21:02:37.821681: Epoch: 28, Batch: 31, Loss: 0.3996, Elapsed: 0m3s
2023-03-06 21:02:42.655995: Epoch: 28, Batch: 32, Loss: 0.4127, Elapsed: 0m4s
2023-03-06 21:02:44.645712: Epoch: 28, Batch: 33, Loss: 0.3747, Elapsed: 0m1s
2023-03-06 21:02:48.789698: Epoch: 28, Batch: 34, Loss: 0.4124, Elapsed: 0m4s
2023-03-06 21:02:51.501645: Epoch: 28, Batch: 35, Loss: 0.3877, Elapsed: 0m2s
2023-03-06 21:02:55.038719: Epoch: 28, Batch: 36, Loss: 0.4003, Elapsed: 0m3s
2023-03-06 21:02:57.821162: Epoch: 28, Batch: 37, Loss: 0.3875, Elapsed: 0m2s
2023-03-06 21:03:00.613153: Epoch: 28, Batch: 38, Loss: 0.3873, Elapsed: 0m2s
2023-03-06 21:03:02.902025: Epoch: 28, Batch: 39, Loss: 0.3680, Elapsed: 0m2s
2023-03-06 21:03:06.440796: Epoch: 28, Batch: 40, Loss: 0.3969, Elapsed: 0m3s
2023-03-06 21:03:10.265272: Epoch: 28, Batch: 41, Loss: 0.4067, Elapsed: 0m3s
2023-03-06 21:03:13.663229: Epoch: 28, Batch: 42, Loss: 0.3923, Elapsed: 0m3s
2023-03-06 21:03:16.582539: Epoch: 28, Batch: 43, Loss: 0.3846, Elapsed: 0m2s
2023-03-06 21:03:18.726673: Epoch: 28, Batch: 44, Loss: 0.3709, Elapsed: 0m2s
2023-03-06 21:03:22.848900: Epoch: 28, Batch: 45, Loss: 0.4052, Elapsed: 0m4s
2023-03-06 21:03:25.338352: Epoch: 28, Batch: 46, Loss: 0.3893, Elapsed: 0m2s
2023-03-06 21:03:29.746086: Epoch: 28, Batch: 47, Loss: 0.4065, Elapsed: 0m4s
2023-03-06 21:03:32.249354: Epoch: 28, Batch: 48, Loss: 0.3751, Elapsed: 0m2s
2023-03-06 21:03:34.402900: Epoch: 28, Batch: 49, Loss: 0.3826, Elapsed: 0m2s
2023-03-06 21:03:38.039841: Epoch: 28, Batch: 50, Loss: 0.4034, Elapsed: 0m3s
2023-03-06 21:03:38.048403 Starting testing the valid set with 20 subgraphs!
2023-03-06 21:04:43.692182: validation Test:  Loss: 0.3943,  AUC: 0.8778, Acc: 79.5499,  Precision: 0.9078 -- Elapsed: 1m5s
2023-03-06 21:04:43.693341 Starting testing the train set with 20 subgraphs!
2023-03-06 21:09:09.237430: training Test:  Loss: 0.3935,  AUC: 0.8783, Acc: 79.6245,  Precision: 0.9077 -- Elapsed: 4m25s
2023-03-06 21:09:13.542378: Epoch: 28, Batch: 51, Loss: 0.4116, Elapsed: 0m4s
2023-03-06 21:09:15.145824: Epoch: 28, Batch: 52, Loss: 0.3610, Elapsed: 0m1s
2023-03-06 21:09:18.152552: Epoch: 28, Batch: 53, Loss: 0.3802, Elapsed: 0m2s
2023-03-06 21:09:22.538776: Epoch: 28, Batch: 54, Loss: 0.4067, Elapsed: 0m4s
2023-03-06 21:09:25.695188: Epoch: 28, Batch: 55, Loss: 0.3818, Elapsed: 0m3s
2023-03-06 21:09:28.382991: Epoch: 28, Batch: 56, Loss: 0.4015, Elapsed: 0m2s
2023-03-06 21:09:31.022154: Epoch: 28, Batch: 57, Loss: 0.3816, Elapsed: 0m2s
2023-03-06 21:09:34.136569: Epoch: 28, Batch: 58, Loss: 0.3949, Elapsed: 0m3s
2023-03-06 21:09:40.402530: Epoch: 28, Batch: 59, Loss: 0.4239, Elapsed: 0m6s
2023-03-06 21:09:45.482811: Epoch: 28, Batch: 60, Loss: 0.4131, Elapsed: 0m5s
2023-03-06 21:09:48.924941: Epoch: 28, Batch: 61, Loss: 0.4046, Elapsed: 0m3s
2023-03-06 21:09:50.610565: Epoch: 28, Batch: 62, Loss: 0.3716, Elapsed: 0m1s
2023-03-06 21:09:52.617032: Epoch: 28, Batch: 63, Loss: 0.3838, Elapsed: 0m1s
2023-03-06 21:09:54.887634: Epoch: 28, Batch: 64, Loss: 0.3844, Elapsed: 0m2s
2023-03-06 21:09:57.504527: Epoch: 28, Batch: 65, Loss: 0.3908, Elapsed: 0m2s
2023-03-06 21:09:59.877740: Epoch: 28, Batch: 66, Loss: 0.3657, Elapsed: 0m2s
2023-03-06 21:10:03.115534: Epoch: 28, Batch: 67, Loss: 0.3929, Elapsed: 0m3s
2023-03-06 21:10:04.644765: Epoch: 28, Batch: 68, Loss: 0.3512, Elapsed: 0m1s
2023-03-06 21:10:05.941854: Epoch: 28, Batch: 69, Loss: 0.3312, Elapsed: 0m1s
2023-03-06 21:10:11.002453: Epoch: 28, Batch: 70, Loss: 0.3846, Elapsed: 0m5s
2023-03-06 21:10:13.386114: Epoch: 28, Batch: 71, Loss: 0.3881, Elapsed: 0m2s
2023-03-06 21:10:15.303035: Epoch: 28, Batch: 72, Loss: 0.3681, Elapsed: 0m1s
2023-03-06 21:10:17.796980: Epoch: 28, Batch: 73, Loss: 0.3906, Elapsed: 0m2s
2023-03-06 21:10:20.639206: Epoch: 28, Batch: 74, Loss: 0.3859, Elapsed: 0m2s
2023-03-06 21:10:23.501149: Epoch: 28, Batch: 75, Loss: 0.3950, Elapsed: 0m2s
2023-03-06 21:10:28.460364: Epoch: 28, Batch: 76, Loss: 0.4089, Elapsed: 0m4s
2023-03-06 21:10:31.950987: Epoch: 28, Batch: 77, Loss: 0.4104, Elapsed: 0m3s
2023-03-06 21:10:36.224290: Epoch: 28, Batch: 78, Loss: 0.4135, Elapsed: 0m4s
2023-03-06 21:10:40.450521: Epoch: 28, Batch: 79, Loss: 0.4222, Elapsed: 0m4s
2023-03-06 21:10:42.970241: Epoch: 28, Batch: 80, Loss: 0.3814, Elapsed: 0m2s
2023-03-06 21:10:48.329451: Epoch: 29, Batch: 1, Loss: 0.4188, Elapsed: 0m5s
2023-03-06 21:10:50.822012: Epoch: 29, Batch: 2, Loss: 0.3896, Elapsed: 0m2s
2023-03-06 21:10:53.326089: Epoch: 29, Batch: 3, Loss: 0.3907, Elapsed: 0m2s
2023-03-06 21:10:56.349846: Epoch: 29, Batch: 4, Loss: 0.4015, Elapsed: 0m3s
2023-03-06 21:10:57.883334: Epoch: 29, Batch: 5, Loss: 0.3512, Elapsed: 0m1s
2023-03-06 21:11:00.269179: Epoch: 29, Batch: 6, Loss: 0.3659, Elapsed: 0m2s
2023-03-06 21:11:02.284083: Epoch: 29, Batch: 7, Loss: 0.3837, Elapsed: 0m2s
2023-03-06 21:11:07.261651: Epoch: 29, Batch: 8, Loss: 0.4089, Elapsed: 0m4s
2023-03-06 21:11:08.869035: Epoch: 29, Batch: 9, Loss: 0.3612, Elapsed: 0m1s
2023-03-06 21:11:11.286158: Epoch: 29, Batch: 10, Loss: 0.3824, Elapsed: 0m2s
2023-03-06 21:11:13.918325: Epoch: 29, Batch: 11, Loss: 0.3907, Elapsed: 0m2s
2023-03-06 21:11:16.413673: Epoch: 29, Batch: 12, Loss: 0.4010, Elapsed: 0m2s
2023-03-06 21:11:18.917431: Epoch: 29, Batch: 13, Loss: 0.3884, Elapsed: 0m2s
2023-03-06 21:11:21.495183: Epoch: 29, Batch: 14, Loss: 0.3751, Elapsed: 0m2s
2023-03-06 21:11:24.479426: Epoch: 29, Batch: 15, Loss: 0.3852, Elapsed: 0m2s
2023-03-06 21:11:26.661040: Epoch: 29, Batch: 16, Loss: 0.3714, Elapsed: 0m2s
2023-03-06 21:11:27.961056: Epoch: 29, Batch: 17, Loss: 0.3323, Elapsed: 0m1s
2023-03-06 21:11:30.778264: Epoch: 29, Batch: 18, Loss: 0.3874, Elapsed: 0m2s
2023-03-06 21:11:35.694554: Epoch: 29, Batch: 19, Loss: 0.4119, Elapsed: 0m4s
2023-03-06 21:11:39.142806: Epoch: 29, Batch: 20, Loss: 0.3802, Elapsed: 0m3s
2023-03-06 21:11:44.244617: Epoch: 29, Batch: 21, Loss: 0.4123, Elapsed: 0m5s
2023-03-06 21:11:48.698245: Epoch: 29, Batch: 22, Loss: 0.4223, Elapsed: 0m4s
2023-03-06 21:11:50.555515: Epoch: 29, Batch: 23, Loss: 0.3754, Elapsed: 0m1s
2023-03-06 21:11:52.823981: Epoch: 29, Batch: 24, Loss: 0.3846, Elapsed: 0m2s
2023-03-06 21:11:54.721747: Epoch: 29, Batch: 25, Loss: 0.3577, Elapsed: 0m1s
2023-03-06 21:11:57.509484: Epoch: 29, Batch: 26, Loss: 0.3935, Elapsed: 0m2s
2023-03-06 21:12:00.443920: Epoch: 29, Batch: 27, Loss: 0.3859, Elapsed: 0m2s
2023-03-06 21:12:04.768549: Epoch: 29, Batch: 28, Loss: 0.4069, Elapsed: 0m4s
2023-03-06 21:12:08.396708: Epoch: 29, Batch: 29, Loss: 0.3997, Elapsed: 0m3s
2023-03-06 21:12:11.340682: Epoch: 29, Batch: 30, Loss: 0.4000, Elapsed: 0m2s
2023-03-06 21:12:14.049202: Epoch: 29, Batch: 31, Loss: 0.3895, Elapsed: 0m2s
2023-03-06 21:12:17.430625: Epoch: 29, Batch: 32, Loss: 0.3925, Elapsed: 0m3s
2023-03-06 21:12:19.620192: Epoch: 29, Batch: 33, Loss: 0.3803, Elapsed: 0m2s
2023-03-06 21:12:23.195411: Epoch: 29, Batch: 34, Loss: 0.4022, Elapsed: 0m3s
2023-03-06 21:12:25.747408: Epoch: 29, Batch: 35, Loss: 0.3896, Elapsed: 0m2s
2023-03-06 21:12:29.544902: Epoch: 29, Batch: 36, Loss: 0.4123, Elapsed: 0m3s
2023-03-06 21:12:32.687393: Epoch: 29, Batch: 37, Loss: 0.3823, Elapsed: 0m3s
2023-03-06 21:12:34.336413: Epoch: 29, Batch: 38, Loss: 0.3578, Elapsed: 0m1s
2023-03-06 21:12:36.709318: Epoch: 29, Batch: 39, Loss: 0.3878, Elapsed: 0m2s
2023-03-06 21:12:39.932535: Epoch: 29, Batch: 40, Loss: 0.3932, Elapsed: 0m3s
2023-03-06 21:12:44.098255: Epoch: 29, Batch: 41, Loss: 0.4087, Elapsed: 0m4s
2023-03-06 21:12:48.463879: Epoch: 29, Batch: 42, Loss: 0.4086, Elapsed: 0m4s
2023-03-06 21:12:53.663082: Epoch: 29, Batch: 43, Loss: 0.3849, Elapsed: 0m5s
2023-03-06 21:12:55.830098: Epoch: 29, Batch: 44, Loss: 0.3681, Elapsed: 0m2s
2023-03-06 21:12:58.612609: Epoch: 29, Batch: 45, Loss: 0.3880, Elapsed: 0m2s
2023-03-06 21:13:00.767772: Epoch: 29, Batch: 46, Loss: 0.3828, Elapsed: 0m2s
2023-03-06 21:13:04.883572: Epoch: 29, Batch: 47, Loss: 0.4131, Elapsed: 0m4s
2023-03-06 21:13:10.467936: Epoch: 29, Batch: 48, Loss: 0.4148, Elapsed: 0m5s
2023-03-06 21:13:14.262648: Epoch: 29, Batch: 49, Loss: 0.4071, Elapsed: 0m3s
2023-03-06 21:13:17.698312: Epoch: 29, Batch: 50, Loss: 0.4048, Elapsed: 0m3s
2023-03-06 21:13:17.707064 Starting testing the valid set with 20 subgraphs!
2023-03-06 21:14:23.608080: validation Test:  Loss: 0.3942,  AUC: 0.8782, Acc: 79.5136,  Precision: 0.8554 -- Elapsed: 1m5s
2023-03-06 21:14:23.609261 Starting testing the train set with 20 subgraphs!
2023-03-06 21:18:48.968715: training Test:  Loss: 0.3934,  AUC: 0.8786, Acc: 79.5860,  Precision: 0.8555 -- Elapsed: 4m25s
2023-03-06 21:18:50.972323: Epoch: 29, Batch: 51, Loss: 0.3844, Elapsed: 0m2s
2023-03-06 21:18:53.676247: Epoch: 29, Batch: 52, Loss: 0.4019, Elapsed: 0m2s
2023-03-06 21:18:56.177140: Epoch: 29, Batch: 53, Loss: 0.3804, Elapsed: 0m2s
2023-03-06 21:18:58.232241: Epoch: 29, Batch: 54, Loss: 0.3768, Elapsed: 0m2s
2023-03-06 21:19:02.755532: Epoch: 29, Batch: 55, Loss: 0.4125, Elapsed: 0m4s
2023-03-06 21:19:05.272233: Epoch: 29, Batch: 56, Loss: 0.3863, Elapsed: 0m2s
2023-03-06 21:19:10.384737: Epoch: 29, Batch: 57, Loss: 0.4135, Elapsed: 0m5s
2023-03-06 21:19:11.411759: Epoch: 29, Batch: 58, Loss: 0.3318, Elapsed: 0m1s
2023-03-06 21:19:14.543706: Epoch: 29, Batch: 59, Loss: 0.3970, Elapsed: 0m3s
2023-03-06 21:19:16.478511: Epoch: 29, Batch: 60, Loss: 0.3654, Elapsed: 0m1s
2023-03-06 21:19:20.783429: Epoch: 29, Batch: 61, Loss: 0.4060, Elapsed: 0m4s
2023-03-06 21:19:24.150644: Epoch: 29, Batch: 62, Loss: 0.3969, Elapsed: 0m3s
2023-03-06 21:19:30.414088: Epoch: 29, Batch: 63, Loss: 0.4238, Elapsed: 0m6s
2023-03-06 21:19:33.944133: Epoch: 29, Batch: 64, Loss: 0.4106, Elapsed: 0m3s
2023-03-06 21:19:36.511086: Epoch: 29, Batch: 65, Loss: 0.3814, Elapsed: 0m2s
2023-03-06 21:19:39.600587: Epoch: 29, Batch: 66, Loss: 0.4019, Elapsed: 0m3s
2023-03-06 21:19:42.197917: Epoch: 29, Batch: 67, Loss: 0.3817, Elapsed: 0m2s
2023-03-06 21:19:45.885003: Epoch: 29, Batch: 68, Loss: 0.4033, Elapsed: 0m3s
2023-03-06 21:19:50.330571: Epoch: 29, Batch: 69, Loss: 0.4067, Elapsed: 0m4s
2023-03-06 21:19:52.056841: Epoch: 29, Batch: 70, Loss: 0.3714, Elapsed: 0m1s
2023-03-06 21:19:55.474995: Epoch: 29, Batch: 71, Loss: 0.4000, Elapsed: 0m3s
2023-03-06 21:19:58.325746: Epoch: 29, Batch: 72, Loss: 0.3858, Elapsed: 0m2s
2023-03-06 21:20:00.269280: Epoch: 29, Batch: 73, Loss: 0.3722, Elapsed: 0m1s
2023-03-06 21:20:02.223535: Epoch: 29, Batch: 74, Loss: 0.3671, Elapsed: 0m1s
2023-03-06 21:20:05.220447: Epoch: 29, Batch: 75, Loss: 0.3948, Elapsed: 0m2s
2023-03-06 21:20:08.154888: Epoch: 29, Batch: 76, Loss: 0.3950, Elapsed: 0m2s
2023-03-06 21:20:11.602048: Epoch: 29, Batch: 77, Loss: 0.4031, Elapsed: 0m3s
2023-03-06 21:20:15.614099: Epoch: 29, Batch: 78, Loss: 0.4087, Elapsed: 0m4s
2023-03-06 21:20:18.819274: Epoch: 29, Batch: 79, Loss: 0.3943, Elapsed: 0m3s
2023-03-06 21:20:21.314263: Epoch: 29, Batch: 80, Loss: 0.3851, Elapsed: 0m2s
2023-03-06 21:20:22.761444: Epoch: 30, Batch: 1, Loss: 0.3313, Elapsed: 0m1s
2023-03-06 21:20:24.515698: Epoch: 30, Batch: 2, Loss: 0.3610, Elapsed: 0m1s
2023-03-06 21:20:28.018209: Epoch: 30, Batch: 3, Loss: 0.3927, Elapsed: 0m3s
2023-03-06 21:20:30.436010: Epoch: 30, Batch: 4, Loss: 0.3878, Elapsed: 0m2s
2023-03-06 21:20:34.599855: Epoch: 30, Batch: 5, Loss: 0.4051, Elapsed: 0m4s
2023-03-06 21:20:37.460331: Epoch: 30, Batch: 6, Loss: 0.3855, Elapsed: 0m2s
2023-03-06 21:20:39.746950: Epoch: 30, Batch: 7, Loss: 0.3847, Elapsed: 0m2s
2023-03-06 21:20:41.921176: Epoch: 30, Batch: 8, Loss: 0.3827, Elapsed: 0m2s
2023-03-06 21:20:46.687951: Epoch: 30, Batch: 9, Loss: 0.4104, Elapsed: 0m4s
2023-03-06 21:20:49.922648: Epoch: 30, Batch: 10, Loss: 0.3843, Elapsed: 0m3s
2023-03-06 21:20:53.449501: Epoch: 30, Batch: 11, Loss: 0.3819, Elapsed: 0m3s
2023-03-06 21:20:56.242962: Epoch: 30, Batch: 12, Loss: 0.3748, Elapsed: 0m2s
2023-03-06 21:20:57.274498: Epoch: 30, Batch: 13, Loss: 0.3316, Elapsed: 0m1s
2023-03-06 21:21:02.914870: Epoch: 30, Batch: 14, Loss: 0.4142, Elapsed: 0m5s
2023-03-06 21:21:07.044094: Epoch: 30, Batch: 15, Loss: 0.4081, Elapsed: 0m4s
2023-03-06 21:21:09.581392: Epoch: 30, Batch: 16, Loss: 0.3816, Elapsed: 0m2s
2023-03-06 21:21:11.618125: Epoch: 30, Batch: 17, Loss: 0.3834, Elapsed: 0m2s
2023-03-06 21:21:14.274139: Epoch: 30, Batch: 18, Loss: 0.3898, Elapsed: 0m2s
2023-03-06 21:21:16.299055: Epoch: 30, Batch: 19, Loss: 0.3841, Elapsed: 0m2s
2023-03-06 21:21:18.510738: Epoch: 30, Batch: 20, Loss: 0.3794, Elapsed: 0m2s
2023-03-06 21:21:21.002040: Epoch: 30, Batch: 21, Loss: 0.3890, Elapsed: 0m2s
2023-03-06 21:21:24.883087: Epoch: 30, Batch: 22, Loss: 0.3996, Elapsed: 0m3s
2023-03-06 21:21:26.670376: Epoch: 30, Batch: 23, Loss: 0.3716, Elapsed: 0m1s
2023-03-06 21:21:28.853706: Epoch: 30, Batch: 24, Loss: 0.3710, Elapsed: 0m2s
2023-03-06 21:21:31.805680: Epoch: 30, Batch: 25, Loss: 0.3961, Elapsed: 0m2s
2023-03-06 21:21:34.619488: Epoch: 30, Batch: 26, Loss: 0.3869, Elapsed: 0m2s
2023-03-06 21:21:39.723733: Epoch: 30, Batch: 27, Loss: 0.4131, Elapsed: 0m5s
2023-03-06 21:21:42.446685: Epoch: 30, Batch: 28, Loss: 0.3895, Elapsed: 0m2s
2023-03-06 21:21:45.807871: Epoch: 30, Batch: 29, Loss: 0.3972, Elapsed: 0m3s
2023-03-06 21:21:48.321317: Epoch: 30, Batch: 30, Loss: 0.3864, Elapsed: 0m2s
2023-03-06 21:21:52.686071: Epoch: 30, Batch: 31, Loss: 0.4073, Elapsed: 0m4s
2023-03-06 21:21:55.717130: Epoch: 30, Batch: 32, Loss: 0.4007, Elapsed: 0m3s
2023-03-06 21:21:58.777845: Epoch: 30, Batch: 33, Loss: 0.4020, Elapsed: 0m3s
2023-03-06 21:22:02.428027: Epoch: 30, Batch: 34, Loss: 0.4040, Elapsed: 0m3s
2023-03-06 21:22:04.264705: Epoch: 30, Batch: 35, Loss: 0.3654, Elapsed: 0m1s
2023-03-06 21:22:06.132809: Epoch: 30, Batch: 36, Loss: 0.3751, Elapsed: 0m1s
2023-03-06 21:22:08.062158: Epoch: 30, Batch: 37, Loss: 0.3675, Elapsed: 0m1s
2023-03-06 21:22:12.497575: Epoch: 30, Batch: 38, Loss: 0.4066, Elapsed: 0m4s
2023-03-06 21:22:14.996321: Epoch: 30, Batch: 39, Loss: 0.3875, Elapsed: 0m2s
2023-03-06 21:22:18.400657: Epoch: 30, Batch: 40, Loss: 0.3922, Elapsed: 0m3s
2023-03-06 21:22:21.804729: Epoch: 30, Batch: 41, Loss: 0.3999, Elapsed: 0m3s
2023-03-06 21:22:23.991748: Epoch: 30, Batch: 42, Loss: 0.3678, Elapsed: 0m2s
2023-03-06 21:22:27.979127: Epoch: 30, Batch: 43, Loss: 0.4122, Elapsed: 0m3s
2023-03-06 21:22:30.480480: Epoch: 30, Batch: 44, Loss: 0.3655, Elapsed: 0m2s
2023-03-06 21:22:34.518496: Epoch: 30, Batch: 45, Loss: 0.4088, Elapsed: 0m4s
2023-03-06 21:22:38.381264: Epoch: 30, Batch: 46, Loss: 0.4066, Elapsed: 0m3s
2023-03-06 21:22:42.889830: Epoch: 30, Batch: 47, Loss: 0.4120, Elapsed: 0m4s
2023-03-06 21:22:44.546974: Epoch: 30, Batch: 48, Loss: 0.3573, Elapsed: 0m1s
2023-03-06 21:22:46.477944: Epoch: 30, Batch: 49, Loss: 0.3723, Elapsed: 0m1s
2023-03-06 21:22:49.188189: Epoch: 30, Batch: 50, Loss: 0.4019, Elapsed: 0m2s
2023-03-06 21:22:49.197945 Starting testing the valid set with 20 subgraphs!
2023-03-06 21:23:56.564523: validation Test:  Loss: 0.3943,  AUC: 0.8778, Acc: 79.4966,  Precision: 0.8367 -- Elapsed: 1m7s
2023-03-06 21:23:56.565792 Starting testing the train set with 20 subgraphs!
2023-03-06 21:28:19.221048: training Test:  Loss: 0.3935,  AUC: 0.8783, Acc: 79.5790,  Precision: 0.8382 -- Elapsed: 4m22s
2023-03-06 21:28:21.746006: Epoch: 30, Batch: 51, Loss: 0.3816, Elapsed: 0m2s
2023-03-06 21:28:23.284422: Epoch: 30, Batch: 52, Loss: 0.3506, Elapsed: 0m1s
2023-03-06 21:28:26.791001: Epoch: 30, Batch: 53, Loss: 0.4103, Elapsed: 0m3s
2023-03-06 21:28:30.927860: Epoch: 30, Batch: 54, Loss: 0.4132, Elapsed: 0m4s
2023-03-06 21:28:33.894113: Epoch: 30, Batch: 55, Loss: 0.3852, Elapsed: 0m2s
2023-03-06 21:28:36.832115: Epoch: 30, Batch: 56, Loss: 0.3799, Elapsed: 0m2s
2023-03-06 21:28:39.320360: Epoch: 30, Batch: 57, Loss: 0.4006, Elapsed: 0m2s
2023-03-06 21:28:41.231824: Epoch: 30, Batch: 58, Loss: 0.3576, Elapsed: 0m1s
2023-03-06 21:28:43.738250: Epoch: 30, Batch: 59, Loss: 0.3903, Elapsed: 0m2s
2023-03-06 21:28:47.191043: Epoch: 30, Batch: 60, Loss: 0.4044, Elapsed: 0m3s
2023-03-06 21:28:49.472762: Epoch: 30, Batch: 61, Loss: 0.3846, Elapsed: 0m2s
2023-03-06 21:28:53.105744: Epoch: 30, Batch: 62, Loss: 0.4017, Elapsed: 0m3s
2023-03-06 21:28:59.620559: Epoch: 30, Batch: 63, Loss: 0.4237, Elapsed: 0m6s
2023-03-06 21:29:02.413344: Epoch: 30, Batch: 64, Loss: 0.3873, Elapsed: 0m2s
2023-03-06 21:29:06.896164: Epoch: 30, Batch: 65, Loss: 0.4115, Elapsed: 0m4s
2023-03-06 21:29:11.315375: Epoch: 30, Batch: 66, Loss: 0.4218, Elapsed: 0m4s
2023-03-06 21:29:13.482921: Epoch: 30, Batch: 67, Loss: 0.3768, Elapsed: 0m2s
2023-03-06 21:29:19.014200: Epoch: 30, Batch: 68, Loss: 0.4186, Elapsed: 0m5s
2023-03-06 21:29:21.886673: Epoch: 30, Batch: 69, Loss: 0.3948, Elapsed: 0m2s
2023-03-06 21:29:26.972933: Epoch: 30, Batch: 70, Loss: 0.3839, Elapsed: 0m5s
2023-03-06 21:29:29.947797: Epoch: 30, Batch: 71, Loss: 0.3991, Elapsed: 0m2s
2023-03-06 21:29:34.935530: Epoch: 30, Batch: 72, Loss: 0.4091, Elapsed: 0m4s
2023-03-06 21:29:37.748334: Epoch: 30, Batch: 73, Loss: 0.3941, Elapsed: 0m2s
2023-03-06 21:29:40.737883: Epoch: 30, Batch: 74, Loss: 0.3974, Elapsed: 0m2s
2023-03-06 21:29:44.895090: Epoch: 30, Batch: 75, Loss: 0.4110, Elapsed: 0m4s
2023-03-06 21:29:47.528269: Epoch: 30, Batch: 76, Loss: 0.3923, Elapsed: 0m2s
2023-03-06 21:29:50.623580: Epoch: 30, Batch: 77, Loss: 0.3948, Elapsed: 0m3s
2023-03-06 21:29:53.113101: Epoch: 30, Batch: 78, Loss: 0.3815, Elapsed: 0m2s
2023-03-06 21:29:56.558370: Epoch: 30, Batch: 79, Loss: 0.4038, Elapsed: 0m3s
2023-03-06 21:29:59.149415: Epoch: 30, Batch: 80, Loss: 0.3829, Elapsed: 0m2s
2023-03-06 21:29:59.158656: Training completed!
